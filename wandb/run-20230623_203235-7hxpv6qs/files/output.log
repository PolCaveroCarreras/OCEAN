size input:  torch.Size([128, 1, 36, 40])
tensor([[[[0.0768, 0.0768, 0.0768,  ..., 0.1514, 0.1823, 0.0991],
          [0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.1226, 0.0810],
          [0.0768, 0.0768, 0.0768,  ..., 0.0793, 0.0903, 0.1120],
          ...,
          [0.1557, 0.0768, 0.0768,  ..., 0.0768, 0.1074, 0.1601],
          [0.1379, 0.0768, 0.0768,  ..., 0.1148, 0.1599, 0.1635],
          [0.1587, 0.0768, 0.0768,  ..., 0.0805, 0.1915, 0.0767]]],
        [[[0.0768, 0.0768, 0.0768,  ..., 0.0839, 0.1870, 0.2094],
          [0.0768, 0.0768, 0.0768,  ..., 0.0779, 0.1685, 0.2045],
          [0.0768, 0.0768, 0.0768,  ..., 0.0790, 0.1428, 0.1774],
          ...,
          [0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.1021, 0.2291],
          [0.0768, 0.0768, 0.0768,  ..., 0.0955, 0.1865, 0.2537],
          [0.0768, 0.0768, 0.0768,  ..., 0.0821, 0.1850, 0.1676]]],
        [[[0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.0830, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.0827, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          ...,
          [0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768]]],
        ...,
        [[[0.0880, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0981],
          [0.1069, 0.0768, 0.0768,  ..., 0.0768, 0.0875, 0.0973],
          [0.0948, 0.0768, 0.0768,  ..., 0.0768, 0.0788, 0.0893],
          ...,
          [0.1572, 0.0783, 0.0789,  ..., 0.0768, 0.0768, 0.0858],
          [0.1821, 0.0780, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.1463, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768]]],
        [[[0.1025, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.1573, 0.0768, 0.0768,  ..., 0.0768, 0.0768, 0.0768],
          [0.1394, 0.0911, 0.0968,  ..., 0.0768, 0.0768, 0.0768],
          ...,
          [0.2208, 0.1062, 0.1284,  ..., 0.0768, 0.0787, 0.1121],
          [0.2030, 0.1516, 0.1149,  ..., 0.0768, 0.0768, 0.1045],
          [0.2310, 0.1491, 0.0910,  ..., 0.0768, 0.0832, 0.1082]]],
        [[[0.1802, 0.0768, 0.0795,  ..., 0.0768, 0.0846, 0.1105],
          [0.1812, 0.0768, 0.0768,  ..., 0.0790, 0.0962, 0.1247],
          [0.1166, 0.0768, 0.0768,  ..., 0.1110, 0.0933, 0.1475],
          ...,
          [0.0768, 0.0768, 0.0768,  ..., 0.0768, 0.1141, 0.1414],
          [0.0803, 0.0768, 0.0768,  ..., 0.1071, 0.1360, 0.1339],
          [0.0802, 0.0768, 0.0768,  ..., 0.1004, 0.0859, 0.1732]]]],
       grad_fn=<MaxPool2DWithIndicesBackward0>)
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0%|          | 0/478 [00:00<?, ?batch/s]
Traceback (most recent call last):
  File "src/main.py", line 233, in <module>
    my_model = train_model(config)
  File "src/main.py", line 139, in train_model
    train_loss, train_acc = train_single_epoch(my_model, train_loader, optimizer)
  File "src/main.py", line 51, in train_single_epoch
    y_ = model(x, y)[0] #                   POL: AFEGIT [0]
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/DMHA.py", line 131, in forward
    embedding_0, alignment = self.poolingLayer(encoder_output)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/poolings_original.py", line 152, in forward
    utteranceRepresentation, alignment = self.utteranceAttention(x)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/poolings_original.py", line 130, in forward
    headsContextVectors = self.getHeadsContextVectors(ht)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/poolings_original.py", line 124, in getHeadsContextVectors
    key = ht.view(batch_size*ht.size(1), self.heads_number, self.head_size)
RuntimeError: shape '[1152, 5, 4]' is invalid for input of size 11520