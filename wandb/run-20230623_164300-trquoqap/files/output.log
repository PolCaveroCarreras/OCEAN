wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0%|          | 0/478 [00:00<?, ?batch/s]
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
el valor es  36
cpu
torch.Size([128, 1, 36, 40])
Antes del view: torch.Size([128, 1, 36, 40])
tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.]])
last_features: tensor([[ 1.2746,  0.2308,  0.1921,  ..., -0.2932, -0.1753,  0.6449],
        [-0.7902,  3.3481,  4.2862,  ..., -2.3789, -0.6885, -0.7494],
        [ 0.3421,  0.3209, -0.5296,  ...,  0.6379,  0.2668,  0.3369],
        ...,
        [-0.2132, -0.7626, -0.6828,  ..., -0.3845,  0.1686,  0.1056],
        [ 0.5499,  0.1490,  0.5549,  ..., -1.1136,  0.0088, -0.4580],
        [ 2.4686, -0.8598,  0.4780,  ...,  1.1022, -1.3499,  0.9641]],
       grad_fn=<NativeBatchNormBackward0>)
label: tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.],
        [0., 1.],
  0%|          | 0/478 [00:01<?, ?batch/s]
Traceback (most recent call last):
  File "src/main.py", line 233, in <module>
    my_model = train_model(config)
  File "src/main.py", line 139, in train_model
    train_loss, train_acc = train_single_epoch(my_model, train_loader, optimizer)
  File "src/main.py", line 52, in train_single_epoch
    y_ = model(x, y)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/DMHA.py", line 147, in forward
    inner_products, inner_products_m_s = self.am_softmax_layer(embedding_3, label)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/loss.py", line 61, in forward
    aux_m = torch.zeros(inner_products.size()).scatter_(1, label_view, self.m) # make a zeros matrix with m in the corresponding label position
RuntimeError: scatter(): Expected dtype int64 for index