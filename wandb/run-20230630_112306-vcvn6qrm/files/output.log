wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0%|          | 0/478 [00:00<?, ?batch/s]
input: torch.Size([128, 1, 36, 40])
labels:  torch.Size([128, 2])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5133, -0.5053, -0.3288,  ..., -0.5753, -0.7914, -0.8309],
          [-0.2688, -0.2187, -0.2381,  ..., -0.4843, -0.6277, -0.8088],
          [-0.2317, -0.1912, -0.2591,  ..., -0.3493, -0.6673, -0.8611],
          ...,
          [-0.3626, -0.2931, -0.3145,  ..., -0.7088, -0.7143, -0.5232],
          [-0.2175, -0.2278, -0.1232,  ..., -0.5232, -0.6081, -0.6296],
          [-0.1644, -0.2459, -0.0857,  ..., -0.4895, -0.7490, -0.7486]]],
        [[[-0.9409, -0.5326,  0.0344,  ...,  0.6397,  0.5453,  0.3656],
          [-0.7380,  0.0298,  0.2637,  ...,  0.7650,  0.7488,  0.3807],
          [-0.5423,  0.1963,  0.2515,  ...,  0.9061,  0.5893,  0.3887],
          ...,
          [-0.8937, -0.2210,  0.1894,  ...,  0.9996,  0.5677,  0.4446],
          [-1.0000, -0.1897,  0.1758,  ...,  0.9870,  0.7666,  0.3599],
          [-0.8295, -0.1033,  0.0440,  ...,  0.7568,  0.7496,  0.1874]]],
        [[[-0.4244, -0.4864, -0.3513,  ...,  0.1828, -0.0660, -0.2148],
          [-0.3217, -0.5076, -0.3382,  ...,  0.2689,  0.0219, -0.2284],
          [-0.2872, -0.3007, -0.0117,  ...,  0.2712,  0.0846, -0.2038],
          ...,
          [-0.2914, -0.2803, -0.4511,  ..., -0.3909, -0.2705, -0.7329],
          [-0.3223, -0.3853, -0.2937,  ..., -0.2079, -0.1129, -0.4707],
          [-0.3617, -0.2694, -0.3908,  ...,  0.0109,  0.0689, -0.3320]]],
        ...,
        [[[-0.2481,  0.0425,  0.1140,  ..., -0.5461, -0.5486, -0.5669],
          [-0.4079, -0.0573, -0.0452,  ..., -0.4437, -0.6016, -0.4392],
          [-0.2658, -0.1562, -0.4224,  ..., -0.7071, -0.5704, -0.5024],
          ...,
          [-0.1943,  0.0017, -0.2076,  ..., -0.7355, -0.6492, -0.2469],
          [-0.2553,  0.0534, -0.2054,  ..., -0.6997, -0.6622, -0.2692],
          [-0.3722, -0.0272, -0.0808,  ..., -0.8602, -0.6498, -0.2713]]],
        [[[-0.3104, -0.0658, -0.1150,  ..., -0.5950, -0.6394, -0.6367],
          [-0.4404, -0.2532, -0.1221,  ..., -0.5133, -0.8502, -0.7152],
          [-0.4248, -0.2801, -0.2896,  ..., -0.4502, -0.6909, -0.7426],
          ...,
          [-0.3707, -0.2629, -0.3857,  ..., -0.6878, -0.7317, -0.5888],
          [-0.3730, -0.1466, -0.2717,  ..., -0.8848, -0.9615, -0.5994],
          [-0.2599, -0.0733, -0.0586,  ..., -0.7508, -0.8554, -0.5803]]],
        [[[-0.5723, -0.2508, -0.0048,  ...,  0.0358,  0.0745, -0.0753],
          [-0.4398, -0.2108, -0.2136,  ...,  0.2172,  0.0763, -0.3143],
          [-0.4209, -0.0755, -0.0819,  ...,  0.0875, -0.2340, -0.3596],
          ...,
          [-0.6075, -0.2501,  0.0552,  ...,  0.1617,  0.0656, -0.2463],
          [-0.6744, -0.1419,  0.1652,  ...,  0.1606,  0.0268, -0.2398],
          [-0.8320, -0.0676,  0.1751,  ...,  0.1631,  0.1229, -0.5772]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[6.2793e-03, 8.5061e-03, 7.7230e-03, 9.1780e-03, 1.3533e-02],
          [4.0486e-03, 2.9842e-03, 2.1861e-03, 3.7933e-03, 1.0300e-02],
          [4.5218e-03, 2.3934e-03, 1.1577e-03, 4.2827e-03, 9.5483e-03],
          [2.0564e-02, 2.0774e-02, 1.8678e-02, 2.3079e-02, 2.2043e-02],
          [8.5647e-03, 5.9110e-03, 5.3153e-03, 6.2721e-03, 1.2203e-02]],
         [[3.5126e-02, 3.6352e-02, 3.3469e-02, 3.7899e-02, 4.4910e-02],
          [2.5153e-02, 2.4226e-02, 2.2004e-02, 2.5068e-02, 3.2997e-02],
          [2.4982e-02, 2.3326e-02, 2.2066e-02, 2.5351e-02, 3.2865e-02],
          [2.4329e-02, 2.2894e-02, 2.1353e-02, 2.3714e-02, 3.2644e-02],
          [3.2500e-02, 2.7729e-02, 2.7678e-02, 2.9027e-02, 2.6141e-02]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         ...,
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[2.3402e-02, 2.0955e-02, 2.1440e-02, 2.0307e-02, 1.3123e-02],
          [2.5733e-02, 1.9984e-02, 2.0295e-02, 2.0623e-02, 9.2142e-03],
          [2.5400e-02, 1.8609e-02, 1.8589e-02, 1.9757e-02, 1.0249e-02],
          [2.4326e-02, 1.8721e-02, 1.8344e-02, 1.8359e-02, 8.4784e-03],
          [2.0509e-02, 1.8473e-02, 1.8660e-02, 1.8610e-02, 1.7434e-02]]],
        [[[7.8086e-03, 7.8561e-03, 8.8707e-03, 9.2135e-03, 1.5700e-02],
          [4.0709e-03, 1.5007e-03, 9.7371e-04, 2.6451e-03, 1.1796e-02],
          [4.0597e-03, 1.0576e-03, 3.7934e-05, 3.0209e-03, 1.1533e-02],
          [2.0525e-02, 1.8343e-02, 1.9158e-02, 2.1699e-02, 2.4289e-02],
          [8.9953e-03, 4.8572e-03, 5.2793e-03, 5.5151e-03, 1.3169e-02]],
         [[3.5861e-02, 3.5688e-02, 3.6811e-02, 3.8637e-02, 4.2638e-02],
          [2.4290e-02, 2.3168e-02, 2.3838e-02, 2.7426e-02, 2.9898e-02],
          [2.4715e-02, 2.3647e-02, 2.3925e-02, 2.7261e-02, 2.9151e-02],
          [2.4732e-02, 2.3275e-02, 2.4562e-02, 2.7649e-02, 3.0020e-02],
          [3.3377e-02, 2.8456e-02, 2.8454e-02, 2.9429e-02, 2.7201e-02]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         ...,
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[2.4363e-02, 2.1627e-02, 2.2765e-02, 2.2517e-02, 1.4265e-02],
          [2.4903e-02, 1.9529e-02, 2.0428e-02, 2.0799e-02, 7.1960e-03],
          [2.5007e-02, 1.9522e-02, 1.9059e-02, 1.9194e-02, 7.2227e-03],
          [2.4361e-02, 1.9720e-02, 1.9328e-02, 1.9751e-02, 1.0804e-02],
          [2.0127e-02, 1.8053e-02, 1.7633e-02, 1.7571e-02, 1.8290e-02]]],
        [[[7.5830e-03, 7.1652e-03, 1.0041e-02, 8.8182e-03, 1.4745e-02],
          [3.5514e-03, 1.0312e-03, 3.0078e-03, 2.5746e-03, 1.0511e-02],
          [4.5348e-03, 1.9546e-03, 3.5442e-03, 3.1314e-03, 1.0873e-02],
          [1.9794e-02, 1.9100e-02, 1.9576e-02, 2.0367e-02, 2.0834e-02],
          [7.9060e-03, 5.2559e-03, 5.4114e-03, 5.1178e-03, 1.2210e-02]],
         [[3.3052e-02, 3.4514e-02, 3.8535e-02, 3.4895e-02, 4.4839e-02],
          [2.1757e-02, 2.2704e-02, 2.4889e-02, 2.1963e-02, 3.3251e-02],
          [2.1946e-02, 2.2207e-02, 2.5503e-02, 2.3153e-02, 3.3675e-02],
          [2.1172e-02, 2.2595e-02, 2.4572e-02, 2.2208e-02, 3.3074e-02],
          [3.1790e-02, 2.7745e-02, 2.8581e-02, 2.7984e-02, 2.7098e-02]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         ...,
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[2.3768e-02, 2.2313e-02, 2.1364e-02, 2.1129e-02, 1.2209e-02],
          [2.4703e-02, 1.8724e-02, 1.8991e-02, 1.9494e-02, 9.3238e-03],
          [2.3591e-02, 1.9448e-02, 1.9981e-02, 2.0466e-02, 8.1410e-03],
          [2.4244e-02, 1.7407e-02, 1.7749e-02, 1.9604e-02, 8.2285e-03],
          [2.0865e-02, 1.8469e-02, 1.8215e-02, 1.8655e-02, 1.6696e-02]]],
        ...,
        [[[7.4109e-03, 8.7876e-03, 6.6534e-03, 1.0581e-02, 1.3414e-02],
          [4.3728e-03, 2.4629e-03, 1.9493e-03, 3.9720e-03, 9.5779e-03],
          [3.3200e-03, 2.6886e-03, 3.5423e-03, 3.7783e-03, 9.5553e-03],
          [2.0494e-02, 2.1950e-02, 1.8071e-02, 2.2628e-02, 2.2500e-02],
          [9.0357e-03, 6.2226e-03, 5.0160e-03, 6.5017e-03, 1.2046e-02]],
         [[3.5808e-02, 3.6197e-02, 3.3437e-02, 3.9770e-02, 4.4540e-02],
          [2.4702e-02, 2.4465e-02, 2.2593e-02, 2.6102e-02, 3.3051e-02],
          [2.5085e-02, 2.5223e-02, 2.2986e-02, 2.5280e-02, 3.2905e-02],
          [2.4873e-02, 2.4470e-02, 2.1944e-02, 2.5198e-02, 3.2677e-02],
          [3.2723e-02, 2.8237e-02, 2.7737e-02, 2.9341e-02, 2.6199e-02]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         ...,
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[2.3607e-02, 2.1371e-02, 2.2110e-02, 2.1206e-02, 1.4077e-02],
          [2.6491e-02, 2.0709e-02, 2.0693e-02, 1.9943e-02, 1.0254e-02],
          [2.5534e-02, 1.9712e-02, 2.0496e-02, 2.0630e-02, 1.0120e-02],
          [2.5655e-02, 1.8997e-02, 1.8336e-02, 1.9135e-02, 9.7441e-03],
          [2.0942e-02, 1.8557e-02, 1.8635e-02, 1.8336e-02, 1.7344e-02]]],
        [[[7.0057e-03, 8.7662e-03, 8.1258e-03, 8.7400e-03, 1.3600e-02],
          [4.0816e-03, 2.7555e-03, 1.6819e-03, 3.3809e-03, 9.9450e-03],
          [4.2736e-03, 2.5950e-03, 1.8029e-03, 4.1992e-03, 9.8633e-03],
          [2.0669e-02, 2.1400e-02, 1.7765e-02, 2.2492e-02, 2.2598e-02],
          [8.3368e-03, 5.7955e-03, 5.0227e-03, 6.6958e-03, 1.2026e-02]],
         [[3.5062e-02, 3.5292e-02, 3.3689e-02, 3.7020e-02, 4.4760e-02],
          [2.3721e-02, 2.2727e-02, 2.1514e-02, 2.4404e-02, 3.2907e-02],
          [2.3561e-02, 2.2628e-02, 2.2466e-02, 2.5651e-02, 3.3430e-02],
          [2.2935e-02, 2.2388e-02, 2.2650e-02, 2.5321e-02, 3.2368e-02],
          [3.2543e-02, 2.7793e-02, 2.7572e-02, 2.8870e-02, 2.6359e-02]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         ...,
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[2.3615e-02, 2.0711e-02, 2.1332e-02, 1.9933e-02, 1.2652e-02],
          [2.5268e-02, 1.9121e-02, 1.9003e-02, 1.8747e-02, 8.7299e-03],
          [2.4995e-02, 1.9589e-02, 2.0092e-02, 2.0064e-02, 1.0234e-02],
          [2.4832e-02, 1.8601e-02, 1.8568e-02, 1.8928e-02, 1.0267e-02],
          [2.1131e-02, 1.8708e-02, 1.8195e-02, 1.8369e-02, 1.7747e-02]]],
        [[[7.5135e-03, 7.8907e-03, 7.4601e-03, 9.8845e-03, 1.4560e-02],
          [5.6675e-03, 2.5572e-03, 1.8359e-03, 3.0157e-03, 1.0152e-02],
          [5.4600e-03, 2.7453e-03, 7.1166e-04, 2.8446e-03, 1.0500e-02],
          [1.9758e-02, 1.9434e-02, 1.8667e-02, 2.3628e-02, 2.2300e-02],
          [9.5835e-03, 4.9773e-03, 5.1637e-03, 6.1613e-03, 1.2335e-02]],
         [[3.5533e-02, 3.5035e-02, 3.5712e-02, 3.7955e-02, 4.4194e-02],
          [2.7497e-02, 2.3741e-02, 2.3800e-02, 2.5919e-02, 3.2174e-02],
          [2.7088e-02, 2.3644e-02, 2.3908e-02, 2.5555e-02, 3.2101e-02],
          [2.4234e-02, 2.2878e-02, 2.4397e-02, 2.5447e-02, 3.1455e-02],
          [3.3668e-02, 2.8457e-02, 2.8266e-02, 2.8907e-02, 2.5918e-02]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         ...,
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],
         [[2.3846e-02, 2.0973e-02, 2.1632e-02, 2.1386e-02, 1.3417e-02],
          [2.6489e-02, 2.0531e-02, 2.1244e-02, 2.0425e-02, 9.1648e-03],
          [2.4635e-02, 2.0070e-02, 1.9861e-02, 1.9603e-02, 9.2679e-03],
          [2.4301e-02, 1.8310e-02, 1.9319e-02, 2.0172e-02, 9.2228e-03],
          [1.9925e-02, 1.8187e-02, 1.7907e-02, 1.8427e-02, 1.7527e-02]]]],
       grad_fn=<MaxPool2DWithIndicesBackward0>)
output:  torch.Size([128, 2])
Train Epoch 0 loss=nan acc=0.00
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.6014e-01, -1.8731e-01, -3.4774e-01,  ...,  9.3379e-02,
            1.4084e-01, -1.4225e-01],
          [-4.7063e-01, -2.6280e-01, -1.3942e-01,  ...,  1.7012e-01,
            2.8548e-01, -4.5698e-03],
          [-3.9325e-01, -1.4449e-01,  4.1799e-02,  ...,  1.6290e-01,
            1.6471e-01, -1.0027e-02],
          ...,
          [-7.8881e-01, -6.0229e-01, -1.5993e-01,  ...,  3.9205e-01,
            1.2525e-01, -4.1818e-01],
          [-7.4819e-01, -3.4425e-01, -2.6032e-02,  ...,  3.6249e-01,
            5.4769e-02, -3.9304e-01],
          [-7.0873e-01, -3.4713e-01,  1.0424e-01,  ...,  3.3362e-01,
            1.7137e-01, -1.8078e-01]]],
        [[[-5.5356e-01,  1.6345e-01,  6.4045e-01,  ..., -1.9962e-01,
           -1.6534e-01, -7.3843e-01],
          [-6.6767e-01, -1.7487e-01,  1.8656e-01,  ..., -6.7273e-02,
           -4.4991e-01, -9.8388e-01],
          [-5.5336e-01, -8.6600e-02, -7.3281e-02,  ..., -7.6856e-02,
           -4.6058e-01, -8.5150e-01],
          ...,
          [-7.8402e-01, -2.5674e-01,  3.7119e-01,  ..., -2.4251e-01,
           -1.3553e-01, -3.3801e-01],
          [-6.9421e-01, -1.0649e-01,  2.8069e-01,  ..., -7.6280e-02,
            1.0634e-02, -4.6829e-01],
          [-7.4626e-01, -1.3630e-01,  3.1445e-01,  ...,  1.0524e-01,
           -1.0320e-01, -5.7962e-01]]],
        [[[-6.9013e-01, -5.0320e-01, -4.4354e-01,  ..., -1.1992e-02,
           -7.1805e-02, -4.8731e-02],
          [-7.0799e-01, -7.6034e-01, -2.9616e-01,  ..., -3.1775e-02,
           -1.0986e-01, -2.7984e-01],
          [-5.4504e-01, -6.6825e-01, -4.1778e-01,  ..., -1.4787e-01,
           -1.6368e-01, -3.9659e-01],
          ...,
          [-5.8942e-01, -2.7592e-01, -2.4499e-01,  ...,  1.7208e-01,
            3.5208e-01,  2.2779e-01],
          [-7.6230e-01, -6.0658e-01, -5.9431e-01,  ...,  1.3854e-01,
            2.9228e-01,  3.9336e-01],
          [-6.7125e-01, -6.7641e-01, -6.6449e-01,  ...,  2.8202e-01,
            4.6346e-01,  4.4645e-01]]],
        ...,
        [[[-6.3812e-01,  6.6461e-02,  5.9147e-02,  ..., -2.2418e-02,
           -3.7520e-01, -7.3290e-01],
          [-6.3633e-01,  5.1694e-02, -7.7763e-03,  ..., -2.5033e-01,
           -4.0651e-01, -7.1043e-01],
          [-5.9932e-01, -1.4291e-02,  1.2910e-01,  ..., -3.3208e-01,
           -3.5323e-01, -6.3520e-01],
          ...,
          [-7.3502e-01, -1.7828e-01, -9.0936e-02,  ..., -2.2183e-01,
           -5.4641e-01, -8.4880e-01],
          [-9.7126e-01, -1.1680e-01, -1.1615e-01,  ..., -5.4713e-01,
           -6.9274e-01, -6.9101e-01],
          [-6.7638e-01, -2.6088e-02,  6.5490e-03,  ..., -3.8130e-02,
           -3.9124e-01, -7.9083e-01]]],
        [[[-2.0999e-01, -3.7256e-01, -2.6090e-01,  ...,  5.9538e-01,
            5.3102e-01,  3.2466e-01],
          [-1.2898e-01, -2.7569e-01, -4.4037e-01,  ...,  3.8220e-01,
            5.4526e-01,  2.3782e-01],
          [-2.4373e-01, -2.4661e-01,  7.5496e-03,  ...,  6.6097e-01,
            4.8066e-01,  2.5542e-01],
          ...,
          [-1.4522e-02, -1.9750e-01, -1.7111e-01,  ...,  7.5967e-01,
            5.8191e-01,  2.0882e-01],
          [-1.6038e-02,  1.9863e-02,  1.5117e-02,  ...,  8.5540e-01,
            7.7004e-01,  3.5824e-01],
          [-2.9701e-01, -1.8426e-01, -1.0588e-01,  ...,  7.3497e-01,
            6.8452e-01,  3.1546e-01]]],
        [[[-2.4747e-01, -1.7888e-01, -1.7951e-01,  ...,  7.5873e-01,
            3.9818e-01,  1.6147e-01],
          [-3.8406e-01, -1.4782e-01, -1.0532e-01,  ...,  6.1925e-01,
            3.0263e-01, -3.0732e-04],
          [-5.3844e-01, -1.7400e-01, -2.4566e-01,  ...,  5.7732e-01,
            5.0183e-01,  2.9113e-02],
          ...,
          [-6.6955e-01, -4.6073e-01, -3.5776e-01,  ...,  7.6923e-01,
            6.1132e-01, -2.1419e-01],
          [-4.6653e-01, -6.5680e-01, -3.2863e-01,  ...,  5.1148e-01,
            4.7218e-01, -1.6466e-01],
          [-3.6128e-01, -2.5217e-01, -1.1502e-01,  ...,  6.4655e-01,
            5.3618e-01, -6.6549e-02]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.4662e-01, -1.4808e-01, -3.0526e-01,  ..., -5.1852e-01,
           -5.5844e-01, -6.7035e-01],
          [-5.5292e-01, -2.6890e-01, -3.4255e-01,  ..., -6.0810e-01,
           -6.3989e-01, -6.2080e-01],
          [-5.0680e-01, -3.9658e-01, -2.6737e-01,  ..., -8.5788e-01,
           -8.0362e-01, -7.4084e-01],
          ...,
          [-3.6409e-01, -4.4766e-01, -4.5932e-01,  ..., -5.3412e-02,
            8.5940e-02, -2.8668e-01],
          [-3.1658e-01, -5.0196e-01, -3.4505e-01,  ...,  3.8119e-02,
            1.8418e-01,  3.0277e-02],
          [-3.7466e-01, -3.2345e-01, -2.2682e-01,  ..., -1.7874e-01,
           -2.6535e-02,  5.8567e-02]]],
        [[[-2.2861e-01, -2.2857e-01, -2.0866e-01,  ..., -5.6465e-01,
           -5.7844e-01, -4.0289e-01],
          [-3.8794e-01,  1.0682e-02, -1.0414e-01,  ..., -5.4380e-01,
           -5.7101e-01, -3.8221e-01],
          [-4.0383e-01, -4.4313e-02,  3.9432e-02,  ..., -4.6541e-01,
           -3.9803e-01, -4.9699e-01],
          ...,
          [-5.2686e-01, -5.1367e-01, -4.4538e-01,  ..., -3.7849e-01,
           -6.2162e-01, -6.7096e-01],
          [-4.9757e-01, -3.6312e-01, -5.2319e-01,  ..., -4.8531e-01,
           -5.8070e-01, -8.2865e-01],
          [-6.1362e-01, -4.2276e-01, -5.6942e-01,  ..., -5.4430e-01,
           -8.1838e-01, -9.8306e-01]]],
        [[[-4.7893e-01,  5.9977e-02,  3.2757e-01,  ..., -1.1388e-01,
           -1.5290e-01,  1.4710e-01],
          [ 1.1187e-02,  1.3867e-01,  1.4790e-02,  ...,  1.5167e-02,
            1.1296e-01,  5.7469e-02],
          [-8.3143e-04,  5.7835e-02, -4.1771e-02,  ...,  1.2714e-01,
            1.0353e-01, -1.3476e-02],
          ...,
          [-2.3020e-01, -2.9096e-01,  3.4963e-02,  ..., -3.1858e-02,
            4.3517e-02,  4.0741e-01],
          [-1.0634e-01, -2.4786e-01,  4.2267e-03,  ..., -2.7582e-02,
            1.3251e-01,  4.1786e-01],
          [ 4.0468e-03, -7.3890e-02,  3.9973e-03,  ..., -3.8758e-01,
            6.1871e-02,  4.9821e-01]]],
        ...,
        [[[-6.8836e-01, -7.0980e-01, -2.9163e-01,  ...,  9.4429e-01,
            5.9765e-01,  1.5207e-02],
          [-5.5901e-01, -7.4355e-01, -4.7877e-01,  ...,  9.3320e-01,
            6.0055e-01,  5.8821e-02],
          [-5.5665e-01, -8.9246e-01, -7.3598e-01,  ...,  9.3011e-01,
            6.4662e-01,  3.1661e-01],
          ...,
          [-2.8674e-01, -1.8147e-01, -6.0911e-01,  ...,  8.5868e-01,
            4.2296e-01, -1.0070e-02],
          [-2.9714e-01, -1.0026e-01, -3.5091e-01,  ...,  9.1692e-01,
            5.0800e-01, -6.8350e-02],
          [-4.1429e-01, -1.6057e-01, -4.2464e-01,  ...,  9.4228e-01,
            4.6331e-01, -5.4052e-02]]],
        [[[-7.4799e-01, -2.8033e-01, -1.7445e-01,  ...,  1.3966e-01,
            5.4573e-01,  5.1996e-01],
          [-5.5243e-01, -1.8523e-01, -2.5482e-01,  ..., -3.0618e-02,
            3.2300e-01,  3.6502e-01],
          [-5.2203e-01,  6.1253e-02, -3.5231e-01,  ...,  2.8594e-01,
            4.6830e-01,  6.4419e-01],
          ...,
          [-3.3938e-01,  4.2484e-01,  7.2270e-01,  ...,  4.5330e-01,
            5.9062e-01,  6.4748e-01],
          [-5.2168e-01,  2.8915e-01,  4.7051e-01,  ...,  4.9487e-01,
            3.7276e-01,  4.2498e-01],
          [-7.0626e-01, -1.3174e-01,  2.2676e-01,  ...,  1.4109e-01,
           -9.3139e-02,  2.1893e-01]]],
        [[[-1.0000e+00, -7.3374e-01, -3.4005e-01,  ..., -4.7685e-01,
           -3.3193e-01, -1.4083e-01],
          [-6.1895e-01, -4.6563e-01, -5.3352e-01,  ..., -4.0671e-01,
           -4.0434e-01, -2.5144e-01],
          [-6.0426e-01, -5.0938e-01, -3.7777e-01,  ..., -2.0111e-01,
           -1.4550e-01, -3.9215e-01],
          ...,
          [-5.7506e-01, -6.2112e-01, -8.6130e-01,  ..., -3.0745e-01,
           -8.0988e-02, -2.4351e-01],
          [-7.3872e-01, -5.8426e-01, -5.6042e-01,  ..., -3.4757e-01,
           -1.9519e-01, -3.0121e-01],
          [-8.3974e-01, -6.0212e-01, -4.7105e-01,  ..., -3.3255e-01,
           -3.5216e-01, -2.3790e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.8697e-01, -1.1521e-01,  2.6452e-01,  ...,  2.3192e-01,
            2.4605e-02,  4.2304e-02],
          [-2.6933e-01,  8.1080e-02,  3.3955e-01,  ...,  3.4203e-01,
            2.1780e-01,  1.1086e-01],
          [-2.7629e-01,  1.1809e-01,  1.9750e-01,  ...,  3.8396e-01,
            1.4907e-01, -1.0516e-02],
          ...,
          [-1.7101e-01,  1.6986e-01,  9.5069e-02,  ..., -3.0821e-02,
           -1.4658e-01, -4.1186e-02],
          [-1.8155e-01,  8.1992e-02, -1.1553e-01,  ...,  9.3334e-02,
           -1.1220e-01, -2.9241e-02],
          [-1.6668e-01,  1.6979e-01,  2.6753e-01,  ..., -4.5719e-02,
           -1.5527e-01, -5.9272e-02]]],
        [[[ 3.8858e-01,  6.4642e-01,  2.8797e-01,  ...,  3.7575e-02,
            1.0707e-01, -4.0378e-02],
          [ 4.5857e-01,  6.6288e-01,  5.6774e-01,  ..., -2.1978e-01,
           -5.5239e-02, -1.5462e-01],
          [ 5.0469e-01,  5.6625e-01,  6.2209e-01,  ..., -3.3025e-01,
           -1.7636e-01, -1.7162e-01],
          ...,
          [ 5.9698e-01,  4.7643e-01,  3.5593e-01,  ...,  1.5810e-01,
           -1.4888e-01, -2.8299e-01],
          [ 6.1554e-01,  6.1835e-01,  3.8784e-01,  ...,  1.3412e-02,
           -2.8532e-01, -4.6676e-01],
          [ 4.0169e-01,  5.4380e-01,  5.0279e-01,  ..., -2.8751e-01,
           -3.2121e-01, -3.5236e-01]]],
        [[[-4.1773e-01, -3.9379e-02, -1.0811e-02,  ..., -2.2802e-01,
           -1.5179e-01,  9.0465e-02],
          [-3.2510e-01, -7.8543e-02, -3.9413e-01,  ..., -1.2605e-01,
           -5.9961e-03,  1.0216e-01],
          [-2.5743e-01, -1.7697e-01, -3.5402e-01,  ..., -3.7262e-01,
           -3.9264e-01, -1.0029e-01],
          ...,
          [-1.0444e-01,  2.1046e-01,  4.7769e-01,  ...,  3.8958e-01,
            3.9383e-01,  4.7679e-01],
          [-3.9627e-02,  9.3259e-02,  4.3797e-01,  ...,  2.6052e-01,
            5.2944e-01,  4.0454e-01],
          [-8.1508e-02, -3.0226e-01,  1.7711e-01,  ...,  1.6088e-03,
            3.6676e-01,  3.7870e-01]]],
        ...,
        [[[-5.6266e-01, -4.7760e-01, -8.2202e-02,  ..., -3.8969e-01,
           -2.5220e-02, -3.2223e-02],
          [-7.7417e-01, -3.3295e-01,  1.9575e-01,  ..., -3.1074e-01,
           -8.1199e-02, -9.1666e-02],
          [-5.6147e-01, -1.1572e-01,  1.1432e-01,  ..., -4.6366e-01,
           -3.5767e-01, -3.7247e-01],
          ...,
          [-6.0281e-01, -2.0013e-01,  6.9977e-02,  ..., -6.3537e-01,
           -4.4380e-01, -1.5833e-01],
          [-6.2783e-01, -1.9848e-01, -2.2493e-01,  ..., -5.0580e-01,
           -3.9823e-01, -2.0992e-01],
          [-2.4393e-01, -7.5220e-02, -1.4867e-01,  ..., -4.4776e-01,
           -3.2015e-01, -1.5920e-01]]],
        [[[-4.9705e-01,  1.2176e-01,  4.0845e-01,  ...,  3.2577e-01,
            9.2470e-02,  3.6896e-01],
          [-6.8998e-01, -2.9121e-02,  2.0776e-01,  ..., -6.9024e-02,
           -9.7637e-02,  3.5794e-01],
          [-6.9781e-01, -1.6974e-01,  2.8434e-01,  ..., -2.5010e-02,
           -2.6028e-01,  3.6645e-01],
          ...,
          [-9.7684e-01,  9.2304e-04,  4.6349e-01,  ...,  7.4893e-03,
           -3.8967e-01,  3.6098e-01],
          [-5.9284e-01, -1.8897e-01,  2.7149e-01,  ..., -8.7791e-02,
           -5.0854e-01,  3.7273e-01],
          [-4.1250e-01, -1.5960e-01, -1.3498e-01,  ..., -5.3710e-01,
           -1.8921e-01,  3.8716e-01]]],
        [[[-5.8798e-01, -3.3278e-01,  1.3755e-01,  ..., -9.6693e-02,
           -2.9246e-01, -7.9092e-01],
          [-5.6240e-01, -3.0178e-01, -7.1097e-02,  ...,  9.4679e-02,
           -5.5441e-01, -9.1415e-01],
          [-6.4571e-01, -1.2454e-01,  3.7815e-02,  ...,  9.7035e-02,
           -5.5120e-01, -8.2716e-01],
          ...,
          [-6.1175e-01, -2.6586e-01,  1.0165e-01,  ...,  1.9192e-01,
           -2.3340e-01, -6.7174e-01],
          [-5.1857e-01,  4.6812e-02,  4.2666e-03,  ...,  1.5236e-01,
           -2.7724e-02, -5.9381e-01],
          [-5.6962e-01,  1.1793e-01,  1.5162e-01,  ...,  1.5422e-01,
            9.9937e-03, -7.2312e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-6.1850e-01, -4.0158e-01, -3.3093e-01,  ..., -3.5113e-01,
           -4.7355e-01, -5.3812e-01],
          [-3.0940e-01, -1.7254e-01, -2.5814e-01,  ..., -5.0845e-01,
           -5.6943e-01, -5.8833e-01],
          [-1.8797e-01, -1.1358e-01, -2.2958e-01,  ..., -6.6975e-01,
           -6.4272e-01, -7.4871e-01],
          ...,
          [-4.0990e-01, -4.0148e-01, -3.4564e-01,  ..., -7.2045e-01,
           -6.4986e-01, -5.1542e-01],
          [-3.8136e-01, -2.7679e-01, -5.3254e-01,  ..., -5.7582e-01,
           -5.5047e-01, -6.6200e-01],
          [-6.8040e-01, -3.4566e-01, -2.2836e-01,  ..., -5.2012e-01,
           -5.2566e-01, -6.5865e-01]]],
        [[[-6.1447e-01, -1.2893e-01,  8.3224e-02,  ...,  3.0545e-02,
            8.9014e-02, -1.2192e-01],
          [-8.1518e-01, -3.2209e-01,  5.5951e-02,  ..., -6.0187e-02,
            1.2543e-02, -2.1510e-01],
          [-1.0000e+00, -1.9316e-01,  1.6116e-01,  ..., -1.9768e-01,
           -2.0008e-01, -2.1448e-01],
          ...,
          [-4.6176e-01,  1.2186e-01,  6.9614e-02,  ..., -3.5660e-01,
           -2.1348e-01, -1.7605e-01],
          [-4.7388e-01, -2.3979e-03, -9.0474e-02,  ..., -3.7083e-01,
           -2.1697e-01, -1.3275e-01],
          [-6.1859e-01, -2.4895e-01, -1.4472e-02,  ..., -1.0133e-01,
           -2.9947e-01, -2.6388e-01]]],
        [[[-3.6181e-01, -1.6590e-01, -3.3025e-01,  ..., -4.1348e-04,
            6.2404e-02,  6.7472e-05],
          [-7.0515e-01, -2.2072e-01, -2.7947e-01,  ..., -3.3062e-01,
           -1.7195e-01, -1.8305e-02],
          [-4.1453e-01, -1.4826e-01, -3.6475e-01,  ..., -2.6946e-02,
           -6.6919e-02, -8.3236e-02],
          ...,
          [ 7.4616e-02, -4.4367e-01, -5.5459e-01,  ...,  5.4148e-01,
           -8.9710e-03,  1.5300e-01],
          [ 5.0435e-02, -1.8553e-01, -4.0615e-01,  ...,  5.7196e-01,
            3.5199e-01, -1.5290e-01],
          [-4.1700e-01, -9.1893e-02, -3.5618e-01,  ...,  7.4093e-01,
            4.8897e-01, -2.0312e-02]]],
        ...,
        [[[-2.2670e-01,  2.7301e-01,  1.9486e-01,  ..., -4.7225e-02,
            4.3111e-02, -2.0238e-01],
          [-4.2866e-01, -2.9711e-02,  5.4794e-02,  ..., -9.7128e-02,
           -8.1130e-02, -3.2041e-01],
          [-8.0300e-01, -4.8892e-02,  1.3877e-01,  ..., -2.0412e-02,
           -3.8415e-01, -5.2108e-01],
          ...,
          [-3.2271e-01,  1.5030e-01,  4.5274e-01,  ..., -1.3104e-01,
           -3.5501e-01, -8.9783e-01],
          [-3.3115e-01,  7.5727e-02,  4.4511e-01,  ..., -1.9262e-01,
           -3.3974e-01, -6.1626e-01],
          [-3.4553e-01,  2.4167e-01,  4.8444e-01,  ..., -3.3481e-01,
           -1.7844e-01, -3.8097e-01]]],
        [[[-1.7218e-02, -9.8322e-02, -2.0346e-01,  ..., -6.2745e-01,
           -6.3287e-01, -6.0507e-01],
          [-3.2096e-02, -1.6264e-01, -2.5973e-01,  ..., -6.8020e-01,
           -8.6129e-01, -6.2164e-01],
          [-1.4217e-01, -1.3711e-01, -4.3156e-01,  ..., -4.7845e-01,
           -5.8108e-01, -6.1914e-01],
          ...,
          [-2.8105e-01, -2.8288e-01, -2.9722e-01,  ..., -6.1039e-01,
           -6.5149e-01, -4.9229e-01],
          [-1.9126e-01, -2.6605e-01, -2.1471e-01,  ..., -7.4542e-01,
           -7.3672e-01, -5.0314e-01],
          [-7.0946e-02, -8.9756e-02, -7.7931e-02,  ..., -6.7409e-01,
           -8.3383e-01, -4.7699e-01]]],
        [[[-5.6419e-01, -5.0317e-01, -3.5019e-01,  ..., -2.8716e-01,
           -1.3154e-01, -3.5081e-01],
          [-4.1844e-01, -4.6510e-01, -5.0500e-01,  ..., -6.2959e-01,
           -4.8495e-01, -4.2111e-01],
          [-6.0794e-01, -4.8485e-01, -2.8506e-01,  ..., -7.7640e-01,
           -6.2347e-01, -3.9807e-01],
          ...,
          [-3.3738e-01, -1.8529e-01, -1.6275e-01,  ..., -3.3421e-01,
           -4.9287e-01, -3.5865e-01],
          [-1.3361e-01, -2.4312e-01, -4.8623e-01,  ..., -2.8189e-01,
           -5.2133e-01, -3.4745e-01],
          [-2.4832e-01, -3.9599e-01, -5.9426e-01,  ..., -3.7800e-01,
           -3.9210e-01, -3.9851e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 1.6555e-01,  1.2708e-01, -1.8352e-01,  ...,  2.0043e-02,
            1.3151e-01,  1.8650e-02],
          [-2.8915e-02,  5.8375e-02,  9.8114e-02,  ..., -2.5825e-01,
            4.8066e-02, -1.0325e-01],
          [-2.2147e-03,  5.4738e-02,  1.9462e-03,  ..., -7.0366e-02,
           -1.4215e-01, -4.5709e-02],
          ...,
          [-6.3554e-02,  3.0064e-01,  1.3150e-01,  ..., -2.7392e-01,
           -4.3294e-01, -3.8735e-01],
          [-1.4424e-01,  2.7475e-01,  2.2499e-01,  ...,  7.8608e-02,
            3.4836e-02, -1.2100e-01],
          [-2.4690e-01,  3.9475e-02, -1.9018e-01,  ...,  2.5338e-01,
            9.1138e-02, -2.4886e-01]]],
        [[[-4.6771e-01, -3.0982e-01, -1.1721e-01,  ...,  1.2727e-01,
            1.5062e-01, -7.9681e-02],
          [ 1.2831e-01, -1.1304e-01, -3.9255e-01,  ..., -2.1268e-01,
            3.5754e-02,  6.4080e-02],
          [ 3.5479e-01,  2.1660e-01, -3.0991e-01,  ..., -6.6024e-01,
           -3.5949e-01, -1.8248e-01],
          ...,
          [-3.8384e-01, -5.8448e-02,  4.2969e-01,  ..., -3.1937e-01,
            3.4474e-02, -1.1196e-01],
          [-3.2587e-02, -1.4713e-01,  3.1602e-01,  ..., -5.4626e-01,
           -1.4421e-01,  4.2776e-02],
          [-1.8417e-01, -1.2569e-01, -1.0252e-01,  ..., -1.2374e-01,
           -1.2746e-01, -3.6665e-02]]],
        [[[-4.9706e-01, -1.3718e-02, -7.2402e-02,  ..., -2.9278e-02,
           -2.0325e-01, -6.8094e-01],
          [-4.4419e-01,  6.6491e-02,  9.2255e-02,  ..., -2.3903e-01,
           -3.1866e-01, -6.0925e-01],
          [-5.8793e-01,  2.5403e-02,  2.5778e-01,  ..., -8.9723e-02,
           -5.7932e-01, -7.1125e-01],
          ...,
          [-6.2253e-01,  1.3267e-01,  3.7892e-01,  ..., -1.9893e-01,
           -2.2910e-01, -7.0535e-01],
          [-4.8612e-01,  1.2054e-01,  2.0565e-01,  ..., -2.1035e-01,
           -3.1192e-01, -4.0615e-01],
          [-4.1111e-01, -4.1327e-02,  3.1197e-04,  ..., -2.9975e-01,
           -2.8070e-01, -7.3472e-01]]],
        ...,
        [[[-6.9342e-01, -4.1996e-01, -2.2895e-01,  ..., -1.8429e-01,
           -1.6200e-02,  1.7896e-02],
          [-1.0000e+00, -3.9175e-01, -4.8999e-02,  ..., -1.4264e-01,
           -1.3358e-01,  8.7747e-02],
          [-6.0554e-01,  9.2908e-03,  2.9111e-01,  ...,  1.5352e-02,
           -3.6415e-01, -3.8957e-02],
          ...,
          [-6.3750e-01, -2.0196e-01,  8.8961e-02,  ..., -4.9989e-02,
           -1.4873e-01,  3.8660e-03],
          [-6.7588e-01, -1.0700e-01, -3.5485e-02,  ..., -1.8860e-01,
           -5.7613e-02, -2.4938e-02],
          [-7.3729e-01,  6.0325e-02,  1.4157e-01,  ..., -7.0193e-02,
           -2.5601e-01, -3.5317e-02]]],
        [[[-2.7383e-01, -6.5874e-02,  7.0011e-02,  ...,  1.9283e-01,
           -2.2072e-01, -2.7680e-01],
          [-2.5693e-01, -9.1932e-02, -1.2451e-02,  ...,  1.6346e-01,
           -8.3244e-02, -3.4738e-01],
          [-4.9718e-02,  1.4808e-01,  1.8891e-01,  ...,  6.6021e-02,
           -1.9724e-01, -5.1762e-01],
          ...,
          [-7.2980e-02, -7.7635e-02, -1.0533e-01,  ...,  1.2396e-01,
           -1.9194e-01, -3.0786e-01],
          [ 6.5050e-02, -1.3330e-01, -1.6118e-01,  ...,  9.7634e-02,
           -1.3302e-01, -3.3972e-01],
          [-7.7883e-03, -2.0300e-01, -1.8734e-01,  ...,  1.9175e-01,
           -1.1535e-01, -3.7160e-01]]],
        [[[-5.1975e-01,  9.1168e-02,  2.2584e-01,  ..., -1.6881e-01,
           -2.9814e-01,  8.1122e-02],
          [-8.3874e-01,  6.5858e-02,  2.4000e-01,  ...,  1.5628e-01,
           -9.2050e-02,  1.1529e-01],
          [-5.6741e-01, -7.3452e-02,  6.3340e-02,  ...,  2.1602e-01,
            4.5985e-02,  1.2796e-01],
          ...,
          [-5.2904e-01, -3.7611e-02, -8.1518e-02,  ..., -1.4791e-01,
           -1.7859e-01,  1.1898e-01],
          [-4.0684e-01, -8.6633e-02,  4.4713e-02,  ..., -1.3725e-01,
           -1.2813e-01,  1.2039e-01],
          [-4.0257e-01,  1.2395e-01,  9.8035e-02,  ...,  2.0388e-01,
            2.2941e-02,  8.4800e-02]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3163, -0.0117, -0.0427,  ..., -0.6112, -0.3961, -0.6095],
          [-0.5378, -0.1695,  0.0254,  ..., -0.3722, -0.4340, -0.5724],
          [-0.3369, -0.0065,  0.2656,  ..., -0.1764, -0.2763, -0.7882],
          ...,
          [-0.6364, -0.1669, -0.2231,  ...,  0.1813, -0.1274, -0.6019],
          [-0.2610,  0.0876, -0.0227,  ..., -0.0176, -0.1219, -0.6331],
          [-0.2037,  0.1656,  0.0308,  ..., -0.3394, -0.2268, -0.4914]]],
        [[[-0.7235, -0.3795,  0.0867,  ..., -0.3082, -0.2300, -0.4960],
          [-0.6454, -0.3726, -0.0416,  ..., -0.2524, -0.3683, -0.6751],
          [-0.8016, -0.2825, -0.1052,  ..., -0.0971, -0.4790, -1.0000],
          ...,
          [-0.3513, -0.1893, -0.0839,  ..., -0.0326, -0.3514, -0.5506],
          [-0.5633, -0.1239,  0.1029,  ..., -0.0520, -0.4028, -0.5310],
          [-0.5497, -0.1124,  0.0675,  ..., -0.1362, -0.5050, -0.8700]]],
        [[[ 0.5531,  0.6774,  0.7203,  ..., -0.2461,  0.2592,  0.3267],
          [ 0.5321,  0.7089,  0.8540,  ..., -0.0755,  0.2112,  0.2636],
          [-0.0142,  0.2227,  0.6000,  ..., -0.1750, -0.2133, -0.0431],
          ...,
          [-0.2572, -0.1526, -0.4646,  ...,  0.1121,  0.0544, -0.3053],
          [-0.2351, -0.2607, -0.4699,  ...,  0.0014,  0.1352, -0.0186],
          [-0.3615, -0.5219, -0.6588,  ..., -0.1577, -0.0982,  0.0219]]],
        ...,
        [[[-0.4685,  0.1743,  0.2662,  ...,  0.4609,  0.6084,  0.4436],
          [-0.4898,  0.0264,  0.2223,  ...,  0.4605,  0.4541,  0.3534],
          [-0.9495, -0.4074, -0.0158,  ...,  0.3951,  0.5967,  0.3856],
          ...,
          [-0.2796,  0.0835,  0.4769,  ...,  0.5285,  0.6641,  0.4020],
          [-0.3452,  0.1689,  0.2649,  ...,  0.4574,  0.4115,  0.1272],
          [-0.3093,  0.1782,  0.1098,  ...,  0.4612,  0.6403,  0.4018]]],
        [[[ 0.0550,  0.0487,  0.0075,  ..., -0.3307, -0.5231, -0.5604],
          [ 0.2185,  0.2943,  0.2077,  ..., -0.2470, -0.4360, -0.3776],
          [ 0.1788,  0.1437,  0.2292,  ..., -0.1896, -0.3381, -0.3895],
          ...,
          [ 0.1963, -0.0226,  0.0806,  ..., -0.3168, -0.0373,  0.2207],
          [ 0.0219, -0.1372,  0.0402,  ..., -0.3783,  0.0362,  0.2596],
          [-0.1699, -0.0434,  0.0902,  ..., -0.0533,  0.2551,  0.1412]]],
        [[[-0.5280,  0.2511,  0.4571,  ...,  0.0373, -0.1831, -0.6148],
          [-0.5588,  0.0106,  0.2697,  ..., -0.1062, -0.1064, -0.5510],
          [-0.7250, -0.0255,  0.1926,  ...,  0.0849, -0.0094, -0.6132],
          ...,
          [-0.6618,  0.2327,  0.4147,  ..., -0.1104,  0.1053, -0.1956],
          [-0.6810,  0.1375,  0.3187,  ...,  0.0934, -0.0126, -0.2039],
          [-0.4718,  0.0204,  0.3096,  ...,  0.0304, -0.0526, -0.1936]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2125, -0.2313,  0.0363,  ...,  0.0636,  0.1137,  0.0846],
          [-0.2951, -0.3165, -0.2553,  ...,  0.2146,  0.2408,  0.1784],
          [-0.2533, -0.2525, -0.2066,  ...,  0.1472,  0.3359,  0.2591],
          ...,
          [-0.2055, -0.1661, -0.0738,  ...,  0.0200,  0.1057, -0.0277],
          [-0.2107, -0.1291,  0.1128,  ...,  0.2082,  0.1776,  0.0660],
          [-0.0344,  0.0361,  0.0849,  ...,  0.1240,  0.2813,  0.0207]]],
        [[[-0.2461, -0.3924,  0.1725,  ...,  0.2680, -0.2755, -0.5760],
          [-0.0631, -0.3943, -0.1692,  ..., -0.2312, -0.2769, -0.6727],
          [-0.1059, -0.3140,  0.0344,  ..., -0.1439, -0.2732, -0.3914],
          ...,
          [-0.4614, -0.2273, -0.1061,  ..., -0.5227, -0.2777, -0.0048],
          [-0.3922, -0.0303, -0.1384,  ..., -0.1958, -0.2899, -0.1583],
          [-0.3272, -0.2295, -0.2109,  ..., -0.1748, -0.1298, -0.2003]]],
        [[[-0.6960, -0.3834, -0.2639,  ..., -0.3308, -0.2042, -0.0813],
          [-0.7176, -0.2897, -0.2738,  ..., -0.1137, -0.3470, -0.4828],
          [-1.0000, -0.4106, -0.3567,  ..., -0.1613, -0.4677, -0.6062],
          ...,
          [-0.5097, -0.1078, -0.0040,  ..., -0.0436,  0.0310,  0.3585],
          [-0.3734, -0.3149, -0.4984,  ..., -0.5603, -0.0432,  0.3278],
          [-0.3866, -0.5371, -0.3959,  ..., -0.5961,  0.0244,  0.2470]]],
        ...,
        [[[-0.5351,  0.0721,  0.0710,  ...,  0.3437,  0.0895, -0.4555],
          [-0.3352,  0.1927,  0.0628,  ...,  0.0097, -0.0411, -0.5811],
          [-0.4073,  0.2367,  0.3986,  ..., -0.3949, -0.3003, -0.5449],
          ...,
          [-0.5710, -0.3772,  0.1612,  ..., -0.0386,  0.0671, -0.2147],
          [-0.4401, -0.1343,  0.3552,  ..., -0.2265, -0.2653, -0.4442],
          [-0.4109, -0.0280,  0.4422,  ..., -0.0267, -0.4564, -0.4269]]],
        [[[-0.2059, -0.1286,  0.0344,  ..., -0.5848, -0.6573, -0.1497],
          [-0.0685, -0.3422,  0.1162,  ..., -0.8475, -0.4831, -0.0437],
          [ 0.1030, -0.1928,  0.2341,  ..., -0.5802, -0.5559, -0.0261],
          ...,
          [ 0.1504, -0.0692,  0.0360,  ..., -0.3704, -0.4803,  0.0688],
          [ 0.1940,  0.1328, -0.2086,  ..., -0.3304, -0.5423,  0.0459],
          [-0.0767,  0.0295, -0.0361,  ..., -0.3866, -0.4150,  0.0908]]],
        [[[ 0.1422,  0.1949,  0.2329,  ..., -0.5621, -0.0672, -0.2118],
          [-0.0605, -0.0037,  0.0439,  ..., -0.3718,  0.0128, -0.0033],
          [-0.2693, -0.1600, -0.2618,  ..., -0.5161, -0.2394, -0.0478],
          ...,
          [-0.0611, -0.0043,  0.2106,  ..., -0.6776, -0.8762, -0.5339],
          [ 0.0330, -0.0246,  0.1762,  ..., -0.8250, -0.6232, -0.4056],
          [-0.1528, -0.2767, -0.0601,  ..., -0.8635, -0.7008, -0.3397]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.0970,  0.0856,  0.0205,  ..., -0.3003, -0.4333, -0.4297],
          [-0.0217,  0.1612,  0.0632,  ..., -0.4531, -0.5277, -0.2927],
          [ 0.0165,  0.0159,  0.0214,  ..., -0.6591, -0.4221, -0.2789],
          ...,
          [-0.0941,  0.0042, -0.1919,  ..., -0.4923, -0.6323, -0.6600],
          [-0.1492, -0.0237, -0.1915,  ..., -0.3327, -0.5158, -0.4509],
          [-0.2648, -0.0859, -0.1510,  ..., -0.3114, -0.6111, -0.8462]]],
        [[[-0.2705,  0.2189,  0.3421,  ...,  0.2120, -0.1082, -0.5551],
          [-0.1231,  0.4695,  0.6496,  ...,  0.0559, -0.0484, -0.5019],
          [-0.2714,  0.3809,  0.6697,  ...,  0.1917, -0.0139, -0.4833],
          ...,
          [-0.4402,  0.1455,  0.4711,  ..., -0.0280,  0.0687, -0.4618],
          [-0.2667,  0.1695,  0.2556,  ...,  0.0894,  0.0221, -0.5674],
          [-0.1676,  0.4271,  0.2887,  ...,  0.1424, -0.0066, -0.4760]]],
        [[[-0.5370, -0.1835, -0.0657,  ..., -0.3831, -0.5572, -0.1215],
          [-0.5292, -0.1455, -0.1224,  ..., -0.2401, -0.4507, -0.1207],
          [-0.4039, -0.0030, -0.0845,  ..., -0.1482, -0.4119, -0.1443],
          ...,
          [-0.6047, -0.2737, -0.0773,  ..., -0.2250, -0.3169, -0.1432],
          [-0.5071, -0.2409, -0.0017,  ..., -0.1991, -0.3464, -0.1076],
          [-0.3533, -0.1047, -0.0722,  ..., -0.0358, -0.3780, -0.1281]]],
        ...,
        [[[-0.4166, -0.2674, -0.2743,  ..., -0.1421, -0.2586, -0.5112],
          [-0.4421, -0.2350, -0.1298,  ..., -0.1605, -0.3560, -0.6114],
          [-0.2948,  0.0761,  0.2170,  ..., -0.2382, -0.4071, -0.8326],
          ...,
          [-0.2899,  0.1413,  0.0405,  ..., -0.3569, -0.5926, -0.7138],
          [-0.2905,  0.0701, -0.1497,  ..., -0.1689, -0.3999, -0.5689],
          [-0.4574,  0.0532, -0.0779,  ..., -0.2775, -0.4310, -0.6600]]],
        [[[-0.4728, -0.0702,  0.3821,  ..., -0.0649, -0.4333, -0.3754],
          [-0.6580, -0.0014,  0.3047,  ...,  0.0380, -0.0673, -0.2381],
          [-0.6449,  0.1214,  0.1829,  ...,  0.2842,  0.0577, -0.2357],
          ...,
          [-0.3541,  0.0078,  0.1600,  ...,  0.1323, -0.3019, -0.2389],
          [-0.5315, -0.4931, -0.0982,  ..., -0.0537, -0.3428, -0.1579],
          [-0.6484, -0.3517,  0.1338,  ...,  0.3295,  0.0309, -0.1605]]],
        [[[-0.1272, -0.3833, -0.4278,  ..., -0.0762,  0.1464,  0.2298],
          [-0.3803, -0.4299, -0.5112,  ...,  0.0017, -0.0682,  0.1507],
          [-0.3477, -0.3806, -0.3858,  ..., -0.1625, -0.0603, -0.0256],
          ...,
          [-0.2313, -0.1262, -0.2098,  ..., -0.7325, -0.6248, -0.6046],
          [-0.5666, -0.3832, -0.4599,  ..., -0.6580, -0.4458, -0.2318],
          [-0.3829, -0.4259, -0.6068,  ..., -0.4761, -0.0525,  0.0453]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.0538, -0.0254,  0.0820,  ..., -0.6745, -0.7484, -0.5660],
          [ 0.0934, -0.0130,  0.0672,  ..., -0.7240, -0.9035, -0.8205],
          [-0.2238, -0.1982, -0.0287,  ..., -0.5686, -0.4591, -0.6447],
          ...,
          [-0.0442, -0.1271, -0.5996,  ..., -0.6234, -0.5702, -0.6292],
          [ 0.0114,  0.0359, -0.1799,  ..., -0.5053, -0.7617, -1.0000],
          [-0.0660, -0.0673, -0.1203,  ..., -0.5202, -0.5987, -0.8737]]],
        [[[-0.1049, -0.1465,  0.2641,  ..., -0.8170, -0.6532, -0.0918],
          [-0.0580, -0.1031,  0.2210,  ..., -0.5488, -0.3742, -0.0407],
          [-0.2947,  0.1020,  0.0583,  ..., -0.4332, -0.4306, -0.0430],
          ...,
          [ 0.0202,  0.1925,  0.1421,  ..., -0.2584, -0.4727, -0.1526],
          [ 0.0098,  0.0082, -0.1481,  ..., -0.2470,  0.0808,  0.0050],
          [ 0.1810,  0.0921, -0.0916,  ...,  0.0013,  0.3410,  0.0214]]],
        [[[-0.3481,  0.0780,  0.1399,  ..., -0.0862, -0.0970, -0.2967],
          [-0.3756, -0.0137,  0.1866,  ..., -0.2235, -0.1144, -0.2402],
          [-0.3370,  0.1758,  0.3042,  ...,  0.0690,  0.0126, -0.1396],
          ...,
          [-0.7308,  0.0799,  0.3924,  ..., -0.2004, -0.0456, -0.4051],
          [-0.5219, -0.0160,  0.3612,  ..., -0.1191,  0.0563, -0.2872],
          [-0.7364,  0.1060,  0.2167,  ...,  0.0223, -0.0283, -0.2479]]],
        ...,
        [[[-0.3714, -0.3219, -0.3367,  ..., -0.4084, -0.2962, -0.4744],
          [-0.4540, -0.3439, -0.2104,  ..., -0.3022, -0.4999, -0.5332],
          [-0.3279, -0.4256, -0.4076,  ..., -0.0170, -0.0784, -0.4842],
          ...,
          [-0.6412, -0.4937, -0.1449,  ..., -0.7495, -0.7244, -0.7001],
          [-0.6964, -0.3730, -0.0981,  ..., -0.6992, -0.8977, -0.8860],
          [-0.5441, -0.3835, -0.2618,  ..., -0.5259, -0.7342, -0.9980]]],
        [[[-0.0206,  0.1373, -0.1927,  ..., -0.2057, -0.4815, -0.5609],
          [ 0.2244,  0.2468,  0.1789,  ..., -0.2315, -0.2720, -0.1889],
          [ 0.0669, -0.1996,  0.2587,  ..., -0.2933, -0.2992, -0.1483],
          ...,
          [ 0.4966,  0.4516,  0.5474,  ..., -0.2575,  0.0561, -0.2701],
          [ 0.1774,  0.1666,  0.3456,  ..., -0.4283,  0.0026, -0.0753],
          [-0.1125,  0.1551,  0.3142,  ..., -0.6936, -0.2050, -0.1424]]],
        [[[-0.4719, -0.1149,  0.0907,  ..., -0.3287, -0.5743, -0.4900],
          [-0.4246,  0.0357,  0.1214,  ..., -0.2462, -0.3883, -0.6801],
          [-0.4978,  0.0506,  0.0826,  ..., -0.1658, -0.1047, -0.4136],
          ...,
          [-0.6489, -0.0917,  0.1644,  ..., -0.2624, -0.3011, -0.4932],
          [-0.5964, -0.1742,  0.2048,  ..., -0.2214, -0.3503, -0.3873],
          [-0.6672, -0.0156,  0.3195,  ..., -0.0704, -0.1086, -0.3692]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 2.3146e-01,  4.0139e-01,  2.0421e-01,  ..., -4.8403e-01,
            1.3191e-01,  2.9037e-01],
          [ 1.7253e-01,  3.3632e-01, -8.4519e-02,  ..., -5.4609e-01,
            1.6422e-01,  3.0361e-01],
          [ 1.5802e-01,  2.7154e-01, -1.0364e-01,  ..., -3.5360e-01,
            1.1812e-02,  1.9210e-01],
          ...,
          [-3.2718e-01, -7.4777e-03, -9.8791e-02,  ..., -5.1244e-01,
           -5.5399e-01, -3.5196e-01],
          [-4.0056e-02,  5.1351e-02, -2.3535e-01,  ..., -5.3224e-01,
           -2.5796e-01, -2.0150e-01],
          [ 9.1876e-03,  3.2382e-02, -4.4447e-02,  ..., -4.4810e-01,
           -3.0911e-01, -2.3540e-01]]],
        [[[-5.5307e-02, -2.0849e-01, -1.0473e-01,  ..., -3.8740e-01,
           -7.6857e-01, -8.3703e-01],
          [-6.1137e-02, -1.2931e-01, -1.8183e-01,  ..., -3.2857e-01,
           -4.0827e-01, -6.0698e-01],
          [-2.0440e-01, -1.7485e-01, -1.6715e-01,  ..., -3.5015e-01,
           -4.1078e-01, -7.0138e-01],
          ...,
          [-1.7876e-01, -1.0661e-01, -1.1763e-01,  ..., -3.5241e-01,
           -4.2563e-01, -7.6158e-01],
          [-2.5119e-01, -1.7773e-01, -1.6874e-01,  ..., -3.8882e-01,
           -4.0424e-01, -5.6509e-01],
          [-1.9974e-01, -2.9092e-01, -1.2947e-01,  ..., -2.6595e-01,
           -4.5817e-01, -5.8670e-01]]],
        [[[-1.8627e-01, -7.6696e-02, -7.1645e-02,  ..., -6.9619e-02,
            3.1933e-01,  2.5639e-02],
          [-7.4736e-01, -4.6621e-01, -1.1774e-01,  ...,  1.0281e-01,
            2.9945e-01,  2.1066e-01],
          [-7.6543e-01, -7.4286e-01, -3.0877e-01,  ...,  1.8294e-01,
            3.2350e-01,  4.2588e-01],
          ...,
          [-3.3621e-01, -1.2960e-01,  1.3070e-02,  ..., -4.8492e-01,
           -6.8003e-01, -9.5493e-01],
          [-1.9332e-01, -3.0610e-01, -3.5656e-01,  ..., -4.6584e-01,
           -4.6775e-01, -9.7291e-01],
          [-8.6825e-02, -3.2107e-01, -6.0190e-02,  ..., -1.8205e-01,
           -3.5051e-01, -5.4842e-01]]],
        ...,
        [[[ 2.4216e-01,  3.5378e-01,  2.2737e-01,  ...,  3.1021e-01,
            9.9693e-02, -2.0048e-01],
          [-1.5278e-01, -1.2054e-01, -2.2847e-01,  ...,  3.5341e-01,
            1.1703e-01, -3.7654e-02],
          [-3.7909e-01, -8.7560e-02, -8.0825e-03,  ...,  3.5015e-01,
            1.6280e-01,  2.7783e-02],
          ...,
          [-4.1668e-01, -4.5089e-01, -1.2389e-01,  ...,  5.3746e-01,
            9.1433e-02, -2.6981e-01],
          [-6.1443e-01, -5.2801e-01, -3.4111e-01,  ...,  5.2189e-01,
            7.7091e-02, -6.9355e-01],
          [-7.6011e-02,  8.1208e-02,  5.2572e-03,  ...,  5.5980e-01,
            2.0454e-01, -5.7645e-01]]],
        [[[-8.2543e-01, -3.4717e-01,  8.0716e-02,  ..., -4.5499e-01,
           -4.1795e-01, -6.0740e-01],
          [-7.6669e-01, -3.2388e-01, -7.7367e-04,  ..., -2.4888e-01,
           -5.4398e-01, -6.6867e-01],
          [-7.2512e-01, -2.8233e-01, -6.7784e-02,  ..., -1.7469e-01,
           -4.4113e-01, -6.5702e-01],
          ...,
          [-8.1306e-01, -2.9506e-01, -1.6111e-01,  ..., -3.9998e-01,
           -3.7599e-01, -6.9716e-01],
          [-6.8471e-01, -6.9707e-02,  1.8302e-01,  ..., -3.3684e-01,
           -3.5985e-01, -1.0000e+00],
          [-6.7596e-01, -7.3479e-02,  2.5384e-01,  ..., -2.4408e-01,
           -4.5273e-01, -6.6868e-01]]],
        [[[-3.0792e-01, -1.0694e-01,  1.2220e-01,  ...,  3.8332e-01,
            2.0327e-01, -2.5034e-01],
          [-3.8947e-01,  7.2470e-03,  6.5014e-02,  ...,  2.0753e-01,
            1.4522e-02, -1.8085e-01],
          [-6.9384e-01, -1.4702e-01,  1.7513e-01,  ...,  2.9448e-01,
            1.1448e-01, -2.4251e-01],
          ...,
          [-6.7056e-01,  5.3310e-02,  4.2496e-01,  ...,  4.9120e-01,
            5.5185e-01,  5.8873e-02],
          [-7.0604e-01,  9.3746e-02,  4.0836e-01,  ...,  3.2905e-01,
            4.5473e-01,  4.1060e-02],
          [-6.1292e-01, -9.6793e-02,  7.6209e-02,  ...,  2.8957e-01,
            1.5462e-01, -1.2695e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2958, -0.2508, -0.0026,  ..., -0.5527, -0.5466, -0.1773],
          [-0.1214, -0.1711, -0.0084,  ..., -0.5372, -0.4692, -0.1874],
          [-0.2019, -0.1863, -0.0143,  ..., -0.3978, -0.4734, -0.2511],
          ...,
          [-0.4789, -0.1318, -0.2247,  ..., -0.8347, -0.4485, -0.1547],
          [-0.3444, -0.0137, -0.2123,  ..., -0.9079, -0.6191, -0.2371],
          [-0.1354, -0.0902, -0.2147,  ..., -1.0000, -0.8454, -0.3051]]],
        [[[-0.2796, -0.0058,  0.1977,  ..., -0.3967, -0.3550, -0.5053],
          [-0.1753, -0.4447,  0.0529,  ..., -0.3263, -0.3888, -0.5896],
          [-0.0186, -0.0759,  0.0876,  ..., -0.3609, -0.2733, -0.6101],
          ...,
          [-0.0139,  0.1292,  0.0747,  ..., -0.4462, -0.3513, -0.3635],
          [ 0.0155,  0.0974, -0.1572,  ..., -0.5114, -0.5059, -0.4554],
          [ 0.0201,  0.0858,  0.1003,  ..., -0.3417, -0.3670, -0.3846]]],
        [[[-0.3210, -0.0346, -0.2640,  ...,  0.0940, -0.1670,  0.0059],
          [-0.3668, -0.1159,  0.0114,  ...,  0.3024,  0.1073,  0.0959],
          [-0.5686, -0.2971,  0.1756,  ...,  0.1678,  0.0527,  0.0743],
          ...,
          [-0.5239, -0.1638, -0.0554,  ..., -0.0273, -0.0035,  0.0569],
          [-0.4941, -0.4337, -0.2565,  ..., -0.1989, -0.0842,  0.1494],
          [-0.4443, -0.1926, -0.2237,  ...,  0.1321,  0.0767,  0.0378]]],
        ...,
        [[[ 0.1006,  0.6385,  0.6353,  ..., -0.8313, -0.5105, -0.3841],
          [-0.1588,  0.2740,  0.3132,  ..., -0.8042, -0.3248, -0.3025],
          [-0.2811, -0.2698, -0.0803,  ..., -0.8338, -0.4819, -0.4491],
          ...,
          [-0.1198,  0.2035, -0.2181,  ..., -0.5193, -0.3917, -0.3848],
          [ 0.1441,  0.0966, -0.2507,  ..., -0.5275, -0.5565, -0.5595],
          [ 0.0489, -0.2213, -0.2594,  ..., -0.4210, -0.5130, -0.3419]]],
        [[[-0.5338, -0.2083, -0.1229,  ...,  0.0105,  0.0825,  0.2205],
          [-0.5429, -0.2745,  0.1021,  ...,  0.0049,  0.0867,  0.3520],
          [-0.6477, -0.2804, -0.0434,  ..., -0.1039,  0.1593,  0.2615],
          ...,
          [-0.8505, -0.0837,  0.1756,  ...,  0.2829,  0.2145,  0.1617],
          [-0.6695, -0.3182, -0.0775,  ...,  0.2184,  0.0572,  0.0916],
          [-0.7532, -0.6119, -0.2139,  ..., -0.0586, -0.0703,  0.2563]]],
        [[[ 0.3488,  0.5114,  0.4616,  ...,  0.0063, -0.1171, -0.0550],
          [ 0.2468,  0.2900,  0.2092,  ..., -0.1129, -0.1933, -0.0747],
          [ 0.2049,  0.2792,  0.2212,  ..., -0.3742, -0.3811, -0.2349],
          ...,
          [ 0.2521,  0.4950,  0.4892,  ..., -0.2241, -0.1909, -0.1679],
          [ 0.2173,  0.4536,  0.3777,  ..., -0.2460, -0.2190, -0.0101],
          [ 0.1782,  0.2441,  0.5151,  ..., -0.2508, -0.0979, -0.0878]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-7.4097e-01, -3.8614e-01,  2.8203e-01,  ...,  4.3874e-01,
           -4.2602e-02, -3.9172e-01],
          [-7.1989e-01, -1.0320e-01,  3.4440e-01,  ...,  3.7959e-01,
           -8.3553e-02, -3.7785e-01],
          [-8.0033e-01, -1.1693e-01,  2.0194e-01,  ...,  2.7414e-01,
            5.9841e-02, -2.5802e-01],
          ...,
          [-5.8340e-01,  9.2575e-02,  4.8595e-01,  ...,  1.8290e-01,
            1.6565e-01, -6.1190e-01],
          [-4.2907e-01,  1.3619e-01,  5.2059e-01,  ...,  4.2028e-01,
            1.4417e-01, -2.2924e-01],
          [-4.6838e-01, -2.0963e-01,  3.1370e-01,  ...,  4.3046e-01,
            2.9281e-01, -1.4252e-01]]],
        [[[-7.8348e-01, -3.5447e-01, -9.8667e-02,  ...,  2.3681e-01,
           -9.6668e-02, -6.1012e-01],
          [-7.8509e-01, -3.6166e-01, -5.3766e-03,  ...,  1.8545e-01,
           -5.4449e-02, -4.7010e-01],
          [-6.7463e-01, -3.3766e-01, -9.4711e-02,  ..., -1.1172e-01,
           -2.4479e-01, -4.4572e-01],
          ...,
          [-7.4173e-01, -4.0841e-01, -1.5963e-01,  ..., -9.8721e-02,
           -1.7043e-01, -3.0862e-01],
          [-9.6440e-01, -2.7975e-01, -5.1272e-02,  ..., -1.2338e-01,
           -1.5597e-01, -5.4504e-01],
          [-9.1580e-01, -2.4828e-01, -1.8346e-01,  ...,  1.0210e-01,
            4.0267e-03, -4.9079e-01]]],
        [[[-4.8033e-01, -7.2274e-03,  3.2653e-01,  ...,  1.0186e-01,
           -1.5314e-01, -3.9735e-02],
          [-4.0432e-01,  9.5620e-02,  1.3070e-01,  ...,  9.7329e-02,
           -4.7585e-01, -2.1148e-01],
          [-5.7043e-01, -4.4043e-02,  2.3650e-01,  ...,  2.6081e-01,
            1.2690e-01,  2.9319e-02],
          ...,
          [-5.5561e-01,  2.2617e-01,  2.4469e-01,  ...,  7.1278e-02,
            2.2398e-02, -1.0546e-01],
          [-4.9646e-01,  1.2455e-01,  8.4123e-02,  ...,  2.0941e-01,
            1.5801e-01, -3.8801e-02],
          [-3.9709e-01, -1.0177e-01,  9.6505e-02,  ...,  1.4558e-02,
           -7.0859e-03, -3.9706e-02]]],
        ...,
        [[[-1.9181e-01, -2.2812e-01, -1.6594e-01,  ..., -7.7350e-01,
           -7.7396e-01, -4.4589e-01],
          [-3.3017e-01, -1.0238e-01, -9.1049e-02,  ..., -6.5315e-01,
           -6.6275e-01, -4.7389e-01],
          [-2.6412e-01, -8.3572e-04, -1.3959e-01,  ..., -4.9274e-01,
           -5.9204e-01, -4.4174e-01],
          ...,
          [-1.4970e-01, -1.9150e-01, -2.3039e-01,  ..., -5.6996e-01,
           -3.9413e-01, -4.5544e-01],
          [-3.0802e-01, -4.3193e-03, -1.7676e-01,  ..., -6.3297e-01,
           -5.0483e-01, -4.6509e-01],
          [-3.6456e-01,  6.1720e-02, -1.6259e-01,  ..., -6.7044e-01,
           -6.9582e-01, -5.7633e-01]]],
        [[[-6.9602e-01, -5.7158e-01, -5.9156e-01,  ..., -2.7624e-01,
           -3.2134e-01, -5.7384e-01],
          [-9.3523e-01, -5.2137e-01, -3.0101e-01,  ..., -1.9671e-01,
           -4.1343e-01, -6.5116e-01],
          [-6.3989e-01, -7.0707e-01, -3.8268e-01,  ..., -8.0162e-02,
           -3.4860e-01, -4.2049e-01],
          ...,
          [-7.0365e-01, -5.9926e-01, -6.5565e-01,  ...,  6.4479e-02,
           -3.2664e-01, -8.6992e-01],
          [-4.9651e-01, -4.9816e-01, -6.9278e-01,  ..., -5.4027e-02,
           -3.7766e-01, -9.0393e-01],
          [-6.7240e-01, -7.0532e-01, -6.3433e-01,  ..., -2.0269e-01,
           -5.0223e-01, -9.7703e-01]]],
        [[[-7.6468e-01, -1.3402e-03, -2.7957e-02,  ...,  1.8684e-01,
           -4.9449e-03, -1.4523e-02],
          [-7.0951e-01,  1.2922e-01,  2.4020e-01,  ...,  2.4775e-01,
            1.2348e-01, -6.2109e-02],
          [-8.4244e-01,  1.9689e-01,  3.7825e-01,  ...,  3.9197e-01,
            3.3851e-01, -2.1125e-01],
          ...,
          [-9.1784e-01, -5.8472e-03,  3.4114e-01,  ...,  1.6364e-01,
            1.1674e-01, -2.9060e-01],
          [-8.0822e-01, -1.3172e-01,  1.7093e-01,  ..., -2.7024e-01,
           -1.7795e-02, -8.2687e-02],
          [-7.5304e-01, -2.6054e-01,  8.8310e-02,  ..., -6.6205e-02,
           -1.9967e-01, -2.4127e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0728,  0.4658,  0.3579,  ...,  0.2949,  0.2659, -0.2482],
          [-0.1478,  0.3560,  0.5128,  ...,  0.3349, -0.0343, -0.3025],
          [-0.3497,  0.1770,  0.5507,  ...,  0.4183, -0.0588, -0.3933],
          ...,
          [-0.4517,  0.1076,  0.1960,  ...,  0.1154,  0.1089, -0.6686],
          [-0.4257, -0.0527,  0.2314,  ...,  0.3466,  0.1693, -0.5087],
          [-0.6160,  0.0847,  0.3915,  ...,  0.3591,  0.1921, -0.4115]]],
        [[[-0.3563, -0.0901,  0.1624,  ..., -0.4050, -0.4383, -0.3247],
          [-0.2194, -0.1342,  0.1757,  ..., -0.3698, -0.3693, -0.3810],
          [-0.4005, -0.1564,  0.1939,  ..., -0.6603, -0.5590, -0.4690],
          ...,
          [-0.3457, -0.2787, -0.2168,  ..., -0.3547, -0.3254, -0.6691],
          [-0.4294, -0.5114, -0.0944,  ..., -0.2605, -0.3884, -0.6355],
          [-0.3159, -0.2061,  0.0038,  ..., -0.4638, -0.5762, -0.5465]]],
        [[[-0.1437, -0.2293, -0.1260,  ..., -0.5943,  0.0034,  0.3430],
          [-0.2642, -0.3594, -0.1587,  ..., -0.2369,  0.1213,  0.3327],
          [-0.5008, -0.2022, -0.0131,  ..., -0.3084,  0.3128,  0.1616],
          ...,
          [-0.0935, -0.0273, -0.0769,  ..., -0.3694, -0.0487,  0.2186],
          [-0.0909, -0.2311, -0.0760,  ..., -0.0737,  0.0061,  0.0974],
          [-0.0137, -0.2294, -0.0463,  ..., -0.3313, -0.0719,  0.1319]]],
        ...,
        [[[-0.3354, -0.4408, -0.3045,  ..., -0.8315, -0.8345, -0.5632],
          [-0.5866, -0.5845, -0.4895,  ..., -0.7179, -0.7176, -0.5655],
          [-0.6415, -0.4851, -0.3130,  ..., -0.6134, -0.6749, -0.5392],
          ...,
          [-0.3200, -0.4444, -0.5179,  ..., -0.7279, -0.8084, -0.6055],
          [-0.3135, -0.3086, -0.4113,  ..., -0.7532, -0.8059, -0.7585],
          [-0.2617, -0.0164, -0.0735,  ..., -0.7327, -0.7269, -0.8184]]],
        [[[-0.3125,  0.1743,  0.1617,  ...,  0.0940, -0.0600, -0.3830],
          [-0.5110, -0.0186,  0.3422,  ...,  0.1128, -0.0073, -0.3539],
          [-0.6665, -0.1918,  0.2556,  ...,  0.1156,  0.0976, -0.2563],
          ...,
          [-0.4825, -0.2523,  0.0857,  ..., -0.0334, -0.0707, -0.3589],
          [-0.3795, -0.0870,  0.0806,  ...,  0.0070,  0.0524, -0.4465],
          [-0.4220, -0.0056,  0.1250,  ..., -0.1086,  0.1480, -0.1809]]],
        [[[-0.5967, -0.1046,  0.1855,  ..., -0.4957, -0.8810, -0.7299],
          [-0.6485, -0.1661, -0.0881,  ..., -0.5195, -0.6668, -0.7423],
          [-0.9396, -0.3879,  0.0682,  ..., -0.4058, -0.5335, -0.6338],
          ...,
          [-0.3259,  0.0483,  0.5148,  ..., -0.2248, -0.4698, -0.5015],
          [-0.5057,  0.2193,  0.6470,  ...,  0.1833, -0.1288, -0.7335],
          [-0.5776,  0.0207,  0.4603,  ...,  0.1541, -0.0784, -0.4939]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-6.0817e-01, -4.9368e-01, -2.6737e-01,  ...,  4.9767e-01,
            3.3763e-01, -2.8142e-01],
          [-4.5708e-01, -6.6041e-01, -4.0773e-01,  ...,  4.3783e-01,
            1.9425e-01, -4.9584e-01],
          [-5.0369e-01, -5.6881e-01, -5.3599e-01,  ...,  3.0826e-01,
            1.9348e-01, -6.1932e-01],
          ...,
          [-7.0134e-02,  3.1833e-01,  4.2978e-01,  ...,  5.8218e-01,
            4.9777e-01,  1.5752e-01],
          [-2.1886e-01,  2.5971e-01,  4.3488e-01,  ...,  5.3017e-01,
            3.8079e-01,  1.0658e-01],
          [-5.0029e-01, -3.6572e-02,  6.3498e-02,  ...,  5.1363e-01,
            2.8626e-01, -1.3254e-03]]],
        [[[-4.4373e-01, -2.5419e-02,  5.7958e-02,  ...,  5.2172e-01,
            1.9243e-01,  5.8099e-02],
          [-8.1727e-01, -2.8172e-01,  1.2493e-02,  ...,  3.8649e-01,
            1.7477e-01,  1.2008e-01],
          [-8.2898e-01, -1.4104e-01,  2.0307e-01,  ...,  5.3350e-01,
            4.9218e-01,  1.7465e-01],
          ...,
          [-6.9582e-01, -5.5743e-01, -2.1939e-01,  ...,  6.9217e-01,
            5.4328e-01,  3.9543e-01],
          [-6.0887e-01, -3.5095e-01,  2.2775e-02,  ...,  5.0755e-01,
            6.2513e-01,  3.1697e-01],
          [-5.4676e-01, -2.0050e-01,  1.4746e-01,  ...,  5.5156e-01,
            5.1186e-01,  2.0151e-01]]],
        [[[-4.4355e-01, -3.8427e-01, -1.2396e-01,  ..., -4.5576e-01,
           -3.2806e-01, -5.0084e-01],
          [-4.0824e-01, -3.3660e-01, -1.9262e-01,  ..., -4.3357e-01,
           -3.0612e-01, -7.1453e-01],
          [-3.7375e-01, -4.1078e-01, -4.0337e-01,  ..., -3.2411e-01,
           -2.6062e-01, -6.2560e-01],
          ...,
          [-1.0274e-02, -1.0276e-01, -5.0119e-02,  ..., -6.2060e-01,
           -6.5172e-01, -8.2343e-01],
          [-1.1909e-02, -1.5658e-01, -5.7438e-02,  ..., -5.9377e-01,
           -5.3416e-01, -5.9643e-01],
          [-8.1644e-02, -8.7216e-02,  1.3299e-03,  ..., -7.8069e-01,
           -7.3390e-01, -6.2656e-01]]],
        ...,
        [[[-2.4987e-01,  2.9319e-01,  5.2575e-01,  ...,  1.8429e-01,
            1.1600e-01, -3.5711e-01],
          [-1.4550e-01,  4.4869e-01,  5.1710e-01,  ...,  2.9306e-01,
            7.8814e-03, -4.2523e-01],
          [-2.1683e-01,  3.2102e-01,  1.3272e-01,  ...,  3.1410e-01,
            1.3961e-01, -5.6009e-01],
          ...,
          [-1.9118e-01,  1.9387e-01,  5.1399e-01,  ..., -3.0916e-01,
           -2.0436e-01, -5.0483e-01],
          [-2.8639e-01,  4.2893e-02,  4.2762e-01,  ..., -1.7665e-01,
           -3.9431e-01, -7.5647e-01],
          [-2.5297e-01,  1.2609e-01,  2.9942e-01,  ..., -1.2205e-01,
           -2.8470e-01, -1.0000e+00]]],
        [[[-5.0998e-01,  1.0754e-02, -3.7583e-02,  ...,  8.9567e-02,
           -1.9839e-01,  1.8116e-02],
          [-5.4460e-01,  2.7732e-02,  9.6492e-02,  ...,  1.4967e-01,
           -2.1799e-01, -1.9041e-02],
          [-4.2069e-01,  1.0176e-01,  7.7050e-02,  ...,  6.0877e-02,
           -1.7320e-01,  5.0052e-03],
          ...,
          [-4.0261e-01, -2.8011e-02,  1.8190e-01,  ..., -7.1223e-01,
           -7.9119e-01,  4.6899e-03],
          [-5.7378e-01,  6.6617e-02, -1.2445e-01,  ..., -4.0475e-01,
           -6.6086e-01, -7.8928e-03],
          [-5.2927e-01, -2.7529e-02,  1.3442e-01,  ..., -2.8171e-01,
           -4.8824e-01,  8.3840e-04]]],
        [[[-6.0731e-01, -8.5660e-02,  1.1618e-01,  ..., -4.9218e-01,
           -4.4793e-01, -2.9566e-01],
          [-1.2006e-01,  3.8859e-02, -5.8397e-02,  ..., -4.4820e-01,
           -3.8838e-01, -3.5327e-01],
          [-1.4876e-01,  5.4909e-02, -1.6675e-01,  ..., -5.4607e-01,
           -5.3744e-01, -6.0884e-01],
          ...,
          [-2.1245e-01, -3.5088e-01, -2.3321e-01,  ..., -4.3030e-01,
           -4.8936e-01, -3.2791e-01],
          [-2.7508e-01, -4.5379e-01, -5.5113e-03,  ..., -2.5394e-01,
           -6.1019e-01, -5.0479e-01],
          [-1.4004e-01, -2.9141e-01,  5.3212e-02,  ..., -3.2441e-01,
           -3.9000e-01, -3.3020e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2335, -0.0082,  0.2000,  ...,  0.1790, -0.2762, -0.6359],
          [-0.1699,  0.0429,  0.3513,  ...,  0.2344, -0.0308, -0.4627],
          [-0.1721,  0.2482,  0.2139,  ...,  0.4728,  0.1380, -0.5104],
          ...,
          [-0.3632,  0.0629, -0.0115,  ...,  0.5345,  0.2244, -0.1413],
          [-0.3435, -0.2025, -0.1830,  ...,  0.5326,  0.3019,  0.0585],
          [-0.1404, -0.0647, -0.1201,  ...,  0.5328,  0.3633,  0.0866]]],
        [[[-0.4470, -0.2339, -0.1721,  ..., -0.3991, -0.6660, -0.7319],
          [-0.3910, -0.0646, -0.1603,  ..., -0.3767, -0.4422, -0.5842],
          [-0.2277, -0.0785, -0.1752,  ..., -0.4611, -0.4671, -0.6018],
          ...,
          [-0.4294, -0.2241, -0.2806,  ..., -0.5632, -0.6637, -0.5675],
          [-0.3341, -0.3307, -0.3137,  ..., -0.4971, -0.7238, -0.8523],
          [-0.3704, -0.3554, -0.3100,  ..., -0.4279, -0.3973, -0.5244]]],
        [[[-0.8098, -0.0412,  0.3915,  ..., -0.1262,  0.0767,  0.1037],
          [-0.6557, -0.1028,  0.1567,  ...,  0.1292,  0.0524, -0.0227],
          [-0.5250, -0.0018, -0.0471,  ...,  0.2814,  0.2895,  0.1231],
          ...,
          [-0.7584,  0.1114,  0.5074,  ...,  0.1846,  0.1475,  0.1718],
          [-0.7853, -0.0193,  0.3559,  ...,  0.2120,  0.0783, -0.1142],
          [-0.7279, -0.5390,  0.2351,  ...,  0.1551,  0.2068, -0.1212]]],
        ...,
        [[[-0.1109, -0.0438, -0.1521,  ..., -0.8534, -0.7816, -0.8950],
          [-0.1238, -0.1294, -0.3786,  ..., -0.8756, -0.8032, -0.7414],
          [-0.0131, -0.1852, -0.1762,  ..., -1.0000, -0.9546, -0.5884],
          ...,
          [-0.3357, -0.3716, -0.4286,  ..., -0.2599, -0.0176,  0.1587],
          [-0.2847, -0.4153, -0.3801,  ..., -0.0904,  0.2335,  0.1392],
          [-0.3220, -0.3350, -0.2519,  ..., -0.2071,  0.1742, -0.0119]]],
        [[[-0.3742, -0.5296, -0.2770,  ..., -0.3395, -0.6192, -0.5979],
          [-0.5350, -0.3666, -0.4624,  ..., -0.3773, -0.3587, -0.6916],
          [-0.1594, -0.0323, -0.2604,  ..., -0.4916, -0.4386, -0.3032],
          ...,
          [-0.1678, -0.3649,  0.1688,  ..., -0.6957, -0.1623,  0.0695],
          [-0.4503, -0.5652, -0.0723,  ..., -0.6719, -0.5715, -0.3264],
          [-0.5350, -0.4582,  0.0663,  ..., -0.3755, -0.5163, -0.2050]]],
        [[[-0.4213,  0.1281,  0.3984,  ..., -0.2030, -0.1434,  0.1544],
          [-0.0597, -0.0532,  0.1812,  ..., -0.2938, -0.1270,  0.1777],
          [-0.1563,  0.0780, -0.0907,  ..., -0.3187, -0.3557,  0.1180],
          ...,
          [-0.0931,  0.3467,  0.2693,  ..., -0.0880, -0.0790,  0.0125],
          [-0.1566,  0.3392,  0.3988,  ..., -0.0552, -0.0766,  0.0524],
          [-0.4058,  0.0269,  0.4683,  ..., -0.0311, -0.1408,  0.0769]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.6793, -0.0457,  0.2299,  ..., -0.1944, -0.1303, -0.8396],
          [-0.7429, -0.2948,  0.1561,  ..., -0.1579, -0.0063, -0.5458],
          [-0.6741, -0.1884, -0.0880,  ..., -0.0666,  0.1093, -0.4648],
          ...,
          [-0.5879,  0.1664,  0.1444,  ..., -0.0182, -0.3127, -0.5143],
          [-0.4447,  0.3057,  0.3325,  ..., -0.0763, -0.2308, -0.6330],
          [-0.5719,  0.2271,  0.2415,  ..., -0.1529, -0.4389, -0.6869]]],
        [[[-0.0736,  0.0756,  0.2356,  ...,  0.0331,  0.0197,  0.2436],
          [ 0.0319,  0.1032, -0.1262,  ...,  0.0701, -0.0667,  0.2856],
          [ 0.2261, -0.2256, -0.0200,  ..., -0.2139, -0.0577,  0.2704],
          ...,
          [-0.2547, -0.0851, -0.0056,  ..., -0.1569, -0.2087, -0.0178],
          [ 0.0027,  0.1280,  0.0835,  ..., -0.0391, -0.2631,  0.0435],
          [ 0.1015,  0.2108, -0.1240,  ..., -0.0172, -0.1280,  0.0650]]],
        [[[-0.7212, -0.4934, -0.6748,  ..., -0.6112, -0.6643, -0.4887],
          [-0.7116, -0.5327, -0.6486,  ..., -0.6343, -0.5548, -0.4273],
          [-0.7710, -0.7077, -0.6394,  ..., -0.5071, -0.5496, -0.4163],
          ...,
          [-0.4730, -0.3363, -0.3704,  ..., -0.3137, -0.3569, -0.3475],
          [-0.4023, -0.3352, -0.2705,  ..., -0.4391, -0.4126, -0.3760],
          [-0.5576, -0.3470, -0.1493,  ..., -0.4518, -0.4599, -0.3291]]],
        ...,
        [[[-0.4516, -0.0038,  0.1288,  ..., -0.3106, -0.4329, -0.6910],
          [-0.5426, -0.0802,  0.1012,  ..., -0.4773, -0.5270, -0.7794],
          [-0.4749, -0.2371,  0.0705,  ..., -0.3657, -0.4724, -0.5284],
          ...,
          [-0.5949, -0.3048, -0.2105,  ..., -0.4124, -0.5371, -0.6498],
          [-0.5000, -0.3140, -0.1029,  ..., -0.3288, -0.4390, -0.6214],
          [-0.4249, -0.1973, -0.0904,  ..., -0.4016, -0.5099, -0.8898]]],
        [[[-0.5777, -0.0518, -0.1215,  ..., -0.3068, -0.5575, -0.9411],
          [-0.5537, -0.1886,  0.0239,  ..., -0.2438, -0.4448, -0.5852],
          [-0.5916, -0.1463,  0.0348,  ..., -0.3198, -0.3496, -0.7047],
          ...,
          [-0.5490, -0.1315,  0.0946,  ..., -0.3902, -0.2118, -0.5605],
          [-0.5502, -0.2299, -0.1078,  ..., -0.1690, -0.2547, -0.7603],
          [-0.5726, -0.1941,  0.0627,  ..., -0.2904, -0.4856, -0.6626]]],
        [[[-0.5196, -0.5997, -0.2504,  ..., -0.5224, -0.4402, -0.1791],
          [-0.4419, -0.4146, -0.4713,  ..., -0.5047, -0.2499, -0.0420],
          [-0.4457, -0.3318, -0.2034,  ..., -0.4016, -0.2581, -0.1120],
          ...,
          [-0.4290, -0.4862, -0.4431,  ..., -0.8583, -0.3908, -0.4246],
          [-0.3023, -0.1070, -0.0291,  ..., -0.8690, -0.4583, -0.5340],
          [-0.4200, -0.1709, -0.0344,  ..., -0.7264, -0.8568, -0.5930]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.2255, -0.0869, -0.3410,  ..., -0.5158, -0.7321, -0.9653],
          [ 0.2941,  0.1072, -0.1763,  ..., -0.5137, -0.6365, -0.7777],
          [ 0.2376,  0.0860,  0.0054,  ..., -0.4694, -0.6002, -0.7944],
          ...,
          [-0.4990, -0.2370, -0.3253,  ..., -0.3026, -0.3172, -0.6546],
          [-0.3149, -0.3358, -0.2984,  ..., -0.4511, -0.5512, -0.9057],
          [-0.3181, -0.3125, -0.1401,  ..., -0.5150, -0.4970, -0.5962]]],
        [[[-0.1317, -0.0388, -0.1035,  ..., -0.4778, -0.4529, -0.2720],
          [-0.2125, -0.1554, -0.3202,  ..., -0.3819, -0.2568, -0.2198],
          [-0.1897, -0.0230, -0.2808,  ..., -0.3945, -0.2712, -0.2351],
          ...,
          [-0.3037, -0.3055, -0.2175,  ..., -0.5212, -0.5104, -0.4333],
          [-0.1923, -0.1438, -0.3153,  ..., -0.5856, -0.5441, -0.3368],
          [-0.1524, -0.0735, -0.4988,  ..., -0.7710, -0.7641, -0.3883]]],
        [[[-0.5544, -0.0638,  0.2102,  ...,  0.0490, -0.2877, -0.4255],
          [-0.5634, -0.0587,  0.1781,  ..., -0.0781,  0.0273, -0.2690],
          [-0.4819,  0.0334,  0.0386,  ...,  0.0795,  0.1010, -0.4167],
          ...,
          [-0.5330, -0.2638,  0.1333,  ...,  0.1175,  0.0255, -0.3292],
          [-0.3955,  0.0126,  0.1100,  ...,  0.1773,  0.0463, -0.3184],
          [-0.3761, -0.0980, -0.0099,  ...,  0.0293, -0.2643, -0.5240]]],
        ...,
        [[[-0.5609, -0.3777, -0.2179,  ..., -0.0447, -0.3680, -0.5996],
          [-0.4172, -0.0280,  0.1117,  ...,  0.0797, -0.5236, -0.6328],
          [-0.3150,  0.1177,  0.2255,  ...,  0.1397, -0.2125, -0.5894],
          ...,
          [-0.3719, -0.0263, -0.0396,  ..., -0.0262, -0.1141, -0.4335],
          [-0.4595, -0.3648, -0.1380,  ..., -0.1018, -0.1413, -0.5584],
          [-0.5064, -0.0796,  0.0020,  ..., -0.0141, -0.3213, -0.6672]]],
        [[[-0.6512,  0.2681,  0.4782,  ...,  0.1391, -0.2630, -0.5460],
          [-0.6060,  0.2556,  0.3933,  ...,  0.2911, -0.1683, -0.3275],
          [-0.4113,  0.0279,  0.3769,  ...,  0.2884, -0.1984, -0.4012],
          ...,
          [-0.4100, -0.0466,  0.1604,  ...,  0.4121,  0.2801, -0.3910],
          [-0.5634, -0.1907,  0.1885,  ...,  0.1956,  0.1746, -0.2645],
          [-0.4787, -0.0247,  0.1998,  ...,  0.0041, -0.1398, -0.4225]]],
        [[[ 0.2084,  0.1433,  0.0567,  ..., -0.3248, -0.2239, -0.2012],
          [ 0.2768,  0.3237,  0.2563,  ..., -0.2617, -0.3481, -0.2526],
          [ 0.3215,  0.4025,  0.1782,  ..., -0.3599, -0.6500, -0.4953],
          ...,
          [ 0.0026,  0.0172,  0.0761,  ..., -0.4262, -0.6796, -0.3008],
          [ 0.0102, -0.1158,  0.0680,  ..., -0.4727, -0.5839, -0.2725],
          [ 0.1456,  0.1656,  0.2264,  ..., -0.3918, -0.4409, -0.2519]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.2348,  0.7062,  0.5903,  ..., -0.0181, -0.1360, -0.4219],
          [ 0.0452,  0.5884,  0.5473,  ...,  0.0153, -0.2035, -0.5051],
          [ 0.0427,  0.3736,  0.5544,  ..., -0.0808, -0.4441, -0.6542],
          ...,
          [-0.3109,  0.2827,  0.2539,  ..., -0.0647, -0.3175, -0.6311],
          [-0.5434,  0.1997,  0.4094,  ...,  0.0541, -0.3592, -0.6834],
          [-0.0330,  0.3260,  0.4208,  ...,  0.0434, -0.3589, -0.5575]]],
        [[[ 0.1627,  0.1916,  0.2487,  ..., -0.9674,  0.1378,  0.7241],
          [ 0.1640,  0.2489, -0.0445,  ..., -0.3523,  0.3153,  0.7534],
          [ 0.2508,  0.2140, -0.2662,  ..., -0.3581,  0.1064,  0.6881],
          ...,
          [-0.0906,  0.2441,  0.1734,  ..., -0.1440,  0.2738,  0.6569],
          [ 0.0207,  0.3177,  0.0793,  ..., -0.5381,  0.0506,  0.6365],
          [ 0.2159,  0.1802,  0.1012,  ..., -0.0700,  0.3317,  0.7365]]],
        [[[-0.6768, -0.7439, -0.5981,  ..., -0.5701, -0.3619, -0.6248],
          [-0.6618, -0.5778, -0.5562,  ..., -0.3925, -0.3942, -0.5179],
          [-0.2792, -0.1323, -0.1451,  ..., -0.1440, -0.1660, -0.5079],
          ...,
          [ 0.0445,  0.1714,  0.2275,  ...,  0.0918,  0.1133, -0.2066],
          [-0.0117,  0.1576,  0.3340,  ...,  0.0759,  0.1656, -0.0541],
          [-0.3008, -0.0649,  0.1806,  ..., -0.2726,  0.0280,  0.0488]]],
        ...,
        [[[-0.5338, -0.2730, -0.4400,  ...,  0.6358,  0.5570,  0.0931],
          [-0.6196, -0.3590, -0.3551,  ...,  0.5231,  0.4213, -0.0915],
          [-0.2315, -0.1681, -0.2740,  ...,  0.5165,  0.6282, -0.1138],
          ...,
          [-0.4525, -0.4892, -0.4825,  ...,  0.3466,  0.4423,  0.0015],
          [-0.3548, -0.4087, -0.6174,  ...,  0.5640,  0.2503, -0.0440],
          [-0.2422, -0.5363, -0.5031,  ...,  0.5750,  0.3472, -0.0608]]],
        [[[-0.2109, -0.1554, -0.3832,  ...,  0.2713,  0.1275, -0.0021],
          [-0.2610, -0.2423, -0.3362,  ...,  0.3897,  0.3479, -0.1313],
          [-0.2244, -0.2741, -0.3259,  ...,  0.2531,  0.2587,  0.1150],
          ...,
          [-0.1520,  0.0181, -0.2438,  ...,  0.8070,  0.5879,  0.3382],
          [-0.4755, -0.2110, -0.5251,  ...,  0.6522,  0.5737,  0.3294],
          [-0.5165, -0.6264, -0.2488,  ...,  0.5413,  0.2434, -0.0399]]],
        [[[ 0.0215,  0.0391, -0.0269,  ..., -0.7206, -0.2860,  0.0141],
          [ 0.0459,  0.0989, -0.0923,  ..., -0.5494, -0.4283, -0.0833],
          [-0.1913, -0.0520, -0.1203,  ..., -0.8068, -0.5973, -0.1750],
          ...,
          [ 0.0674,  0.0244, -0.0541,  ..., -0.3884, -0.4431, -0.2155],
          [-0.0819, -0.2670,  0.0120,  ..., -0.3053, -0.1927, -0.0230],
          [ 0.0300, -0.4408, -0.2522,  ..., -0.3378, -0.2755, -0.0128]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-1.5348e-01,  2.8392e-01,  4.1696e-01,  ..., -3.8011e-01,
           -4.4331e-01, -3.4868e-02],
          [ 1.2816e-02,  2.7693e-01,  2.0285e-01,  ..., -3.2623e-01,
           -4.6338e-01, -1.8486e-01],
          [ 1.5193e-01,  7.8040e-02,  7.0252e-02,  ..., -4.1880e-01,
           -6.1128e-01, -4.3114e-01],
          ...,
          [-2.8231e-01,  6.3276e-02,  3.2287e-01,  ..., -9.1430e-01,
           -2.3348e-01,  2.6091e-01],
          [-6.8256e-02,  1.7052e-01,  2.1610e-01,  ..., -5.9703e-01,
           -2.0305e-01,  2.9186e-01],
          [-1.0942e-01, -3.3755e-01, -1.6199e-01,  ..., -8.2660e-01,
           -1.5611e-01,  3.5672e-01]]],
        [[[ 5.6674e-02,  7.5826e-02,  8.2472e-02,  ..., -9.9543e-02,
           -1.6494e-01, -2.9815e-01],
          [-2.4514e-01, -1.8001e-01, -1.5803e-01,  ..., -1.9061e-01,
           -1.5139e-01, -2.9210e-01],
          [-4.2210e-01, -1.8645e-01, -1.5525e-01,  ..., -5.5950e-01,
           -2.8883e-01, -4.8377e-01],
          ...,
          [-1.2186e-01,  1.0296e-01,  8.5353e-02,  ..., -3.9975e-01,
           -6.5071e-01, -8.9233e-01],
          [-1.3626e-04, -8.6498e-02, -3.5216e-03,  ..., -4.3138e-01,
           -4.0026e-01, -5.8775e-01],
          [-1.5388e-01, -1.5944e-01, -4.6455e-02,  ..., -3.4252e-01,
           -4.5788e-01, -6.6473e-01]]],
        [[[-5.2464e-01,  2.6848e-01,  6.6958e-01,  ...,  1.7612e-01,
           -4.5891e-02,  3.5216e-02],
          [-5.9580e-01, -1.3005e-01,  3.3387e-01,  ..., -1.0113e-01,
           -1.5210e-01,  1.2528e-02],
          [-4.8639e-01, -1.1987e-01,  1.0263e-01,  ..., -5.2747e-01,
           -3.9558e-01, -1.9845e-02],
          ...,
          [-9.6017e-01, -7.3740e-02,  4.5416e-01,  ...,  1.7181e-01,
            3.4494e-01,  8.6240e-02],
          [-8.8142e-01, -5.6513e-02,  4.5166e-01,  ...,  2.4334e-01,
            2.7180e-01,  8.8720e-02],
          [-6.0999e-01,  1.5609e-01,  4.8307e-01,  ..., -3.4168e-01,
           -3.3635e-03,  4.5924e-02]]],
        ...,
        [[[-2.1849e-02, -1.0779e-01, -1.3942e-01,  ..., -3.3788e-01,
           -1.3628e-01, -7.6772e-02],
          [ 9.8743e-02, -1.6913e-01, -3.1517e-02,  ..., -5.5901e-01,
           -2.2602e-01, -4.5034e-02],
          [-1.0373e-01,  1.4153e-01, -1.2582e-01,  ..., -1.3797e-01,
            1.6700e-02,  1.5742e-01],
          ...,
          [ 1.9723e-01, -1.7023e-04, -9.8946e-02,  ...,  1.7805e-01,
           -7.7656e-02, -5.3173e-02],
          [ 8.2372e-02, -1.5789e-01, -3.0474e-01,  ...,  3.6015e-01,
           -1.0068e-01,  1.3725e-01],
          [-2.5145e-01,  1.2499e-01, -1.4172e-02,  ...,  4.1693e-01,
            8.7047e-02,  2.2668e-01]]],
        [[[-2.7986e-01, -7.0749e-02,  2.4646e-01,  ...,  2.1512e-02,
           -4.5225e-02,  3.8746e-01],
          [-7.4830e-01, -3.2258e-01,  3.7268e-01,  ..., -2.1410e-01,
           -2.8996e-01,  4.1044e-01],
          [-5.8547e-01, -3.1798e-02,  4.0263e-01,  ..., -1.4327e-01,
           -1.9824e-01,  4.0448e-01],
          ...,
          [-7.0629e-01,  6.5025e-02,  4.1298e-01,  ..., -5.1437e-02,
           -1.3521e-01,  4.0794e-01],
          [-7.7862e-01, -3.2161e-01,  3.1896e-01,  ..., -1.8795e-01,
           -1.3807e-01,  3.8689e-01],
          [-6.0306e-01,  1.6902e-01,  5.0191e-01,  ..., -3.8386e-02,
           -2.6792e-01,  3.7070e-01]]],
        [[[ 8.8352e-02,  3.1152e-01,  3.5207e-01,  ...,  3.7680e-01,
            1.3559e-01, -3.3136e-01],
          [ 1.1272e-01,  2.1365e-01,  1.8147e-01,  ..., -1.4095e-01,
           -1.5766e-01, -3.2776e-01],
          [-2.3745e-01, -3.1782e-01, -2.5532e-02,  ...,  1.0973e-03,
           -1.2405e-01, -6.2814e-01],
          ...,
          [-1.0000e+00, -3.8072e-01, -7.0355e-01,  ...,  1.1159e-01,
           -2.4640e-01, -7.6752e-01],
          [-5.4304e-01, -3.9704e-01, -5.0077e-01,  ...,  2.0212e-01,
           -2.4516e-01, -8.5969e-01],
          [-4.1326e-01, -5.7804e-01, -4.1881e-01,  ..., -3.3956e-02,
           -3.9173e-01, -8.5200e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.3329e-01,  1.6565e-01,  3.2521e-01,  ..., -3.4699e-01,
           -4.4906e-01, -5.5217e-01],
          [-4.0610e-01, -1.6904e-01,  1.6963e-01,  ..., -3.7284e-01,
           -3.5352e-01, -1.0000e+00],
          [-3.9293e-01, -2.6977e-01,  1.5272e-01,  ..., -2.3319e-01,
           -1.7212e-01, -3.0662e-01],
          ...,
          [-4.1731e-01, -7.4063e-02,  4.3603e-01,  ...,  2.9078e-02,
           -1.4628e-01, -6.2007e-01],
          [-4.3304e-01, -1.2098e-01,  2.1427e-01,  ...,  1.1146e-01,
           -4.5514e-01, -6.9638e-01],
          [-5.9396e-01, -1.0357e-01,  2.5359e-01,  ...,  7.3802e-02,
           -4.6317e-01, -5.8980e-01]]],
        [[[-5.9806e-02,  9.5483e-02,  1.9580e-01,  ..., -4.3162e-01,
           -3.6308e-01, -3.8775e-01],
          [-2.6209e-01,  1.0379e-01,  8.6665e-02,  ..., -2.6330e-01,
           -3.3929e-01, -1.6487e-01],
          [-2.8197e-01, -2.1202e-01, -1.1609e-02,  ..., -3.1321e-01,
           -2.8181e-01, -1.1315e-01],
          ...,
          [-6.6688e-01, -5.3349e-01, -6.3323e-01,  ..., -3.0627e-01,
           -8.9106e-02,  1.8115e-01],
          [-8.1710e-01, -5.9128e-01, -3.0140e-01,  ..., -5.0197e-01,
           -8.0542e-02,  4.4375e-02],
          [-6.4408e-01, -3.4031e-01, -1.3206e-01,  ..., -3.3528e-01,
           -3.0525e-01, -1.9479e-01]]],
        [[[-6.2983e-01, -3.1661e-01, -1.1585e-01,  ...,  4.1640e-02,
            1.2235e-01, -6.6621e-01],
          [-5.9909e-01, -1.9930e-01, -6.3756e-02,  ...,  3.2945e-01,
            1.3348e-01, -1.5644e-01],
          [-7.0139e-01, -2.5836e-01, -1.3885e-01,  ...,  4.6452e-01,
            1.1094e-01, -8.7356e-02],
          ...,
          [-1.4545e-01,  5.5123e-01,  6.2925e-01,  ..., -1.3225e-02,
           -3.1679e-02, -4.9116e-01],
          [-1.3634e-01,  5.2673e-01,  4.1481e-01,  ..., -6.4241e-02,
            6.5773e-02, -2.2718e-01],
          [-3.9048e-01,  3.3556e-01,  3.1179e-01,  ...,  2.3478e-01,
            1.9341e-01, -1.9290e-01]]],
        ...,
        [[[-4.8130e-01,  1.3482e-02,  8.8626e-02,  ..., -4.9807e-02,
           -2.2916e-01, -3.3854e-01],
          [-5.5842e-01, -6.3992e-03, -1.7702e-01,  ..., -9.5256e-02,
           -2.2701e-01, -3.4313e-01],
          [-6.6677e-01, -2.5537e-01, -9.3695e-02,  ..., -5.9456e-01,
           -2.9420e-01, -3.1893e-01],
          ...,
          [-4.1543e-01,  7.6089e-02,  1.7897e-01,  ..., -2.6927e-01,
           -5.8512e-01, -3.2805e-01],
          [-4.8663e-01, -1.7624e-02,  1.3461e-01,  ...,  1.0295e-01,
           -4.0632e-01, -3.2040e-01],
          [-8.1140e-01, -1.0541e-01,  1.5217e-01,  ...,  1.0837e-01,
           -2.7975e-01, -2.6325e-01]]],
        [[[-2.8046e-01, -4.3041e-02,  1.5762e-02,  ..., -3.7004e-01,
           -5.8403e-01, -6.8183e-01],
          [-3.1439e-01, -1.5516e-01,  3.3402e-04,  ..., -5.1846e-01,
           -6.2057e-01, -7.9458e-01],
          [-2.0862e-01, -4.6131e-02,  3.8411e-02,  ..., -5.7314e-01,
           -5.1119e-01, -6.8294e-01],
          ...,
          [-3.0884e-01, -2.4646e-01, -2.2501e-01,  ..., -3.3066e-01,
           -6.6539e-01, -7.0261e-01],
          [-1.6923e-01, -5.7985e-02, -1.7555e-01,  ..., -2.9514e-01,
           -6.4987e-01, -7.1871e-01],
          [-1.3420e-01, -4.0582e-02, -1.3126e-01,  ..., -3.8815e-01,
           -5.0686e-01, -5.8985e-01]]],
        [[[-4.2923e-01,  1.9581e-01,  4.2775e-01,  ..., -2.2638e-01,
           -1.7730e-01,  2.6277e-01],
          [-3.9859e-01, -8.2051e-02,  3.1830e-01,  ..., -1.1031e-01,
           -2.9045e-01,  2.6291e-01],
          [-3.0781e-01,  1.7931e-01,  2.4180e-01,  ..., -1.0858e-02,
           -3.0778e-01,  2.4537e-01],
          ...,
          [-7.3024e-01, -5.6330e-02,  2.3834e-01,  ..., -8.3490e-02,
           -3.6312e-01,  2.5972e-01],
          [-3.6550e-01,  3.2465e-01,  5.2666e-01,  ...,  1.3580e-01,
           -9.7901e-02,  2.5130e-01],
          [-1.3030e-01,  3.4891e-01,  6.5080e-01,  ...,  2.4374e-02,
           -2.4140e-01,  2.2965e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-4.1638e-01, -5.2726e-02, -5.4560e-03,  ..., -7.8456e-01,
           -2.9334e-01, -2.6768e-01],
          [-2.7844e-01, -2.4623e-01, -2.1788e-01,  ..., -3.1339e-01,
           -1.5361e-01, -2.8191e-01],
          [-3.3184e-01, -2.6818e-01, -4.0467e-01,  ..., -2.2075e-01,
           -1.1532e-01, -1.3582e-01],
          ...,
          [-3.8947e-01, -2.4407e-01, -4.1909e-01,  ..., -1.4159e-01,
           -3.2992e-01, -1.8802e-01],
          [-1.1852e-01,  5.0644e-02, -1.0497e-01,  ..., -2.6432e-01,
           -4.2026e-01, -1.5996e-01],
          [-1.7765e-01,  3.9821e-02, -1.3417e-01,  ..., -2.2423e-01,
           -2.3208e-01, -1.1484e-01]]],
        [[[-7.0058e-01, -1.9185e-02,  2.5718e-01,  ..., -9.4295e-02,
           -4.3438e-01,  7.0850e-02],
          [-8.8568e-01, -3.4482e-02,  1.5847e-01,  ..., -4.9490e-01,
           -4.4568e-01,  9.0420e-02],
          [-1.0000e+00, -2.8474e-01,  1.7131e-01,  ..., -5.3900e-01,
           -3.8822e-01,  8.1523e-02],
          ...,
          [-5.5720e-01, -3.4981e-02, -5.5160e-02,  ...,  9.0529e-02,
           -1.4034e-01,  1.1222e-01],
          [-6.9669e-01, -2.7033e-01, -2.1016e-01,  ..., -7.5986e-02,
           -1.8302e-01,  9.7990e-02],
          [-7.6362e-01, -3.8200e-01, -6.0158e-02,  ..., -3.6427e-01,
           -5.4453e-01,  7.1438e-02]]],
        [[[-2.4475e-01, -2.0000e-01, -3.3147e-01,  ..., -2.4599e-01,
           -8.1187e-04, -6.8927e-02],
          [-3.2652e-01, -1.2906e-01, -1.9140e-01,  ..., -6.2791e-01,
           -2.5995e-01, -3.3345e-01],
          [-1.6589e-01, -1.9060e-01, -3.5946e-01,  ..., -3.3324e-01,
           -3.0845e-01, -3.1887e-01],
          ...,
          [-5.9316e-01, -4.0219e-01, -2.5712e-01,  ..., -8.3979e-01,
           -5.1623e-01, -4.9839e-01],
          [-2.0852e-01, -2.6341e-01, -1.3598e-01,  ..., -7.0908e-01,
           -5.7474e-01, -4.2589e-01],
          [-1.1055e-01, -8.8827e-02, -1.5799e-01,  ..., -4.8999e-01,
           -5.0435e-01, -5.1348e-01]]],
        ...,
        [[[-2.5258e-01,  1.5300e-01,  4.5008e-01,  ...,  1.4257e-01,
           -1.5587e-01, -4.6245e-01],
          [-1.2213e-01,  2.2827e-01,  2.3347e-01,  ...,  3.0707e-01,
           -3.7215e-02, -5.8604e-01],
          [-2.4794e-01,  3.2028e-01,  6.1881e-01,  ...,  2.2965e-01,
           -1.6239e-01, -7.3128e-01],
          ...,
          [ 1.4669e-01,  3.9318e-01,  5.3261e-01,  ..., -6.2195e-02,
           -1.7862e-01, -6.0282e-01],
          [ 1.9057e-01,  4.2474e-01,  5.9006e-01,  ...,  2.0319e-01,
           -1.8331e-01, -6.2139e-01],
          [ 2.6473e-01,  6.0403e-01,  8.1048e-01,  ...,  2.6272e-01,
           -1.0232e-01, -5.7947e-01]]],
        [[[-5.1625e-01, -3.6923e-03, -2.1303e-01,  ...,  1.0541e-01,
           -1.0562e-01, -2.9293e-01],
          [-5.0189e-01,  6.7057e-02, -4.2221e-02,  ...,  6.2628e-02,
           -3.0101e-01, -3.0405e-01],
          [-4.5122e-01,  6.2850e-02,  2.7307e-01,  ...,  1.6556e-01,
            5.5363e-02, -2.0989e-01],
          ...,
          [-4.5654e-01, -7.4766e-02, -1.7206e-01,  ...,  2.6848e-01,
            6.5984e-02, -2.2014e-01],
          [-4.2353e-01,  4.6717e-03,  1.4258e-01,  ...,  3.0730e-01,
           -2.2526e-01, -1.8670e-01],
          [-6.0697e-01, -7.2594e-02,  7.3421e-02,  ...,  2.6446e-01,
           -2.4867e-01, -1.5607e-01]]],
        [[[-6.3130e-01, -3.7248e-01,  1.8283e-01,  ...,  6.4468e-01,
            9.0661e-01,  8.5260e-01],
          [-5.9280e-01, -2.5967e-01,  9.8912e-02,  ...,  5.5869e-01,
            7.3245e-01,  7.2141e-01],
          [-6.2297e-01, -1.1487e-01,  1.8991e-01,  ...,  3.9836e-01,
            6.6220e-01,  6.5875e-01],
          ...,
          [-8.5673e-01, -1.4749e-01,  1.3886e-01,  ...,  3.3072e-01,
            4.7563e-01,  5.5706e-01],
          [-5.7479e-01, -1.7987e-01,  1.3839e-01,  ...,  1.7963e-01,
            5.2400e-01,  5.9064e-01],
          [-6.4941e-01, -9.4683e-02,  1.6857e-01,  ...,  5.7000e-01,
            5.3532e-01,  5.6283e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.0010,  0.1776,  0.5691,  ..., -0.6719, -0.0624,  0.4583],
          [ 0.1698,  0.2148,  0.4322,  ..., -0.0995,  0.0512,  0.5296],
          [ 0.4153,  0.3425,  0.2562,  ...,  0.0278, -0.0135,  0.5701],
          ...,
          [-0.2263, -0.1382, -0.1182,  ...,  0.1648, -0.2462, -0.4562],
          [ 0.1706,  0.1284,  0.1946,  ..., -0.0430, -0.1263, -0.5073],
          [-0.0360,  0.0609,  0.2218,  ...,  0.0342,  0.0988,  0.0486]]],
        [[[-0.2621,  0.0729,  0.3470,  ..., -0.1417, -0.2257, -0.3546],
          [-0.5102,  0.0310,  0.2164,  ...,  0.0585, -0.3261, -0.4598],
          [-0.6563, -0.2164, -0.1052,  ...,  0.0206, -0.1972, -0.4827],
          ...,
          [-0.3947,  0.0630,  0.2690,  ..., -0.1420, -0.1869, -0.7516],
          [-0.6078,  0.0595,  0.3773,  ..., -0.4273, -0.5661, -0.6345],
          [-0.4228,  0.1204,  0.4143,  ..., -0.2597, -0.8615, -0.7257]]],
        [[[-0.5284, -0.4996, -0.4121,  ..., -0.5694, -0.5848, -0.4129],
          [-0.4631, -0.5676, -0.4247,  ..., -0.4864, -0.4986, -0.4395],
          [-0.7628, -0.5093, -0.4917,  ..., -0.5994, -0.4346, -0.2460],
          ...,
          [-0.0662,  0.1567,  0.1139,  ..., -0.6949, -0.4504, -0.2215],
          [-0.4437, -0.1914, -0.0665,  ..., -0.9543, -0.6779, -0.4359],
          [-0.5676, -0.1894, -0.1840,  ..., -0.7272, -0.7325, -0.6731]]],
        ...,
        [[[-0.7391, -0.6855, -0.3864,  ..., -0.1299, -0.3512, -0.5411],
          [-0.6986, -0.7964, -0.5705,  ..., -0.3763, -0.2849, -0.4005],
          [-0.6617, -0.6351, -0.5930,  ..., -0.3788, -0.1231, -0.2569],
          ...,
          [-0.5514, -0.4721, -0.5390,  ...,  0.1243,  0.1511, -0.0786],
          [-0.6062, -0.5331, -0.7308,  ...,  0.1610,  0.2595,  0.0710],
          [-0.9323, -0.4218, -0.3603,  ...,  0.4020,  0.3350,  0.1867]]],
        [[[-0.3221, -0.1099, -0.0868,  ..., -0.5130, -0.2948,  0.0758],
          [-0.2280, -0.0948, -0.1214,  ..., -0.5626, -0.3305,  0.0585],
          [-0.4018, -0.3610, -0.5120,  ..., -0.5766, -0.5500,  0.0061],
          ...,
          [-0.2814, -0.1564, -0.0656,  ..., -0.0066, -0.1962, -0.0720],
          [-0.1491, -0.2431, -0.3159,  ..., -0.2445, -0.2281, -0.0782],
          [-0.0723, -0.0630, -0.3327,  ..., -0.5559, -0.3715, -0.1195]]],
        [[[-0.5519, -0.4822, -0.3283,  ..., -0.2048, -0.5044, -0.6232],
          [-0.5730, -0.5297, -0.3376,  ..., -0.2435, -0.4456, -0.7074],
          [-0.7045, -0.3095, -0.1665,  ..., -0.4684, -0.4523, -0.6512],
          ...,
          [-0.3699, -0.5587, -0.6451,  ..., -0.0489, -0.2548, -0.4743],
          [-0.4008, -0.2480, -0.3061,  ...,  0.0211, -0.2217, -0.5828],
          [-0.6819, -0.4125, -0.3593,  ...,  0.0249, -0.3437, -0.3183]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.6621, -0.1463,  0.2378,  ...,  0.5801,  0.5081,  0.3779],
          [-0.7853, -0.2494, -0.0607,  ...,  0.4508,  0.1671,  0.0700],
          [-0.6112, -0.1848,  0.0507,  ...,  0.6119,  0.4964,  0.4387],
          ...,
          [-0.1739,  0.0782,  0.2418,  ...,  0.4453,  0.3213, -0.0667],
          [-0.2561,  0.1261,  0.3617,  ...,  0.3184, -0.0468,  0.1960],
          [-0.4550,  0.2557,  0.4509,  ...,  0.0640,  0.0498,  0.4159]]],
        [[[-0.2972,  0.1337,  0.0262,  ...,  0.3432,  0.1318,  0.2734],
          [-0.3745, -0.0457,  0.3311,  ...,  0.0648, -0.1129,  0.0391],
          [-0.2106,  0.4223,  0.5530,  ...,  0.0978, -0.1039, -0.0191],
          ...,
          [-0.3678,  0.1595,  0.2085,  ...,  0.4219,  0.1438, -0.0047],
          [-0.4362,  0.1664,  0.3484,  ...,  0.4607, -0.0869, -0.1008],
          [-0.6402, -0.2138,  0.1699,  ...,  0.4459,  0.0579,  0.0449]]],
        [[[-0.4041, -0.8796, -0.7193,  ...,  0.2615,  0.0254, -0.2233],
          [-0.4955, -0.6238, -0.7401,  ...,  0.0861,  0.1583, -0.1506],
          [-0.7121, -0.5947, -0.4933,  ...,  0.1903, -0.0746, -0.2154],
          ...,
          [-0.4865, -0.5684, -0.4221,  ...,  0.1698,  0.1473,  0.1658],
          [-0.6295, -0.6034, -0.2724,  ...,  0.2095, -0.0877, -0.2035],
          [-0.5834, -0.6911, -0.3660,  ...,  0.2134,  0.0402, -0.2989]]],
        ...,
        [[[-0.3788,  0.0302, -0.1858,  ...,  0.0362,  0.0286, -0.3192],
          [-0.7387,  0.1481,  0.2917,  ...,  0.3082,  0.1942, -0.4642],
          [-0.7269,  0.2092,  0.3965,  ...,  0.2412,  0.0551, -0.2748],
          ...,
          [-0.7373,  0.1350,  0.3873,  ..., -0.0243,  0.2364, -0.0108],
          [-0.4610,  0.1817,  0.4519,  ..., -0.0547,  0.2350, -0.1278],
          [-0.2212,  0.2433,  0.3832,  ...,  0.3300,  0.2271, -0.3082]]],
        [[[-0.1980, -0.0364, -0.5439,  ..., -0.3080, -0.6083, -0.4106],
          [-0.2883, -0.4396, -0.4127,  ..., -0.4023, -0.7421, -0.5412],
          [-0.1769, -0.3617, -0.2564,  ..., -0.3562, -0.5522, -0.4425],
          ...,
          [-0.2307,  0.2574,  0.0043,  ..., -1.0000, -0.6580, -0.1219],
          [-0.2721, -0.0510, -0.2432,  ..., -0.6160, -0.6900, -0.1341],
          [-0.4778, -0.5426, -0.2716,  ..., -0.5971, -0.6884, -0.1709]]],
        [[[-0.3191, -0.2465, -0.4732,  ..., -0.6025, -0.7549, -0.9663],
          [-0.5592, -0.3033, -0.2210,  ..., -0.5135, -0.7050, -0.9728],
          [-0.5877, -0.1883, -0.1388,  ..., -0.4058, -0.6782, -0.7262],
          ...,
          [-0.2995, -0.1215, -0.1989,  ..., -0.4578, -0.3741, -0.4037],
          [-0.2484, -0.3307, -0.5049,  ..., -0.5252, -0.4027, -0.2470],
          [-0.5050, -0.5987, -0.3749,  ..., -0.4419, -0.6641, -0.2638]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0885, -0.2428, -0.1363,  ..., -0.3349, -0.5282, -0.6354],
          [ 0.0030, -0.0114, -0.1179,  ..., -0.2224, -0.5315, -1.0000],
          [-0.1092, -0.0522, -0.2154,  ..., -0.2525, -0.4069, -0.7171],
          ...,
          [-0.0402, -0.0781, -0.1675,  ..., -0.4316, -0.5225, -0.6155],
          [-0.1827,  0.0643, -0.0146,  ..., -0.4142, -0.4382, -0.4827],
          [ 0.0373,  0.1182, -0.0184,  ..., -0.5406, -0.6694, -0.5626]]],
        [[[-0.3842, -0.3864, -0.3364,  ..., -0.4288, -0.5243, -0.5409],
          [-0.3602, -0.3566, -0.4657,  ..., -0.5628, -0.4894, -0.6972],
          [-0.4142, -0.5135, -0.3906,  ..., -0.7126, -0.4702, -0.4921],
          ...,
          [-0.3838, -0.3212, -0.3508,  ..., -0.5795, -0.7874, -0.4605],
          [-0.5655, -0.6384, -0.3505,  ..., -0.5845, -0.7017, -0.4049],
          [-0.8471, -0.6630, -0.3724,  ..., -0.5251, -0.6653, -0.3988]]],
        [[[-0.2886, -0.1843, -0.1598,  ..., -0.6750, -1.0000, -0.6516],
          [ 0.0727,  0.0815,  0.0582,  ..., -0.7573, -0.8361, -0.6582],
          [ 0.0395,  0.0723, -0.0978,  ..., -0.8227, -0.7398, -0.7283],
          ...,
          [-0.2586, -0.1390, -0.1821,  ..., -0.4581, -0.4705, -0.4959],
          [ 0.2300,  0.1653,  0.0129,  ..., -0.5081, -0.5948, -0.4699],
          [ 0.5365,  0.5949,  0.6711,  ..., -0.4890, -0.7711, -0.5220]]],
        ...,
        [[[-0.1675,  0.3659,  0.7363,  ..., -0.3300, -0.3261, -0.4885],
          [-0.2260,  0.3264,  0.7011,  ...,  0.0130, -0.2779, -0.6314],
          [-0.4230,  0.0350,  0.5187,  ...,  0.1142, -0.2566, -0.5971],
          ...,
          [ 0.1706,  0.5180,  0.6361,  ...,  0.0506, -0.3570, -0.8085],
          [ 0.1528,  0.5117,  0.6770,  ...,  0.0951, -0.3865, -0.5416],
          [-0.1053,  0.1925,  0.4794,  ...,  0.0144, -0.3359, -1.0000]]],
        [[[-0.3597, -0.0254, -0.0986,  ..., -0.6836, -0.7739, -0.6886],
          [-0.2039, -0.0252, -0.0437,  ..., -0.6505, -0.7462, -1.0000],
          [-0.2581, -0.1712,  0.0078,  ..., -0.5786, -0.7113, -0.9574],
          ...,
          [-0.1585, -0.1790, -0.1873,  ..., -0.7552, -0.5881, -0.5383],
          [-0.1859, -0.3182, -0.1817,  ..., -0.4838, -0.4453, -0.4677],
          [-0.2211, -0.2328, -0.1899,  ..., -0.4105, -0.3727, -0.4900]]],
        [[[-0.6896, -0.0761,  0.0289,  ...,  0.3640,  0.6959,  0.3981],
          [-0.6218, -0.1098,  0.0032,  ...,  0.4690,  0.7240,  0.5003],
          [-0.6176, -0.2845, -0.0200,  ...,  0.3833,  0.5650,  0.3738],
          ...,
          [-0.9002, -0.2580,  0.0951,  ...,  0.4696,  0.7301,  0.5105],
          [-0.9041, -0.3163,  0.1451,  ...,  0.4131,  0.6110,  0.2954],
          [-0.5216, -0.2073, -0.0764,  ...,  0.3168,  0.6494,  0.4152]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3047, -0.1681, -0.1609,  ..., -0.1990, -0.0469, -0.2705],
          [-0.2909, -0.1982, -0.3065,  ...,  0.0321, -0.2224, -0.4003],
          [-0.5233, -0.5219, -0.6046,  ...,  0.1052, -0.0073, -0.5357],
          ...,
          [-0.2803, -0.3502, -0.3027,  ...,  0.1930,  0.1031,  0.0302],
          [-0.3168, -0.4181, -0.2179,  ...,  0.3068,  0.3762,  0.1786],
          [-0.2588, -0.0855, -0.1555,  ...,  0.3130,  0.1114,  0.1230]]],
        [[[-0.4861, -0.6289, -0.7513,  ..., -0.4875, -0.3591, -0.4808],
          [-0.6492, -0.7004, -0.6874,  ..., -0.2598, -0.2586, -0.4188],
          [-0.6492, -0.8033, -0.8431,  ...,  0.0677, -0.0242, -0.3763],
          ...,
          [-0.2411, -0.0278, -0.0688,  ...,  0.0522, -0.1361, -0.5332],
          [-0.3748, -0.2274, -0.1050,  ..., -0.0169, -0.2105, -0.4379],
          [-0.6407, -0.4748, -0.4027,  ...,  0.0368, -0.1857, -0.4066]]],
        [[[-0.0814,  0.0681, -0.1566,  ...,  0.2147,  0.0697,  0.1508],
          [-0.0515,  0.1102, -0.2217,  ...,  0.1772,  0.0085, -0.0213],
          [-0.2961,  0.0115, -0.3566,  ...,  0.0606,  0.1158,  0.0730],
          ...,
          [-0.2635, -0.2221,  0.0411,  ..., -0.2181, -0.4278, -1.0000],
          [-0.1747,  0.1595,  0.1792,  ..., -0.2475, -0.2988, -0.3172],
          [ 0.0278,  0.3713,  0.1156,  ...,  0.0530, -0.1118, -0.1780]]],
        ...,
        [[[-0.5811, -0.6134, -0.6131,  ..., -0.0941, -0.1475, -0.2212],
          [-0.5927, -0.4317, -0.2947,  ..., -0.1487, -0.1443, -0.1878],
          [-0.4719, -0.3262, -0.1578,  ..., -0.0602,  0.0492, -0.1167],
          ...,
          [-0.8666, -0.7442, -0.7471,  ..., -0.2658, -0.2190, -0.4293],
          [-0.9220, -0.8746, -0.7982,  ..., -0.3693, -0.1013, -0.0686],
          [-0.5862, -0.6012, -0.6309,  ...,  0.0080,  0.2430,  0.2438]]],
        [[[-1.0000, -0.1111,  0.1920,  ..., -0.1289,  0.0186,  0.4008],
          [-0.9095, -0.2302, -0.0958,  ...,  0.0315,  0.1640,  0.3231],
          [-0.6157, -0.2151,  0.0201,  ..., -0.1474,  0.1165,  0.3829],
          ...,
          [-0.0896,  0.2436,  0.3452,  ..., -0.0046,  0.2219,  0.4524],
          [-0.2320,  0.3447,  0.4918,  ...,  0.2659,  0.2730,  0.2974],
          [-0.5748,  0.2206,  0.5626,  ...,  0.1453,  0.1192,  0.3523]]],
        [[[-0.3375, -0.4060, -0.3556,  ..., -0.6055, -0.4957, -0.9068],
          [-0.1456, -0.2668, -0.3790,  ..., -0.4910, -0.3637, -0.5898],
          [-0.2179, -0.2434, -0.4127,  ..., -0.4844, -0.4509, -0.6682],
          ...,
          [-0.0564, -0.1085, -0.3695,  ..., -0.5472, -0.6275, -0.5214],
          [-0.0562, -0.1314, -0.3630,  ..., -0.6135, -0.5454, -0.4148],
          [-0.2604, -0.2235, -0.1798,  ..., -0.6204, -0.7017, -0.4242]]]])
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.1990, -0.2243, -0.1775,  ..., -0.4590, -0.4786, -0.7694],
          [-0.1268, -0.2871, -0.1042,  ..., -0.4940, -0.4121, -0.7643],
          [ 0.0397,  0.0442, -0.0620,  ..., -0.4848, -0.5074, -0.6636],
          ...,
          [-0.0711,  0.0483,  0.2490,  ..., -0.5644, -0.5475, -0.5765],
          [-0.2443, -0.1308,  0.0239,  ..., -0.7287, -0.6286, -0.6220],
          [-0.3748, -0.3019, -0.1424,  ..., -0.5549, -0.7820, -0.9028]]],
        [[[ 0.0475, -0.1104, -0.2418,  ..., -0.0197, -0.2044, -0.4779],
          [ 0.0670, -0.1684, -0.1037,  ..., -0.4179, -0.1189, -0.4444],
          [-0.3791, -0.2451, -0.3725,  ..., -0.2505, -0.3975, -0.6907],
          ...,
          [-0.3504, -0.3009, -0.3308,  ..., -0.0431,  0.1156,  0.1791],
          [-0.3711, -0.4641, -0.4209,  ..., -0.2241, -0.0190,  0.1194],
          [-0.1919, -0.3054,  0.0658,  ..., -0.4600, -0.3566, -0.0981]]],
        [[[-0.5161,  0.1509,  0.0870,  ...,  0.0726,  0.0737,  0.2906],
          [-0.3680,  0.1021,  0.2662,  ...,  0.3044,  0.0073,  0.2173],
          [-0.1654,  0.3481,  0.3017,  ...,  0.2726, -0.1496,  0.2084],
          ...,
          [-0.3512,  0.2125,  0.3521,  ...,  0.2765,  0.1605,  0.2546],
          [-0.5127,  0.0463,  0.3301,  ...,  0.2508,  0.0719,  0.2741],
          [-0.6798, -0.1680,  0.3804,  ...,  0.0060, -0.0620,  0.2260]]],
        ...,
        [[[-0.4832, -0.5563, -0.8078,  ..., -0.5615, -0.2120, -0.1387],
          [-0.4795, -0.4442, -0.3407,  ..., -0.4550, -0.1296, -0.1522],
          [-0.4017, -0.2619, -0.2298,  ..., -0.5436, -0.2172, -0.2716],
          ...,
          [ 0.1441,  0.2577,  0.3055,  ..., -0.0778,  0.3437,  0.4401],
          [ 0.0797,  0.2068,  0.2702,  ...,  0.1547,  0.1871,  0.2221],
          [-0.3637, -0.2346, -0.2821,  ...,  0.1582,  0.0502,  0.1731]]],
        [[[ 0.0611,  0.0971,  0.2019,  ..., -0.1832, -0.2945, -0.5626],
          [-0.0827, -0.0469,  0.2718,  ..., -0.1731, -0.3396, -0.8178],
          [-0.1380, -0.1385,  0.1311,  ..., -0.2439, -0.5626, -0.7907],
          ...,
          [ 0.1660,  0.1866,  0.0642,  ..., -0.2742, -0.3769, -0.5049],
          [ 0.0986,  0.0161, -0.1524,  ..., -0.4963, -0.4293, -0.5002],
          [ 0.0943,  0.0192,  0.0317,  ..., -0.3563, -0.4176, -0.7089]]],
        [[[-0.7076, -0.3952, -0.0958,  ..., -0.6653, -0.2021,  0.2216],
          [-0.8906, -0.3391, -0.1219,  ..., -0.6865, -0.2543,  0.0526],
          [-0.8299, -0.4967, -0.1316,  ..., -0.3844, -0.2811,  0.2020],
          ...,
          [-0.9836, -0.4154, -0.2562,  ..., -0.6591, -0.1876,  0.1072],
          [-0.7387, -0.1068, -0.0916,  ..., -0.5028, -0.1243,  0.0150],
          [-0.6194,  0.0429,  0.0636,  ..., -0.5519, -0.2985, -0.0430]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5004, -0.7222, -0.5494,  ..., -0.2534, -0.4384, -0.6537],
          [-0.3618, -0.6185, -0.5283,  ..., -0.1825, -0.1685, -0.3129],
          [-0.4511, -0.3485, -0.5376,  ..., -0.2812, -0.0501, -0.1954],
          ...,
          [-0.5937, -0.5009, -0.2884,  ..., -0.2024, -0.3901, -0.8378],
          [-0.5895, -0.6164, -0.4501,  ..., -0.3144, -0.3891, -0.8077],
          [-0.6419, -0.6766, -0.7231,  ..., -0.4785, -0.5906, -0.6136]]],
        [[[-0.2130,  0.1205, -0.0672,  ..., -0.2111,  0.1132,  0.1617],
          [-0.0503,  0.2841, -0.1226,  ..., -0.1969,  0.0889,  0.0167],
          [ 0.4386,  0.7031,  0.5546,  ...,  0.0763,  0.0801, -0.2081],
          ...,
          [-0.3058,  0.0632,  0.0669,  ..., -0.9344, -0.5361, -0.7132],
          [-0.4315,  0.0741,  0.0964,  ..., -0.6868, -0.4102, -0.5482],
          [-0.2763,  0.0787,  0.2990,  ..., -0.5076, -0.1463, -0.2655]]],
        [[[-0.0562,  0.0353, -0.1721,  ..., -0.8402, -0.6071, -0.3957],
          [-0.1529,  0.0690,  0.0016,  ..., -0.8442, -0.4906, -0.2928],
          [ 0.0523,  0.0449,  0.0684,  ..., -0.7368, -0.6381, -0.3640],
          ...,
          [-0.3845, -0.1733,  0.0063,  ..., -0.3414, -0.3181, -0.1141],
          [-0.0428, -0.0643, -0.0660,  ..., -0.5653, -0.4044, -0.1182],
          [ 0.0035, -0.1770, -0.0220,  ..., -0.7217, -0.6254, -0.1141]]],
        ...,
        [[[-0.1834,  0.1665,  0.4060,  ..., -0.0298, -0.1352,  0.0838],
          [-0.4535,  0.1635,  0.2908,  ..., -0.1569, -0.1375,  0.1244],
          [-0.6975,  0.0543,  0.3166,  ...,  0.0979,  0.1229,  0.1748],
          ...,
          [-0.7014,  0.1462,  0.3388,  ...,  0.0822, -0.0759,  0.1409],
          [-0.3138,  0.3266,  0.5423,  ...,  0.0123, -0.0184,  0.1262],
          [-0.2748,  0.2024,  0.3873,  ..., -0.2467, -0.1084,  0.1649]]],
        [[[-0.2326, -0.2427, -0.4972,  ..., -0.3895, -0.3552, -0.4997],
          [-0.1812, -0.3346, -0.6082,  ..., -0.6129, -0.3869, -0.2823],
          [-0.0696, -0.3612, -0.4729,  ..., -0.7480, -0.7130, -0.3227],
          ...,
          [-0.1486,  0.2119,  0.0837,  ..., -0.0707, -0.1409, -0.1947],
          [ 0.0454,  0.2563,  0.3825,  ..., -0.1115, -0.2911, -0.3525],
          [ 0.0578,  0.1845,  0.2799,  ..., -0.1579, -0.1791, -0.3137]]],
        [[[-0.6439, -0.7203, -0.5793,  ..., -0.0408,  0.0082,  0.0406],
          [-0.5432, -0.9352, -0.8165,  ..., -0.0563, -0.0083, -0.0748],
          [-0.2610, -0.4275, -0.3830,  ..., -0.2910, -0.0886, -0.0170],
          ...,
          [-0.1539,  0.1163, -0.1126,  ...,  0.2447, -0.0276, -0.4486],
          [-0.2471, -0.0394, -0.3958,  ...,  0.3130,  0.0241, -0.4351],
          [-0.4339, -0.1847, -0.5087,  ...,  0.3459,  0.0636, -0.4519]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.0883, -0.1476,  0.2745,  ..., -0.4064, -0.7094, -0.8161],
          [ 0.0899,  0.1146,  0.1539,  ..., -0.4671, -0.8233, -0.8354],
          [-0.0995,  0.0940,  0.1609,  ..., -0.3722, -0.7953, -0.8695],
          ...,
          [-0.0563,  0.0049,  0.0575,  ..., -0.8871, -0.6440, -0.2901],
          [-0.1766, -0.1074, -0.1308,  ..., -0.5241, -0.7813, -0.3922],
          [-0.1327, -0.0029,  0.1581,  ..., -0.3494, -0.6143, -0.3709]]],
        [[[-0.3171,  0.1624,  0.4273,  ...,  0.3425, -0.0590, -0.1885],
          [-0.4514,  0.2985,  0.3425,  ...,  0.3116,  0.1263, -0.4962],
          [-0.6434,  0.2721,  0.4351,  ..., -0.1448, -0.0452, -0.3168],
          ...,
          [-0.5048,  0.2406,  0.3552,  ...,  0.2201, -0.1291, -0.1795],
          [-0.7868,  0.1377,  0.2715,  ...,  0.2040,  0.1866, -0.0778],
          [-0.7284,  0.1035,  0.5277,  ...,  0.2473,  0.0972, -0.2416]]],
        [[[-0.4344,  0.1659,  0.7088,  ..., -0.1032, -0.3745,  0.0496],
          [-0.2881,  0.4429,  0.5666,  ..., -0.0868, -0.3350,  0.0776],
          [-0.3090,  0.3864,  0.5434,  ...,  0.1322, -0.1244,  0.1600],
          ...,
          [-0.9769, -0.1855,  0.4491,  ...,  0.3482,  0.0869,  0.0660],
          [-0.6185,  0.0664,  0.5072,  ...,  0.3237, -0.0348,  0.0867],
          [-0.6490,  0.0650,  0.2316,  ...,  0.1237, -0.1635,  0.0680]]],
        ...,
        [[[ 0.0501,  0.0470,  0.1348,  ..., -0.0894, -0.2489, -0.3704],
          [-0.3729, -0.2682, -0.1105,  ..., -0.3246, -0.3419, -0.3735],
          [-0.5241, -0.2113, -0.1525,  ..., -0.2570, -0.1808, -0.4741],
          ...,
          [-0.0350, -0.0594, -0.2391,  ...,  0.0920, -0.0967, -0.5053],
          [-0.3827, -0.2060, -0.1709,  ..., -0.0766, -0.2090, -0.8973],
          [-0.2086, -0.1003, -0.2225,  ..., -0.2677, -0.5183, -0.8905]]],
        [[[-0.5498, -0.1550,  0.2662,  ...,  0.3055,  0.6869,  0.5496],
          [-0.7554, -0.0331,  0.2986,  ...,  0.1002,  0.5426,  0.5246],
          [-0.4472,  0.0107,  0.1110,  ...,  0.2011,  0.5792,  0.5145],
          ...,
          [-0.5963, -0.1082,  0.1921,  ...,  0.5140,  0.7328,  0.6493],
          [-0.5611, -0.3752,  0.0238,  ...,  0.3721,  0.5893,  0.4064],
          [-0.7175, -0.2497,  0.0980,  ...,  0.3474,  0.3785,  0.4119]]],
        [[[-0.2740, -0.4040, -0.1877,  ...,  0.4718,  0.2933, -0.1081],
          [-0.3095, -0.3833, -0.1229,  ...,  0.4119,  0.0494, -0.4099],
          [-0.6389, -0.7021, -0.3821,  ...,  0.4533,  0.1677, -0.0705],
          ...,
          [-0.4962, -0.4400, -0.2575,  ...,  0.2095, -0.0645, -0.1853],
          [-0.2197, -0.3829, -0.1810,  ...,  0.1846,  0.0802, -0.1934],
          [-0.3867, -0.4614, -0.1428,  ...,  0.1200, -0.0268, -0.2973]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-4.1776e-01, -1.0519e-01, -2.9470e-01,  ..., -5.3945e-01,
           -7.3436e-01, -7.5093e-01],
          [-2.7723e-01, -1.5047e-01, -3.3067e-01,  ..., -7.5940e-01,
           -8.0898e-01, -5.9989e-01],
          [-2.1886e-01, -3.1623e-01, -4.0695e-01,  ..., -4.5412e-01,
           -5.6439e-01, -3.3112e-01],
          ...,
          [-4.0024e-01, -1.2813e-02, -4.2480e-02,  ..., -2.7953e-01,
           -1.1431e-01, -5.8051e-01],
          [-5.5162e-01, -1.2024e-01, -1.3067e-01,  ..., -4.7672e-01,
           -1.9988e-01, -4.9103e-01],
          [-2.9909e-01, -4.1494e-02, -8.8224e-02,  ..., -5.0219e-01,
           -3.6115e-01, -7.4484e-01]]],
        [[[-1.7749e-01,  3.1309e-01,  1.0885e-01,  ...,  3.4604e-01,
            2.6758e-01,  2.3071e-01],
          [-1.4721e-01,  1.8142e-01, -2.9032e-02,  ...,  4.5284e-01,
            2.0526e-01,  1.5133e-01],
          [-4.3186e-01, -7.3988e-02,  1.3368e-01,  ...,  2.2398e-01,
            3.8436e-02,  2.4092e-01],
          ...,
          [ 3.4604e-02,  1.1689e-01,  4.7325e-03,  ...,  2.4996e-01,
            2.3086e-01,  3.0887e-01],
          [-6.8787e-02,  3.5122e-01,  6.2029e-01,  ...,  2.0726e-01,
            1.6883e-01,  3.6123e-01],
          [-7.3123e-02,  5.2403e-01,  8.4886e-01,  ...,  9.2098e-02,
            1.6481e-01,  2.6937e-01]]],
        [[[-4.3299e-01,  1.6750e-01,  3.2852e-01,  ..., -1.8927e-01,
           -8.7292e-02, -4.0853e-01],
          [-3.9016e-01,  1.7461e-01,  3.2507e-01,  ..., -3.1105e-01,
           -2.2953e-01, -2.8601e-01],
          [-3.3663e-01,  2.4614e-01,  4.8869e-01,  ..., -1.8841e-02,
           -1.3009e-01, -4.8546e-01],
          ...,
          [-7.7061e-01, -2.0537e-01,  8.8747e-02,  ...,  2.0186e-01,
           -1.3601e-01, -3.4645e-01],
          [-7.3144e-01, -1.4121e-01,  1.8492e-01,  ..., -9.5904e-04,
           -2.9221e-01, -5.3081e-01],
          [-4.7026e-01,  3.6302e-02, -6.8881e-02,  ..., -4.4081e-02,
           -2.1051e-01, -5.3067e-01]]],
        ...,
        [[[-2.9134e-01,  2.7780e-01,  5.1998e-01,  ..., -3.5578e-01,
           -1.1197e-01, -3.6552e-01],
          [-3.3558e-01,  2.5324e-01,  5.4048e-01,  ..., -3.8299e-01,
           -1.1918e-01, -3.1948e-01],
          [-7.0445e-01,  1.9097e-03,  3.0088e-01,  ..., -1.6563e-01,
           -2.0656e-01, -3.5416e-01],
          ...,
          [-3.2766e-01,  1.7968e-01,  2.5892e-01,  ...,  6.9470e-02,
           -4.0252e-02, -5.0561e-01],
          [-5.8364e-01,  1.7166e-01,  5.3732e-02,  ...,  7.8872e-03,
           -2.3044e-01, -3.6174e-01],
          [-2.7875e-01,  2.7722e-01,  2.2132e-01,  ..., -1.2253e-01,
           -1.4233e-01, -5.7964e-01]]],
        [[[-6.3387e-01, -2.1127e-01,  1.9222e-01,  ..., -1.6554e-01,
           -1.9343e-01, -5.4783e-01],
          [-7.4868e-01, -3.4974e-02,  3.4844e-01,  ..., -7.1570e-02,
           -4.2713e-01, -5.3976e-01],
          [-8.8722e-01, -7.3534e-02,  3.1181e-01,  ...,  3.4673e-02,
           -1.9999e-01, -4.6210e-01],
          ...,
          [-6.1742e-01, -2.1720e-02,  1.5218e-01,  ..., -2.3748e-02,
           -3.1829e-01, -4.7054e-01],
          [-4.9873e-01,  8.6144e-02,  2.5919e-01,  ..., -1.2116e-01,
           -1.9975e-01, -2.8666e-01],
          [-5.7932e-01, -1.7997e-01,  3.0403e-01,  ..., -2.1061e-01,
            3.3106e-03, -2.4049e-01]]],
        [[[-5.3062e-02, -2.2181e-01, -3.8316e-01,  ..., -5.0738e-02,
           -2.7839e-01, -3.7329e-01],
          [-3.7363e-02, -8.1982e-02, -1.0712e-02,  ..., -2.4392e-01,
           -4.7880e-01, -6.8195e-01],
          [ 3.1936e-02, -1.8465e-01, -1.3069e-02,  ..., -1.6578e-01,
           -2.0589e-01, -6.3687e-01],
          ...,
          [ 2.8373e-01,  2.6078e-01,  2.2300e-02,  ..., -3.5697e-01,
           -5.2406e-01, -6.2977e-01],
          [ 3.5258e-02,  1.4698e-01,  2.0844e-02,  ..., -3.7017e-01,
           -4.6744e-01, -6.4394e-01],
          [-9.4007e-02,  3.8326e-04, -1.7657e-01,  ...,  3.2604e-02,
           -1.8181e-01, -6.1407e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3548, -0.1639, -0.1359,  ..., -0.5299, -0.6856, -0.6306],
          [-0.3397, -0.1885, -0.0519,  ..., -0.5247, -0.5952, -0.6225],
          [-0.2918, -0.1547,  0.0952,  ..., -0.3472, -0.5062, -0.6593],
          ...,
          [-0.1838,  0.0529,  0.0590,  ..., -0.4057, -0.4123, -0.6072],
          [-0.1331, -0.1573, -0.1494,  ..., -0.2766, -0.4651, -0.5965],
          [-0.0842, -0.2470, -0.3249,  ..., -0.2815, -0.4219, -0.7162]]],
        [[[-0.1868,  0.0061,  0.1548,  ..., -0.0911,  0.0283,  0.0978],
          [-0.0335,  0.1091, -0.0281,  ..., -0.1449, -0.0095,  0.0197],
          [-0.2203, -0.2920, -0.3176,  ..., -0.0995, -0.2825, -0.1418],
          ...,
          [-0.3994, -0.6598, -0.1192,  ..., -0.1315,  0.2074,  0.6457],
          [-0.5771, -0.4683, -0.1549,  ..., -0.4107,  0.1072,  0.5963],
          [-0.7238, -0.4333, -0.4279,  ..., -0.2822, -0.0140,  0.5318]]],
        [[[-0.0820, -0.0146, -0.0663,  ..., -0.3967, -0.4775, -0.3850],
          [-0.1392,  0.0301, -0.1300,  ..., -0.5593, -0.4423, -0.4423],
          [ 0.0020,  0.0213, -0.2366,  ..., -0.3818, -0.4002, -0.6079],
          ...,
          [-0.0443,  0.0580,  0.1381,  ..., -0.4276, -0.4807, -0.4127],
          [ 0.0934,  0.1217,  0.2468,  ..., -0.3187, -0.4491, -0.5526],
          [ 0.1061,  0.1965,  0.2195,  ..., -0.2115, -0.4108, -0.5673]]],
        ...,
        [[[-0.3353,  0.1288,  0.1876,  ...,  0.1715,  0.1653, -0.5472],
          [-0.3156,  0.1046, -0.0337,  ...,  0.1168,  0.1615, -0.4786],
          [-0.4321, -0.0823,  0.1447,  ...,  0.2582,  0.1367, -0.5364],
          ...,
          [-0.7434, -0.1971, -0.0387,  ...,  0.1504, -0.0328, -0.4916],
          [-0.7966, -0.5059, -0.4185,  ..., -0.0061, -0.1987, -0.8154],
          [-0.5912, -0.3148, -0.1122,  ...,  0.3594,  0.0785, -0.4734]]],
        [[[-0.6943, -0.5569, -0.0247,  ..., -0.3913, -0.5301, -0.6396],
          [-0.8505, -0.4705,  0.0039,  ..., -0.2210, -0.3941, -0.7070],
          [-0.8155, -0.2484,  0.0710,  ..., -0.1383, -0.2995, -0.6548],
          ...,
          [-0.4922,  0.0750,  0.1045,  ..., -0.0745, -0.4485, -0.7905],
          [-0.4356,  0.0179,  0.2015,  ..., -0.0662, -0.3845, -0.4564],
          [-0.4503,  0.0795,  0.3783,  ..., -0.2402, -0.3466, -0.4397]]],
        [[[-0.1139, -0.2127, -0.0748,  ..., -0.1851,  0.0123, -0.1456],
          [-0.0549, -0.0273,  0.0979,  ..., -0.0022,  0.0827, -0.3620],
          [-0.1556, -0.0034,  0.2082,  ...,  0.0575,  0.1151, -0.4170],
          ...,
          [-0.1515,  0.0907, -0.0543,  ..., -0.0082, -0.0189,  0.1535],
          [-0.0590,  0.0095, -0.3033,  ...,  0.0079, -0.0786,  0.1053],
          [-0.3757, -0.2076, -0.1570,  ..., -0.0953, -0.1568, -0.0384]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0460, -0.1008,  0.0503,  ..., -0.0116, -0.1850, -0.5149],
          [ 0.0634, -0.2325, -0.2811,  ..., -0.3276, -0.0548, -0.1973],
          [-0.0027, -0.4886, -0.0118,  ..., -0.1878, -0.1793, -0.0645],
          ...,
          [-0.0956,  0.2462,  0.1972,  ..., -0.1062, -0.2873,  0.0501],
          [ 0.1130,  0.2154, -0.2774,  ..., -0.2123, -0.2361, -0.0091],
          [-0.1220, -0.0649, -0.7724,  ..., -0.4797, -0.4239, -0.2470]]],
        [[[ 0.1564,  0.6017,  0.7221,  ...,  0.1901, -0.1367, -0.9507],
          [ 0.0571,  0.6570,  0.5724,  ...,  0.2059, -0.0524, -0.5536],
          [ 0.0267,  0.5373,  0.6754,  ...,  0.1242, -0.0901, -0.4581],
          ...,
          [-0.2095, -0.0677,  0.5509,  ...,  0.0487, -0.0962, -0.3765],
          [-0.2452,  0.2080,  0.6044,  ...,  0.0763, -0.2184, -0.4355],
          [-0.2404,  0.2596,  0.5121,  ...,  0.0805, -0.2462, -0.5470]]],
        [[[ 0.2229,  0.1753, -0.0017,  ..., -0.1306, -0.1453, -0.5125],
          [ 0.1926,  0.1589,  0.1221,  ..., -0.0180, -0.0745, -0.2841],
          [ 0.0768,  0.0865,  0.2012,  ..., -0.0996, -0.2670, -0.3215],
          ...,
          [ 0.4126,  0.2664, -0.0373,  ..., -0.1832, -0.4629, -0.5707],
          [ 0.1949,  0.2789,  0.0049,  ..., -0.3408, -0.6536, -0.7085],
          [ 0.1268,  0.1802, -0.0970,  ..., -0.2846, -0.5490, -0.8689]]],
        ...,
        [[[-0.4732,  0.1995,  0.5979,  ...,  0.1621,  0.0793, -0.3924],
          [-0.3237,  0.1545,  0.4253,  ..., -0.0127,  0.2191, -0.4716],
          [-0.2656,  0.3218,  0.4106,  ..., -0.0470,  0.2384, -0.3626],
          ...,
          [-0.3822,  0.1475,  0.2096,  ..., -0.1802,  0.0135, -0.6579],
          [-0.2756,  0.2266,  0.5606,  ...,  0.1291,  0.2305, -0.2531],
          [-0.2042,  0.2271,  0.4982,  ...,  0.1494,  0.2825, -0.4542]]],
        [[[-0.4619,  0.1266,  0.1546,  ..., -0.0377, -0.2329, -0.2492],
          [-0.4731,  0.3419,  0.5232,  ..., -0.0836, -0.1714, -0.3867],
          [-0.4590,  0.2007,  0.5158,  ...,  0.2700,  0.0209, -0.3619],
          ...,
          [-0.4057,  0.3794,  0.5736,  ...,  0.0277, -0.2873, -0.5149],
          [-0.6189,  0.1091,  0.3600,  ..., -0.1109, -0.1865, -0.3666],
          [-0.6170, -0.1613,  0.0652,  ..., -0.1099, -0.2083, -0.4281]]],
        [[[-0.7162, -0.0471,  0.1538,  ..., -0.4745, -0.3805, -0.5386],
          [-0.5456, -0.1016,  0.1055,  ..., -0.3240, -0.5213, -0.3317],
          [-0.6094,  0.0367,  0.2295,  ..., -0.2504, -0.4411, -0.4526],
          ...,
          [-0.7294, -0.3843,  0.1594,  ..., -0.3410, -0.2624, -0.5171],
          [-0.6884, -0.3621,  0.2017,  ..., -0.4942, -0.2240, -0.4355],
          [-0.5456, -0.1412,  0.1422,  ..., -0.4988, -0.4645, -0.4021]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4634, -0.3654, -0.3908,  ..., -0.4663, -0.0179, -0.0139],
          [-0.2820, -0.1301, -0.0643,  ..., -0.2729, -0.0586, -0.0402],
          [-0.0046, -0.0102, -0.0889,  ...,  0.2235,  0.2623,  0.0878],
          ...,
          [-0.1612, -0.1684,  0.0608,  ...,  0.2722,  0.1218, -0.2350],
          [-0.1529, -0.3559, -0.0889,  ...,  0.1104,  0.0102, -0.1479],
          [-0.0903, -0.1153,  0.1341,  ..., -0.2433,  0.0320, -0.0168]]],
        [[[-0.3337,  0.3359,  0.2989,  ..., -0.2992, -0.6819, -0.9237],
          [-0.2738,  0.3843,  0.2915,  ..., -0.2666, -0.6456, -0.6832],
          [ 0.2165,  0.5627,  0.5172,  ..., -0.1668, -0.6772, -0.8292],
          ...,
          [ 0.4986,  0.7454,  0.5093,  ..., -0.4947, -0.7012, -0.5504],
          [ 0.6311,  0.8696,  0.4739,  ..., -0.4205, -0.5351, -0.5275],
          [ 0.3945,  0.6548,  0.3420,  ..., -0.4508, -0.5722, -0.4633]]],
        [[[-0.2527,  0.3788,  0.6237,  ...,  0.0419, -0.1920, -0.6998],
          [-0.2577,  0.2826,  0.5443,  ..., -0.2164, -0.3155, -0.4673],
          [-0.2634,  0.2005,  0.3691,  ..., -0.0198, -0.2601, -0.4852],
          ...,
          [-0.3652,  0.1765,  0.0792,  ...,  0.1746, -0.2711, -0.7061],
          [-0.2467,  0.2169,  0.2500,  ...,  0.0201, -0.1358, -0.8000],
          [-0.3500,  0.0541,  0.5625,  ..., -0.0931, -0.1925, -0.5918]]],
        ...,
        [[[-0.5345, -0.2327,  0.1717,  ...,  0.0807, -0.0860, -0.5870],
          [-0.6162, -0.2886,  0.2666,  ...,  0.0143, -0.0777, -0.5688],
          [-0.8600, -0.3723,  0.2401,  ..., -0.2853, -0.3018, -0.8331],
          ...,
          [-0.6401, -0.1708,  0.0972,  ..., -0.1031, -0.2102, -0.5124],
          [-0.7262, -0.1241,  0.0018,  ..., -0.1447, -0.2812, -0.9981],
          [-0.6782, -0.0956,  0.0375,  ...,  0.1436, -0.1858, -0.5912]]],
        [[[-0.3013, -0.4454, -0.5409,  ..., -0.5077, -0.4664, -0.3680],
          [-0.6235, -0.5770, -0.5546,  ..., -0.6432, -0.4108, -0.4341],
          [-0.7509, -0.5440, -0.3992,  ..., -0.7482, -0.7480, -0.7926],
          ...,
          [-0.1682, -0.1736, -0.2172,  ..., -0.3095, -0.2481,  0.0777],
          [-0.2255, -0.0756, -0.0382,  ..., -0.5347, -0.1571,  0.0795],
          [-0.3415, -0.2410, -0.0429,  ..., -0.6841, -0.3245, -0.0555]]],
        [[[-0.9851, -0.5220,  0.2108,  ..., -0.2465, -0.2123, -0.7819],
          [-0.9342, -0.5656,  0.0426,  ..., -0.3503, -0.1883, -0.3650],
          [-0.3440,  0.1087,  0.2136,  ..., -0.4253, -0.4270, -0.6561],
          ...,
          [-0.5651, -0.1883,  0.1410,  ...,  0.0263, -0.2752, -0.5193],
          [-0.4454, -0.1090,  0.0286,  ..., -0.1810, -0.6429, -0.5545],
          [-0.4619,  0.1914,  0.1207,  ..., -0.2989, -0.5502, -0.7892]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-2.7243e-01, -4.0090e-03, -1.9474e-01,  ..., -4.2321e-02,
           -4.4845e-01, -4.1631e-01],
          [-1.9550e-01, -9.0785e-02,  1.2892e-01,  ...,  5.7744e-03,
           -3.9616e-01, -3.5413e-01],
          [ 3.0740e-01,  3.5141e-01,  1.9712e-01,  ..., -5.8674e-02,
           -3.3246e-01, -1.0924e-01],
          ...,
          [-8.2474e-02, -1.3255e-01,  1.7877e-01,  ..., -1.1717e-01,
           -3.8886e-01,  4.8970e-02],
          [ 2.4279e-01,  2.5022e-01,  2.1120e-01,  ..., -3.2787e-01,
           -3.1451e-01,  1.8042e-01],
          [ 1.3371e-01,  3.9569e-01,  2.8432e-01,  ..., -4.7733e-01,
           -1.1150e-01,  2.6166e-01]]],
        [[[-6.2950e-02,  2.2160e-01,  6.5756e-02,  ..., -4.4478e-01,
           -5.5584e-01, -3.4351e-01],
          [-1.2577e-01,  3.0302e-02, -1.1855e-01,  ..., -7.7799e-01,
           -5.9839e-01, -2.4497e-01],
          [-3.5387e-02, -1.8141e-01, -2.0475e-01,  ..., -8.9893e-01,
           -3.8743e-01, -7.1554e-02],
          ...,
          [ 2.5953e-02, -1.1221e-02, -7.6430e-02,  ..., -4.1200e-01,
           -4.4634e-01, -1.6093e-01],
          [-3.0993e-01,  9.1339e-02, -9.0863e-02,  ..., -2.6019e-01,
           -2.4569e-01, -1.1819e-01],
          [-5.8029e-01, -1.2872e-01, -3.5332e-01,  ..., -4.9710e-01,
           -3.6678e-01, -1.3490e-01]]],
        [[[-5.1175e-01, -2.3248e-01, -4.7730e-01,  ...,  4.8587e-02,
           -3.6993e-02, -4.2491e-01],
          [-5.1450e-01, -4.8337e-01, -5.6672e-01,  ...,  7.6259e-02,
           -1.7893e-01, -5.3627e-01],
          [-8.4369e-01, -5.4294e-01, -3.8580e-01,  ...,  1.3237e-01,
           -5.8833e-02, -3.6689e-01],
          ...,
          [-4.3776e-01, -6.3354e-04,  2.3142e-01,  ...,  3.7917e-02,
            8.8730e-02, -2.2887e-01],
          [-5.9390e-01, -2.3754e-01, -1.8780e-01,  ...,  1.5171e-01,
            8.6810e-02, -4.3706e-01],
          [-5.5587e-01, -5.1467e-01, -6.4563e-01,  ...,  2.1937e-01,
            9.0361e-02, -5.3237e-01]]],
        ...,
        [[[ 1.0206e-01,  4.5307e-01,  4.0428e-01,  ..., -5.8746e-01,
           -7.4058e-01, -7.2716e-01],
          [ 2.3927e-02,  5.0098e-01,  4.7962e-01,  ..., -4.0566e-01,
           -6.0785e-01, -6.6786e-01],
          [-2.1100e-01,  2.3270e-01,  2.9975e-01,  ..., -4.7292e-01,
           -7.0697e-01, -5.7467e-01],
          ...,
          [ 1.5206e-01,  8.7695e-02, -1.0473e-02,  ..., -5.1922e-01,
           -4.4911e-01, -6.3585e-01],
          [ 8.3662e-02,  4.0311e-02,  9.6231e-03,  ..., -4.3397e-01,
           -3.9010e-01, -7.3990e-01],
          [ 1.7387e-01,  1.3647e-01,  2.9747e-02,  ..., -2.3105e-01,
           -3.3766e-01, -6.0899e-01]]],
        [[[-3.9167e-01, -3.1788e-01, -3.6254e-01,  ...,  1.3097e-01,
            1.5110e-02,  5.5708e-03],
          [-4.0294e-01, -1.7412e-01, -3.4430e-01,  ...,  4.7774e-03,
            1.6455e-01, -6.1246e-02],
          [-2.6038e-01, -2.0688e-01, -2.8579e-01,  ...,  4.4362e-02,
            2.4524e-02, -3.0672e-01],
          ...,
          [-5.6998e-01, -3.3316e-01, -3.5771e-01,  ...,  4.6383e-01,
            1.2490e-01, -1.7846e-01],
          [-3.5218e-01, -2.4973e-01, -4.0438e-01,  ...,  4.8548e-01,
            3.5727e-01, -2.9426e-01],
          [-3.8727e-01, -6.5893e-02, -2.0068e-01,  ...,  5.1704e-01,
            3.8966e-01, -2.1266e-01]]],
        [[[-4.3139e-01, -3.2572e-01, -1.6767e-01,  ..., -3.9639e-01,
           -4.5340e-01, -4.5967e-01],
          [-1.8481e-01, -4.6217e-01, -2.5782e-01,  ..., -4.4927e-01,
           -6.8677e-01, -6.0415e-01],
          [-8.3461e-02, -4.7555e-01, -4.6462e-01,  ..., -6.1136e-01,
           -6.9039e-01, -6.7402e-01],
          ...,
          [-2.4465e-01, -1.1329e-01, -1.5160e-01,  ..., -3.7109e-01,
           -6.8757e-01, -7.9738e-01],
          [-2.8187e-01, -6.0696e-02,  7.9799e-02,  ..., -4.0286e-01,
           -5.5886e-01, -7.0977e-01],
          [-2.8302e-01, -1.0996e-01,  1.0258e-01,  ..., -3.3526e-01,
           -4.6692e-01, -7.0774e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.1928,  0.2689,  0.4483,  ..., -0.8180, -0.4866, -0.1514],
          [ 0.0789,  0.2095,  0.0989,  ..., -0.6582, -0.4615, -0.1612],
          [-0.1499,  0.2122, -0.0820,  ..., -0.6634, -0.4749, -0.1163],
          ...,
          [ 0.2863,  0.2202, -0.2771,  ..., -0.5141, -0.4479, -0.4424],
          [ 0.2446,  0.4025,  0.3050,  ..., -0.2338, -0.4201, -0.3343],
          [-0.0223,  0.4915,  0.5602,  ..., -0.4400, -0.6681, -0.3703]]],
        [[[-0.2632, -0.3839, -0.2853,  ..., -0.3132, -0.3005, -0.1203],
          [-0.1555, -0.3017, -0.1995,  ..., -0.4679, -0.3071, -0.0698],
          [-0.0711, -0.0030,  0.1029,  ..., -0.3850, -0.3776, -0.2916],
          ...,
          [-0.1223, -0.2044,  0.0490,  ..., -0.2559, -0.3801,  0.0731],
          [-0.0922, -0.0200, -0.0398,  ..., -0.1416, -0.3426,  0.0132],
          [-0.0020,  0.0778,  0.1724,  ..., -0.1898, -0.5056, -0.1118]]],
        [[[-0.2462, -0.1101, -0.1763,  ..., -0.1086,  0.1075, -0.0170],
          [-0.0123,  0.1686,  0.0602,  ..., -0.1199, -0.0742, -0.1039],
          [-0.0536,  0.0994,  0.0623,  ...,  0.2156,  0.3642,  0.1516],
          ...,
          [-0.2143, -0.0952,  0.0489,  ..., -0.1581, -0.1717, -0.3045],
          [-0.2180, -0.3064, -0.1484,  ..., -0.1691, -0.1183, -0.3707],
          [-0.1534, -0.2415, -0.2772,  ..., -0.3601, -0.2580, -0.4735]]],
        ...,
        [[[-0.6432, -0.3502, -0.4415,  ..., -0.0882, -0.2841, -0.4412],
          [-0.6959, -0.4757, -0.6403,  ..., -0.1704, -0.3973, -0.3053],
          [-0.5919, -0.6503, -0.8197,  ..., -0.2563, -0.1738, -0.1104],
          ...,
          [-0.5343, -0.8907, -0.6459,  ..., -0.1768, -0.3705, -0.1719],
          [-0.5949, -0.5395, -0.6215,  ..., -0.1764, -0.1848, -0.0763],
          [-0.6561, -0.5655, -0.7090,  ..., -0.3082, -0.3188, -0.1284]]],
        [[[ 0.0159, -0.0264,  0.3374,  ...,  0.0352, -0.1385,  0.5959],
          [-0.1825,  0.0381,  0.4245,  ...,  0.1372, -0.1083,  0.5901],
          [-0.2232,  0.2500,  0.5400,  ...,  0.1880,  0.0930,  0.5976],
          ...,
          [-0.2725,  0.2049,  0.2981,  ...,  0.1605,  0.2686,  0.5839],
          [-0.2684,  0.2562,  0.5663,  ...,  0.2002,  0.2209,  0.5878],
          [-0.2198,  0.3581,  0.5858,  ...,  0.2505,  0.0547,  0.6090]]],
        [[[-0.5651,  0.0014, -0.0064,  ..., -0.6234, -0.4649, -0.7246],
          [-0.7350, -0.0691, -0.0566,  ..., -0.4683, -0.4210, -0.8271],
          [-0.6700, -0.2597, -0.0967,  ..., -0.1072, -0.3089, -0.6042],
          ...,
          [-0.5945,  0.1957,  0.3619,  ..., -0.1306, -0.2010, -0.4201],
          [-0.4481,  0.1868,  0.3577,  ..., -0.1551, -0.2411, -0.4249],
          [-0.5297, -0.1213,  0.2627,  ..., -0.2408, -0.4348, -0.5002]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0851, -0.0984,  0.0930,  ...,  0.2867,  0.0413, -0.5133],
          [-0.1051, -0.0748,  0.2574,  ...,  0.1694, -0.3075, -0.8506],
          [-0.2272,  0.2952,  0.2425,  ...,  0.2007,  0.0391, -0.5680],
          ...,
          [ 0.1589,  0.2024, -0.0520,  ..., -0.0133, -0.2770, -0.6551],
          [ 0.1897,  0.2105, -0.0565,  ..., -0.0473, -0.1831, -0.6374],
          [ 0.0514,  0.3720,  0.1492,  ..., -0.1139, -0.1265, -0.6727]]],
        [[[-0.6878, -0.3595, -0.3087,  ..., -0.2888, -0.0519,  0.2555],
          [-0.7201, -0.1512, -0.2420,  ..., -0.3305, -0.2101,  0.1314],
          [-0.7700, -0.0286,  0.1548,  ..., -0.2831, -0.1704,  0.2207],
          ...,
          [-0.6377, -0.0992, -0.0493,  ..., -0.6084, -0.0584,  0.1130],
          [-0.5349,  0.0206,  0.0594,  ..., -0.5395,  0.0205,  0.2306],
          [-0.5501, -0.1723,  0.0353,  ..., -0.4546, -0.2012,  0.0239]]],
        [[[-0.7950,  0.0201,  0.4173,  ..., -0.0870, -0.3563, -0.4240],
          [-0.5222, -0.0967,  0.1087,  ..., -0.3385, -0.4775, -0.4539],
          [-0.3794, -0.1080, -0.3654,  ..., -0.1994, -0.5236, -0.5379],
          ...,
          [-0.2908,  0.2553,  0.3818,  ..., -0.1285, -0.2417, -0.4416],
          [-0.3496,  0.2934,  0.2920,  ..., -0.3476, -0.3707, -0.4838],
          [-0.6575,  0.2998,  0.5191,  ..., -0.1443, -0.3282, -0.5544]]],
        ...,
        [[[-0.5751, -0.2522, -0.2628,  ...,  0.4669,  0.1902, -0.2191],
          [-0.3038, -0.2566, -0.2544,  ...,  0.3151,  0.1632, -0.1047],
          [-0.1994, -0.2229, -0.2895,  ...,  0.1864, -0.0266, -0.1577],
          ...,
          [-0.3104, -0.3065, -0.4986,  ...,  0.2501,  0.3828,  0.3362],
          [-0.2688, -0.3341, -0.2799,  ...,  0.3057,  0.3362,  0.1904],
          [-0.3531, -0.1078, -0.1255,  ...,  0.2671,  0.0720, -0.0036]]],
        [[[ 0.1082, -0.1673, -0.0113,  ..., -0.0158, -0.1595, -0.7472],
          [ 0.1094, -0.1041, -0.0532,  ..., -0.0722, -0.2078, -0.5992],
          [ 0.0924,  0.1777, -0.0871,  ..., -0.0818, -0.4678, -0.4217],
          ...,
          [-0.1324, -0.0182,  0.3337,  ..., -0.0109, -0.1391, -0.0333],
          [-0.0753,  0.0086,  0.2659,  ..., -0.1200, -0.1876,  0.0708],
          [ 0.1642,  0.1501,  0.2395,  ..., -0.0609, -0.2289,  0.0346]]],
        [[[-0.2736, -0.2655, -0.1032,  ...,  0.1185,  0.0417,  0.4197],
          [-0.2822, -0.2296,  0.2096,  ...,  0.1985, -0.0770,  0.3602],
          [-0.3048,  0.0342,  0.3293,  ..., -0.0071,  0.0988,  0.4062],
          ...,
          [-0.4225,  0.1511,  0.4959,  ...,  0.1158,  0.0940,  0.3925],
          [-0.4509,  0.2516,  0.2722,  ...,  0.2001,  0.0736,  0.3766],
          [-0.1099,  0.3667,  0.3989,  ...,  0.4012,  0.0639,  0.4249]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-6.5897e-01, -5.5866e-01, -4.7432e-01,  ..., -2.2362e-01,
           -1.7136e-03, -3.1300e-01],
          [-5.3855e-01, -2.5889e-01, -4.6731e-01,  ...,  1.5412e-01,
            2.5495e-01, -1.8103e-01],
          [-3.3334e-01, -2.4151e-01, -2.5614e-01,  ...,  1.4773e-01,
            3.4277e-01,  4.1354e-02],
          ...,
          [-5.7585e-01, -2.7917e-01, -5.5252e-01,  ...,  8.6278e-02,
           -1.9560e-01, -5.7226e-01],
          [-3.2797e-01, -1.8966e-01, -5.3043e-01,  ...,  1.0486e-01,
           -2.6337e-01, -4.1858e-01],
          [-3.6028e-01, -4.4378e-01, -3.8837e-01,  ...,  5.7007e-02,
           -2.2012e-01, -4.5107e-01]]],
        [[[-1.8929e-01, -7.6283e-02,  4.5793e-03,  ..., -6.9298e-01,
           -7.4615e-01, -4.5454e-01],
          [-2.0319e-01, -3.7837e-01, -3.3257e-02,  ..., -6.1972e-01,
           -8.0388e-01, -5.4156e-01],
          [-3.5398e-01, -1.0839e-01,  2.7513e-02,  ..., -7.2975e-01,
           -7.7818e-01, -4.6659e-01],
          ...,
          [-3.4398e-01, -2.0363e-01, -1.7079e-01,  ..., -4.3971e-01,
           -6.2958e-01, -4.4135e-01],
          [-1.6246e-01,  2.9883e-02,  1.2930e-01,  ..., -7.4672e-01,
           -7.2497e-01, -4.9297e-01],
          [-2.7918e-01, -1.1875e-01,  9.0544e-02,  ..., -6.1338e-01,
           -6.3398e-01, -6.1539e-01]]],
        [[[-3.2574e-01,  3.0743e-02,  3.0766e-01,  ...,  6.2638e-02,
           -7.2039e-02, -3.6677e-01],
          [-3.9438e-01, -7.9993e-02,  1.9391e-01,  ..., -5.9798e-02,
           -1.3131e-01, -4.9450e-01],
          [-4.2713e-01, -1.4869e-01,  1.7708e-01,  ..., -1.0429e-01,
           -1.1893e-01, -3.7342e-01],
          ...,
          [-4.9217e-01,  1.5122e-01,  2.6248e-03,  ..., -1.8537e-01,
           -2.0286e-01, -3.8716e-01],
          [-3.6267e-01,  2.4204e-01,  9.6899e-02,  ..., -5.4262e-03,
           -2.7073e-01, -3.9076e-01],
          [-4.2002e-01,  1.2285e-01,  1.8210e-01,  ...,  1.4736e-01,
           -2.1174e-01, -4.4550e-01]]],
        ...,
        [[[-9.9668e-02,  2.8385e-02, -1.0375e-01,  ..., -7.6892e-01,
           -5.5436e-01, -2.3594e-01],
          [ 7.7803e-02, -9.3659e-02, -4.0264e-01,  ..., -6.7126e-01,
           -7.2124e-01, -2.7715e-01],
          [-6.1287e-02, -1.4321e-01, -3.1403e-01,  ..., -8.7981e-01,
           -5.7813e-01, -2.7144e-01],
          ...,
          [ 1.7723e-01,  1.1157e-01, -3.4364e-01,  ..., -7.0468e-01,
           -6.4767e-01, -7.6821e-01],
          [ 2.2856e-01, -1.2330e-01, -4.9227e-01,  ..., -6.8692e-01,
           -4.5375e-01, -4.0400e-01],
          [ 7.3135e-02, -1.2389e-01, -2.8396e-01,  ..., -7.7062e-01,
           -5.4546e-01, -4.4108e-01]]],
        [[[-7.1607e-02,  2.7195e-01,  3.0737e-01,  ..., -9.2974e-02,
           -8.4980e-02, -1.8919e-01],
          [ 2.3249e-02,  2.6767e-01,  2.2757e-01,  ..., -2.4270e-01,
           -2.1598e-01, -1.0583e-01],
          [ 2.5759e-01,  4.7764e-01,  4.0829e-01,  ..., -9.3343e-02,
           -2.3774e-01, -1.0682e-01],
          ...,
          [ 1.7399e-01,  5.3502e-02, -2.4550e-02,  ..., -2.5487e-02,
           -1.4583e-01, -3.9195e-01],
          [ 2.2221e-02, -1.2844e-03,  8.6468e-03,  ..., -1.8022e-01,
           -4.0029e-01, -4.1484e-01],
          [ 7.4443e-02,  1.8908e-02, -6.3392e-02,  ..., -9.4351e-02,
           -3.6781e-01, -3.6898e-01]]],
        [[[-8.9008e-02,  3.5770e-01,  5.1945e-01,  ...,  3.9687e-01,
            2.5704e-01,  5.2842e-02],
          [-8.7836e-02,  2.4687e-01,  2.7206e-01,  ...,  3.7358e-01,
            2.9659e-01,  5.9837e-03],
          [-1.4932e-01,  3.6983e-01,  6.5559e-01,  ...,  3.2890e-01,
            1.2918e-01, -1.3711e-01],
          ...,
          [-3.8821e-01,  7.0286e-02,  6.0854e-01,  ...,  6.5053e-04,
            2.5200e-01,  5.6936e-02],
          [-3.0509e-01,  1.7465e-01,  3.4046e-01,  ..., -5.4692e-02,
            1.4139e-01,  1.3169e-02],
          [-4.5014e-01,  1.6787e-02,  2.7231e-01,  ..., -6.1267e-02,
           -2.1136e-02,  6.2501e-04]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 2.6479e-02,  3.7609e-01,  5.8895e-01,  ...,  1.7514e-01,
           -3.1906e-01, -7.8870e-01],
          [-7.4117e-03,  3.5771e-01,  5.1562e-01,  ...,  1.9681e-01,
           -1.7366e-01, -7.6020e-01],
          [-8.0000e-02,  3.4394e-01,  6.7893e-01,  ...,  5.1439e-02,
           -1.2558e-01, -6.0056e-01],
          ...,
          [-1.2454e-01,  2.6472e-01,  5.1099e-01,  ..., -1.4335e-01,
           -5.4139e-01, -7.8721e-01],
          [-3.2419e-01,  1.0213e-01,  3.0220e-01,  ..., -3.7589e-01,
           -7.2810e-01, -8.9895e-01],
          [-1.7121e-01,  3.4253e-01,  5.9654e-01,  ..., -6.9654e-02,
           -7.6211e-01, -1.0000e+00]]],
        [[[-4.0906e-01, -2.6052e-01, -2.5126e-01,  ..., -8.6734e-01,
           -8.8524e-01, -6.8177e-01],
          [-5.2865e-01, -5.2777e-01, -5.4557e-01,  ..., -4.5870e-01,
           -6.6603e-01, -6.7317e-01],
          [-4.5158e-01, -4.3872e-01, -4.1630e-01,  ..., -3.8500e-01,
           -2.7728e-01, -7.2174e-01],
          ...,
          [-4.0310e-01, -1.3974e-01, -3.8069e-01,  ..., -1.6963e-01,
            3.3247e-03,  1.1017e-01],
          [-3.5062e-01, -1.5096e-01, -3.6758e-01,  ..., -2.1064e-01,
           -1.2933e-01, -1.0401e-01],
          [-6.4976e-01, -3.5955e-01, -3.5377e-01,  ..., -3.8131e-01,
           -1.9601e-01, -2.0725e-01]]],
        [[[-7.7042e-01, -5.7369e-01, -3.3739e-01,  ...,  3.3015e-01,
            8.7188e-02, -2.7853e-01],
          [-7.7645e-01, -5.4959e-01, -4.6119e-01,  ...,  3.5127e-01,
           -2.5708e-02, -3.7345e-01],
          [-7.2673e-01, -5.6081e-01, -3.2701e-01,  ...,  3.2477e-01,
            7.4869e-02, -6.0797e-01],
          ...,
          [-5.2193e-01, -2.9615e-01, -2.8644e-01,  ...,  2.5520e-01,
            4.2528e-02,  1.7548e-01],
          [-5.4714e-01, -4.2889e-01, -2.5684e-01,  ...,  2.8306e-01,
            2.0084e-01,  2.2077e-01],
          [-5.5029e-01, -4.5456e-01, -3.8566e-01,  ...,  3.8093e-01,
            1.7396e-01, -1.4081e-02]]],
        ...,
        [[[ 8.2452e-02, -6.3562e-04, -2.0800e-01,  ..., -3.2409e-01,
           -3.3398e-01, -7.4180e-01],
          [-2.8129e-01, -1.7251e-01, -1.7024e-01,  ..., -2.9413e-01,
           -3.7694e-01, -5.5382e-01],
          [-2.1096e-01, -1.7138e-01, -1.8627e-01,  ..., -2.3905e-01,
           -4.2027e-01, -7.8344e-01],
          ...,
          [-2.3671e-01, -9.2024e-02, -2.1954e-01,  ..., -4.4840e-01,
           -3.9444e-01, -5.1602e-01],
          [-4.3475e-01, -4.3891e-01, -5.5093e-02,  ..., -3.8442e-01,
           -6.2397e-01, -6.9193e-01],
          [-2.3436e-01, -3.7520e-01, -8.3705e-02,  ..., -4.1299e-01,
           -7.2299e-01, -1.0000e+00]]],
        [[[-2.3056e-01,  3.9252e-02,  5.7566e-02,  ...,  6.9912e-02,
            9.0367e-02, -4.5198e-01],
          [-4.4329e-01, -1.7597e-01,  8.9448e-02,  ..., -2.8998e-01,
           -7.3176e-02, -3.6869e-01],
          [-2.2815e-01, -2.6429e-01,  7.2856e-02,  ..., -5.2239e-01,
            4.8202e-03, -1.6350e-01],
          ...,
          [ 2.9679e-01,  2.8133e-01, -4.0077e-02,  ..., -7.3881e-01,
           -5.5028e-01, -6.7702e-01],
          [ 1.4185e-01, -1.6598e-02, -1.5528e-01,  ..., -4.2232e-01,
           -5.4871e-01, -3.8225e-01],
          [ 3.2144e-01,  6.9895e-02, -7.1567e-02,  ..., -5.3624e-01,
           -6.0301e-01, -3.9428e-01]]],
        [[[-5.0702e-01,  1.4468e-01,  4.7354e-01,  ..., -3.0649e-01,
           -1.8943e-01,  3.1449e-01],
          [-2.9441e-01,  1.6491e-01,  2.7078e-01,  ..., -6.2295e-01,
           -2.1021e-01,  3.6228e-01],
          [-3.1277e-01,  7.9575e-02,  7.3865e-02,  ..., -2.8805e-01,
           -1.7349e-01,  3.1025e-01],
          ...,
          [-5.2960e-01, -1.4674e-02,  9.4947e-02,  ..., -1.3907e-01,
           -1.5130e-01,  2.9277e-01],
          [-2.7441e-01,  1.1423e-01,  4.6727e-02,  ..., -1.7568e-01,
           -2.9656e-01,  3.2805e-01],
          [-3.8278e-01, -1.4709e-01,  2.7697e-01,  ..., -3.9893e-02,
           -6.7280e-01,  2.9507e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0455,  0.1152, -0.0539,  ..., -0.3333, -0.5309, -0.6016],
          [-0.2064,  0.0891, -0.0110,  ..., -0.3842, -0.5205, -0.6341],
          [-0.0752, -0.0969, -0.3107,  ..., -0.4765, -0.4632, -0.5524],
          ...,
          [ 0.2537,  0.4009,  0.3896,  ..., -0.3784, -0.5601, -0.4647],
          [ 0.3903,  0.5058,  0.4800,  ..., -0.3571, -0.4569, -0.4729],
          [ 0.3047,  0.3654,  0.4452,  ..., -0.5608, -0.6659, -0.6518]]],
        [[[-1.0000, -0.2320, -0.2160,  ..., -0.2753,  0.0682,  0.2824],
          [-0.8740, -0.2804, -0.4124,  ..., -0.2900, -0.0110,  0.2263],
          [-0.9189, -0.4629, -0.1976,  ..., -0.1133, -0.0350,  0.1690],
          ...,
          [-0.1992,  0.1207,  0.2072,  ..., -0.0991,  0.0789,  0.3001],
          [-0.3050,  0.1753,  0.3007,  ..., -0.1836,  0.0654,  0.3943],
          [-0.1168,  0.1528,  0.1399,  ..., -0.5322,  0.0783,  0.4394]]],
        [[[-0.2531,  0.0542,  0.0392,  ..., -1.0000, -0.8408, -0.5827],
          [-0.0547, -0.1791,  0.0303,  ..., -0.5923, -0.8778, -0.6151],
          [-0.0158, -0.1761, -0.1162,  ..., -0.5981, -0.7951, -0.5869],
          ...,
          [-0.0721,  0.1580,  0.1812,  ...,  0.0075,  0.1391,  0.1165],
          [-0.0946, -0.0151,  0.0157,  ..., -0.3414, -0.2476, -0.2827],
          [-0.0959, -0.0465,  0.1808,  ..., -0.6856, -0.6711, -0.4731]]],
        ...,
        [[[-0.4633, -0.1756,  0.2132,  ..., -0.3174, -0.2985, -0.7226],
          [-0.4586, -0.0670,  0.2007,  ..., -0.0766, -0.2712, -0.4750],
          [-0.6517, -0.2807,  0.1466,  ..., -0.2532, -0.4961, -0.6393],
          ...,
          [-0.9387, -0.0713,  0.0768,  ..., -0.0052, -0.1860, -0.5918],
          [-0.6560, -0.1310,  0.1479,  ..., -0.3001, -0.5874, -0.7344],
          [-0.6055,  0.0619,  0.2689,  ..., -0.3255, -0.5494, -0.6510]]],
        [[[-0.6103, -0.5231, -0.4369,  ..., -0.6576, -0.5261, -0.5884],
          [-0.7989, -0.4910, -0.4273,  ..., -0.6186, -0.5278, -0.5432],
          [-0.7142, -0.4470, -0.5104,  ..., -0.6816, -0.5699, -0.5052],
          ...,
          [-0.5585, -0.5773, -0.7006,  ..., -0.6334, -0.7252, -0.5555],
          [-0.7998, -0.6602, -0.5769,  ..., -0.2979, -0.4888, -0.5438],
          [-0.6024, -0.5541, -0.5373,  ..., -0.0812, -0.4626, -0.7305]]],
        [[[-0.4415,  0.0824,  0.2605,  ...,  0.1028, -0.4190, -0.7049],
          [-0.5028,  0.1609,  0.4770,  ..., -0.0903, -0.3635, -0.5683],
          [-0.7112, -0.0185,  0.3563,  ..., -0.2221, -0.2189, -0.5229],
          ...,
          [-0.7506, -0.2832,  0.1858,  ..., -0.0321, -0.1323, -0.6615],
          [-0.7064, -0.0456,  0.4802,  ...,  0.1004, -0.0425, -0.4509],
          [-0.5539,  0.0182,  0.4766,  ..., -0.1718, -0.1970, -0.3674]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5378,  0.0873,  0.0719,  ..., -0.2705, -0.2040, -0.5090],
          [-0.4416,  0.0759, -0.0999,  ..., -0.0396, -0.0573, -0.4545],
          [-0.5269, -0.1755, -0.0222,  ..., -0.1970, -0.2198, -0.5646],
          ...,
          [-0.7541,  0.0291,  0.3902,  ..., -0.1686, -0.3396, -0.7666],
          [-0.7776, -0.2034,  0.2358,  ...,  0.1233,  0.0992, -0.4791],
          [-0.6093, -0.0154,  0.2932,  ..., -0.0324,  0.1390, -0.2553]]],
        [[[-0.9147, -0.5330, -0.5436,  ..., -0.3466, -0.3801, -0.3855],
          [-0.7138, -0.2260, -0.4685,  ..., -0.0319, -0.5445, -0.6988],
          [-0.7744, -0.2201, -0.5674,  ...,  0.1153, -0.5842, -0.9290],
          ...,
          [-0.3653, -0.2205, -0.0479,  ...,  0.2717,  0.1378, -0.5040],
          [-0.6772, -0.3640, -0.2439,  ...,  0.5329,  0.3158,  0.0102],
          [-0.4402, -0.3928, -0.4739,  ...,  0.6597,  0.6380,  0.4516]]],
        [[[-0.2470,  0.2178,  0.4807,  ...,  0.1614, -0.0463,  0.4967],
          [-0.4054,  0.3185,  0.3595,  ...,  0.0651,  0.0905,  0.4681],
          [-0.3571,  0.2282,  0.3859,  ...,  0.2503,  0.1737,  0.4878],
          ...,
          [-0.8721,  0.1324,  0.2945,  ..., -0.1275,  0.0897,  0.4679],
          [-0.7531,  0.0732,  0.4675,  ..., -0.0332,  0.2393,  0.4755],
          [-0.4127,  0.1207,  0.3695,  ..., -0.1224,  0.1952,  0.4967]]],
        ...,
        [[[-0.5533, -0.2481,  0.1456,  ...,  0.0844, -0.1879, -0.5312],
          [-0.6015, -0.2312, -0.0292,  ..., -0.2665, -0.0590, -0.3752],
          [-0.6045, -0.0492,  0.2626,  ...,  0.2135,  0.0344, -0.2308],
          ...,
          [-0.5504, -0.0916,  0.3392,  ...,  0.2918,  0.1414, -0.3751],
          [-0.6036,  0.0380,  0.5174,  ...,  0.2536,  0.1123, -0.4582],
          [-0.5252,  0.1008,  0.5552,  ...,  0.0983, -0.1867, -0.5585]]],
        [[[-0.1693,  0.2993,  0.7487,  ...,  0.0826, -0.0948, -0.8236],
          [-0.2459,  0.3422,  0.6912,  ..., -0.0016, -0.0983, -0.4935],
          [-0.0162,  0.4571,  0.6740,  ..., -0.2455, -0.1933, -0.5407],
          ...,
          [ 0.0125,  0.5596,  0.7574,  ..., -0.0544, -0.1459, -0.4291],
          [ 0.0436,  0.4000,  0.7295,  ..., -0.0814, -0.1891, -0.4705],
          [ 0.1063,  0.2925,  0.5995,  ..., -0.1658, -0.5464, -0.7602]]],
        [[[-0.5220,  0.0945,  0.1822,  ..., -0.3529, -0.5313, -1.0000],
          [-0.3987, -0.0140,  0.0807,  ..., -0.3235, -0.3878, -0.6506],
          [-0.1655,  0.0812,  0.0822,  ..., -0.2326, -0.4297, -0.7082],
          ...,
          [-0.3651, -0.1911, -0.1525,  ..., -0.2786, -0.2730, -0.5610],
          [-0.5093, -0.1784, -0.0818,  ..., -0.2164, -0.2858, -0.5344],
          [-0.6129, -0.1569, -0.0526,  ..., -0.1814, -0.3907, -0.4547]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4400, -0.1612, -0.3120,  ...,  0.4238,  0.2485, -0.1734],
          [-0.6019, -0.3674, -0.4353,  ...,  0.6031,  0.2628, -0.2511],
          [-0.5334, -0.5819, -0.3320,  ...,  0.6920,  0.2913, -0.1780],
          ...,
          [-0.2535, -0.3358, -0.0837,  ...,  0.7969,  0.3607, -0.1469],
          [-0.4819, -0.4196, -0.0775,  ...,  0.8324,  0.5114, -0.1955],
          [-0.3373, -0.1857, -0.1188,  ...,  0.7892,  0.4355, -0.1309]]],
        [[[-0.3302,  0.0256, -0.0820,  ..., -0.3401, -0.4965, -0.3080],
          [-0.2776, -0.0222, -0.0763,  ..., -0.4025, -0.5165, -0.2849],
          [-0.0337,  0.0244, -0.3192,  ..., -0.5192, -0.4786, -0.3994],
          ...,
          [ 0.0678,  0.0696, -0.0237,  ..., -0.5418, -0.5561, -0.4879],
          [-0.1354, -0.1493,  0.1215,  ..., -0.4972, -0.8357, -0.6766],
          [-0.2062,  0.1148,  0.1038,  ..., -0.5192, -0.8865, -1.0000]]],
        [[[-0.3779, -0.0597,  0.2442,  ...,  0.1236, -0.0177, -0.5639],
          [-0.4074, -0.1118,  0.2276,  ..., -0.1628, -0.1644, -0.6264],
          [-0.5234, -0.2856, -0.0645,  ..., -0.0556, -0.1819, -0.5290],
          ...,
          [-0.3815,  0.2033,  0.3452,  ...,  0.1146,  0.0968, -0.2413],
          [-0.4883,  0.1068,  0.2376,  ..., -0.4939, -0.1220, -0.5373],
          [-0.5828, -0.1006, -0.2130,  ..., -0.1351,  0.0184, -0.4777]]],
        ...,
        [[[-0.4433, -0.4137, -0.4332,  ..., -0.5656, -0.1985, -0.1395],
          [-0.3195, -0.1766, -0.2781,  ..., -0.5341, -0.3243, -0.1460],
          [-0.3858, -0.4079, -0.1269,  ..., -0.9832, -0.4331,  0.0866],
          ...,
          [-0.3208, -0.1377, -0.1941,  ...,  0.2000, -0.0406, -0.2529],
          [-0.3157, -0.5080, -0.3834,  ...,  0.2337, -0.1574, -0.2372],
          [-0.2953, -0.4001, -0.3043,  ...,  0.2064,  0.0520, -0.0397]]],
        [[[-0.3436, -0.2532, -0.5406,  ..., -0.4313, -0.7592, -0.7970],
          [-0.1620, -0.3047, -0.2385,  ..., -0.3516, -0.4079, -0.7833],
          [-0.2052, -0.3335, -0.1531,  ..., -0.2885, -0.2663, -0.4355],
          ...,
          [-0.3809, -0.1162, -0.1975,  ..., -0.5220, -0.6002, -0.9648],
          [-0.5342, -0.2550, -0.1953,  ..., -0.4541, -0.4311, -0.7969],
          [-0.3122, -0.2269, -0.0985,  ..., -0.6836, -0.3609, -0.6034]]],
        [[[-0.2376,  0.1924,  0.3100,  ...,  0.0951,  0.0042, -0.4838],
          [-0.6420,  0.0218,  0.3788,  ...,  0.0857,  0.1658, -0.1699],
          [-0.6234,  0.1315,  0.4569,  ...,  0.0728,  0.1017, -0.2341],
          ...,
          [-0.3062,  0.0668,  0.1547,  ...,  0.0648,  0.1149, -0.2239],
          [-0.4297,  0.1154,  0.3202,  ...,  0.0937,  0.0937, -0.1792],
          [-0.4379, -0.0494,  0.2155,  ...,  0.1334, -0.0143, -0.3084]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.4466e-01, -4.6269e-01, -6.2839e-01,  ..., -3.1301e-01,
           -2.6756e-01, -4.8497e-01],
          [-4.9400e-01, -7.1488e-01, -4.4317e-01,  ..., -8.0608e-01,
           -3.6836e-01, -5.7553e-01],
          [-6.7353e-01, -4.1233e-01, -2.6333e-01,  ..., -9.3535e-01,
           -4.4413e-01, -3.3273e-01],
          ...,
          [-5.5600e-01, -1.4382e-01, -1.8647e-01,  ..., -1.9055e-01,
            1.1255e-01, -1.4043e-01],
          [-3.3179e-01, -3.8603e-01, -2.2375e-01,  ..., -2.7674e-01,
            1.2776e-01, -8.5683e-02],
          [-8.3181e-03,  8.0223e-02,  1.9537e-01,  ..., -2.2081e-01,
            1.2708e-01,  2.4474e-01]]],
        [[[-5.7496e-01, -4.8479e-01,  1.3358e-01,  ..., -2.1648e-02,
           -9.1221e-02, -8.2602e-01],
          [-4.3764e-01, -1.0018e-01,  5.5099e-04,  ..., -2.8767e-02,
           -2.0500e-01, -5.1956e-01],
          [-3.7918e-01,  2.0528e-02,  2.5394e-01,  ...,  2.9382e-02,
           -1.1843e-01, -5.8041e-01],
          ...,
          [-2.9868e-01,  2.5215e-02,  1.3190e-01,  ..., -1.3030e-02,
           -9.8378e-02, -7.9486e-01],
          [-2.3507e-01,  7.8121e-02,  4.8563e-02,  ..., -4.2529e-01,
           -2.0418e-01, -5.5229e-01],
          [-2.3781e-01,  6.0822e-02,  7.8036e-03,  ..., -3.3883e-01,
           -2.3523e-01, -4.6149e-01]]],
        [[[-6.1703e-02, -4.0060e-02, -2.0023e-01,  ..., -4.4836e-01,
           -6.2073e-02, -1.3158e-01],
          [-2.0197e-01, -1.3699e-01, -2.1254e-01,  ..., -3.2178e-01,
           -1.3471e-01, -1.7386e-01],
          [-1.2713e-01, -8.9897e-02, -8.0677e-02,  ..., -8.7859e-02,
           -6.7430e-02, -2.3895e-01],
          ...,
          [-1.1292e-01,  9.3995e-02,  1.1836e-01,  ..., -2.9210e-01,
           -5.2844e-01, -3.0358e-01],
          [-1.5010e-01,  3.5946e-02,  5.2679e-02,  ..., -2.9738e-01,
           -4.7321e-01, -6.6977e-01],
          [-1.3415e-01, -7.2456e-02, -2.5531e-01,  ..., -4.8173e-01,
           -5.4029e-01, -6.7886e-01]]],
        ...,
        [[[ 3.9693e-01,  4.9138e-01,  1.4890e-01,  ..., -3.3253e-01,
           -6.9527e-01, -8.5882e-01],
          [ 2.9064e-01,  4.5116e-01,  2.4430e-01,  ..., -4.4235e-01,
           -4.6426e-01, -6.8575e-01],
          [-5.3330e-02,  1.0744e-01, -3.5923e-02,  ..., -4.6860e-01,
           -4.0801e-01, -4.7384e-01],
          ...,
          [ 2.8295e-01,  3.1558e-01, -6.2673e-02,  ..., -4.5158e-01,
           -7.0258e-01, -9.0546e-01],
          [ 2.7134e-02,  7.2486e-02, -1.5640e-02,  ..., -4.9754e-01,
           -6.8599e-01, -7.6363e-01],
          [ 1.4043e-02, -3.8651e-01, -1.9917e-01,  ..., -2.7753e-01,
           -5.2830e-01, -8.5669e-01]]],
        [[[-1.4072e-01, -2.4011e-01, -4.5050e-01,  ...,  4.8105e-02,
            1.9048e-01,  4.3522e-01],
          [-2.5916e-01, -4.2118e-01, -1.6216e-01,  ..., -1.2073e-01,
            1.4338e-01,  3.1136e-01],
          [-5.0908e-01, -4.4971e-01, -4.3090e-02,  ..., -2.9222e-01,
           -6.4585e-02,  1.7500e-01],
          ...,
          [-3.6348e-01, -6.0205e-01, -6.7637e-01,  ..., -5.1100e-01,
           -3.3287e-01, -3.3084e-01],
          [-6.6110e-01, -4.0040e-01, -3.0711e-01,  ..., -2.7402e-01,
           -1.9836e-01, -4.7432e-02],
          [-5.7070e-01, -3.0737e-01, -2.2937e-01,  ..., -1.2752e-01,
           -4.9854e-01, -5.7400e-02]]],
        [[[-4.5152e-01, -1.9195e-01, -1.8042e-01,  ..., -1.0724e-01,
           -3.0742e-02, -3.4733e-01],
          [-4.6479e-01, -2.9945e-01, -2.1214e-01,  ..., -1.7864e-03,
           -1.8866e-01, -4.2076e-01],
          [-5.4399e-01, -1.3434e-01, -2.4556e-01,  ..., -8.2518e-02,
           -5.6552e-01, -6.0031e-01],
          ...,
          [-7.6099e-01, -6.0106e-01, -1.2134e-02,  ...,  1.5716e-01,
           -2.2915e-01, -3.8919e-01],
          [-8.1047e-01, -4.3575e-01, -2.1072e-02,  ...,  9.6934e-02,
           -2.8226e-01, -6.1280e-01],
          [-6.6287e-01, -3.7827e-01, -1.2498e-01,  ..., -5.8301e-02,
           -2.4402e-01, -3.8269e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.6097, -0.0074, -0.0908,  ..., -0.0465, -0.4462, -0.6975],
          [-0.5064,  0.0862, -0.0051,  ..., -0.1271, -0.3356, -0.7238],
          [-0.5268,  0.0320, -0.0871,  ..., -0.0866, -0.3182, -0.6092],
          ...,
          [-0.4630,  0.0582,  0.0877,  ..., -0.0721, -0.1253, -0.5926],
          [-0.3317,  0.1490,  0.0206,  ..., -0.4203, -0.2832, -0.7950],
          [-0.3777,  0.0205, -0.0710,  ..., -0.2450, -0.3445, -0.7521]]],
        [[[-0.3698, -0.1314, -0.1617,  ..., -0.5737, -0.1811, -0.2233],
          [-0.3157, -0.0511, -0.1592,  ..., -0.2430, -0.2152, -0.3935],
          [-0.5245, -0.1933, -0.4247,  ..., -0.0346,  0.1181,  0.0141],
          ...,
          [-0.4589, -0.2543, -0.2972,  ..., -0.2613, -0.5219, -0.6020],
          [-0.3108, -0.2914, -0.3429,  ..., -0.3755, -0.2954, -0.4687],
          [-0.2978, -0.0891, -0.2742,  ..., -0.2143, -0.2416, -0.4485]]],
        [[[-0.6972, -0.1203,  0.0382,  ...,  0.0402, -0.3253, -0.5476],
          [-0.6104, -0.3387, -0.0810,  ..., -0.2290, -0.3330, -0.4664],
          [-0.4624, -0.1320, -0.1596,  ..., -0.1345, -0.4065, -0.4256],
          ...,
          [-0.4093, -0.0070, -0.1653,  ..., -0.2904, -0.3201, -0.5592],
          [-0.3090,  0.0411, -0.0845,  ..., -0.1181, -0.3516, -0.5263],
          [-0.3539, -0.1505, -0.1095,  ..., -0.0780, -0.3077, -0.4705]]],
        ...,
        [[[-0.1727,  0.1170, -0.0817,  ..., -0.6995, -0.4281, -0.4222],
          [-0.3555, -0.0070, -0.1280,  ..., -0.6089, -0.4142, -0.4475],
          [-0.4452, -0.2419, -0.0823,  ..., -0.6019, -0.6008, -1.0000],
          ...,
          [-0.1806, -0.2742, -0.1264,  ..., -0.3871, -0.6160, -0.4413],
          [-0.1275,  0.0123, -0.1505,  ..., -0.5646, -0.4608, -0.4918],
          [-0.1464,  0.0150, -0.2281,  ..., -0.6327, -0.4979, -0.3917]]],
        [[[-0.2518,  0.0738,  0.2734,  ...,  0.7835,  0.2393, -0.5344],
          [-0.0684,  0.2260,  0.4111,  ...,  0.7012,  0.1211, -0.7265],
          [-0.1401, -0.0119,  0.2018,  ...,  0.6408,  0.1541, -0.6741],
          ...,
          [ 0.1742, -0.0055, -0.1025,  ...,  0.4645,  0.0151, -0.2806],
          [ 0.0387,  0.3566,  0.2019,  ...,  0.6236, -0.1802, -0.5553],
          [ 0.1975,  0.1247,  0.1822,  ...,  0.6092,  0.0872, -0.1923]]],
        [[[-0.3866, -0.0879, -0.5187,  ...,  0.3465,  0.1416,  0.0851],
          [-0.1056, -0.1764, -0.1198,  ...,  0.5283,  0.2378,  0.0648],
          [-0.1787, -0.3500, -0.2089,  ...,  0.6036,  0.4723,  0.1984],
          ...,
          [ 0.0148,  0.5203,  0.5997,  ...,  0.4333,  0.0547, -0.4112],
          [ 0.0136,  0.1876,  0.5489,  ...,  0.2538, -0.0967, -0.5031],
          [-0.2295,  0.1194,  0.2727,  ...,  0.1951, -0.2455, -1.0000]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-2.3251e-01, -3.1866e-01, -6.9164e-01,  ..., -5.7508e-01,
           -6.1989e-01, -5.4162e-01],
          [-2.1151e-01, -4.5677e-01, -7.3821e-01,  ..., -4.6293e-01,
           -6.3040e-01, -3.3050e-01],
          [-1.0569e-01, -1.1040e-01, -2.2329e-01,  ..., -4.3155e-01,
           -3.4759e-01, -1.6721e-01],
          ...,
          [-1.4338e-01, -4.0103e-01, -3.9433e-01,  ..., -5.3704e-01,
           -7.2469e-01, -4.4149e-01],
          [-4.1094e-02, -5.7905e-02, -2.6746e-02,  ..., -8.1921e-01,
           -6.6076e-01, -4.3030e-01],
          [-1.6548e-01, -6.5554e-02,  7.9852e-02,  ..., -8.2073e-01,
           -5.6091e-01, -3.5929e-01]]],
        [[[-3.3973e-01, -1.4410e-01, -2.7127e-01,  ...,  8.1888e-01,
            8.5173e-01,  7.5822e-01],
          [-5.9822e-01, -8.2913e-02, -1.6003e-01,  ...,  6.9470e-01,
            9.0182e-01,  7.4560e-01],
          [-7.1177e-01, -7.7017e-02, -1.5019e-01,  ...,  8.2279e-01,
            9.3077e-01,  7.6749e-01],
          ...,
          [-5.7416e-01, -2.1309e-01, -2.0035e-02,  ...,  8.1716e-01,
            7.0614e-01,  5.7119e-01],
          [-5.3442e-01, -2.6271e-01, -2.1631e-01,  ...,  8.9674e-01,
            8.0618e-01,  4.6244e-01],
          [-6.2228e-01, -2.3735e-01, -2.6991e-02,  ...,  9.3913e-01,
            7.5533e-01,  5.4955e-01]]],
        [[[-1.3253e-01,  1.2854e-01,  1.6761e-01,  ..., -6.1691e-01,
           -6.4133e-01, -9.2010e-01],
          [ 4.0585e-02,  1.8199e-01,  9.9324e-02,  ..., -1.5255e-01,
           -4.4812e-01, -8.1565e-01],
          [ 3.2556e-01,  9.7464e-02,  1.0584e-01,  ..., -1.6292e-01,
           -5.4277e-01, -1.0000e+00],
          ...,
          [-5.1752e-01, -3.3409e-01, -1.8482e-02,  ..., -7.3112e-01,
           -5.5711e-01, -5.9730e-01],
          [ 1.5923e-03,  8.4379e-03, -1.7586e-01,  ..., -6.0201e-01,
           -3.2251e-01, -5.2213e-01],
          [ 1.3308e-01,  2.0673e-01,  8.1687e-02,  ..., -3.0320e-01,
           -1.3819e-01, -5.5111e-01]]],
        ...,
        [[[ 5.7472e-02, -9.7631e-02, -2.1602e-01,  ..., -5.9752e-01,
           -3.8389e-01, -4.1966e-01],
          [ 1.0545e-01,  2.1385e-01, -3.9537e-02,  ..., -2.8683e-01,
           -9.0938e-02, -2.8776e-02],
          [-4.3479e-01,  1.3449e-01,  1.9202e-01,  ..., -3.6350e-01,
           -1.1070e-01, -5.9075e-02],
          ...,
          [-5.1072e-03,  3.6569e-02, -3.6429e-02,  ..., -2.9774e-01,
           -3.2762e-02, -1.4799e-01],
          [-1.0967e-01,  1.3537e-01,  4.9214e-02,  ...,  2.0419e-01,
            2.3479e-01,  1.1393e-01],
          [-2.1944e-01,  1.0112e-01, -1.8678e-01,  ...,  3.2323e-01,
            2.5258e-01,  1.8038e-01]]],
        [[[-2.9057e-01,  7.3313e-02,  1.3132e-01,  ...,  3.8583e-01,
            3.5239e-01, -2.9001e-01],
          [-3.7222e-01, -1.5896e-01, -1.8431e-02,  ...,  2.1614e-01,
            6.9978e-02, -3.4149e-01],
          [-5.2572e-01, -7.8001e-02,  7.9061e-02,  ...,  4.7874e-01,
           -1.7631e-04, -6.2749e-02],
          ...,
          [-5.0209e-01,  1.3674e-01,  2.4524e-01,  ...,  1.0533e-01,
            2.9122e-01, -3.1826e-01],
          [-5.0339e-01,  2.4056e-01,  4.7969e-01,  ...,  1.4239e-01,
            3.4418e-01, -2.1239e-01],
          [-5.0902e-01,  2.0662e-01,  4.3301e-01,  ...,  9.2705e-02,
            2.1454e-01,  5.8342e-03]]],
        [[[-1.2846e-01,  2.0732e-01,  8.9998e-02,  ..., -5.0582e-01,
            2.3398e-02,  8.7162e-02],
          [-6.8172e-02,  3.1702e-01,  1.9955e-01,  ..., -4.9979e-01,
            2.0967e-02,  6.0955e-02],
          [-3.9303e-01,  7.7117e-02,  1.0617e-01,  ..., -2.7922e-01,
           -1.2147e-01,  1.2437e-01],
          ...,
          [-8.4437e-02,  2.1466e-01,  6.7956e-02,  ..., -5.5152e-01,
           -8.9980e-01, -9.9230e-01],
          [ 4.0631e-02,  3.9692e-02, -7.3953e-03,  ..., -4.9723e-01,
           -7.7448e-01, -9.7891e-01],
          [-1.2922e-01, -2.9565e-01, -3.1720e-01,  ..., -6.0326e-01,
           -4.7213e-01, -6.5565e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4057, -0.1237,  0.4105,  ..., -0.1092, -0.4104, -0.6294],
          [-0.3172,  0.0145,  0.3144,  ..., -0.0209, -0.1680, -0.3493],
          [-0.2203, -0.0671,  0.0053,  ..., -0.2804, -0.3967, -0.5341],
          ...,
          [-0.5353,  0.2563,  0.3610,  ..., -0.0643, -0.4431, -0.2714],
          [-0.5574,  0.1641,  0.2608,  ..., -0.0392, -0.0677, -0.2190],
          [-0.6311, -0.0016,  0.4181,  ...,  0.0778,  0.0507, -0.0471]]],
        [[[ 0.0196,  0.4085,  0.3443,  ..., -0.4892, -0.5713, -0.7047],
          [ 0.1540,  0.2503,  0.2495,  ..., -0.6141, -0.4000, -0.4294],
          [ 0.1295,  0.3561,  0.1687,  ..., -0.3720, -0.2233, -0.2238],
          ...,
          [-0.5297, -0.5276, -0.2547,  ..., -0.7795, -0.7859, -0.5241],
          [-0.7054, -0.4391, -0.2844,  ..., -0.6376, -0.4224, -0.6583],
          [-0.4482, -0.4619, -0.5449,  ..., -0.2619, -0.1805, -0.3510]]],
        [[[-0.4939, -0.0596,  0.1127,  ..., -0.1408, -0.5133, -0.2814],
          [-0.5846, -0.3089, -0.3404,  ..., -0.3148, -0.3794, -0.2498],
          [-0.8418, -0.4730, -0.6007,  ..., -0.2846, -0.3296, -0.3224],
          ...,
          [-0.8982, -0.2188,  0.1826,  ..., -0.3283, -0.3135, -0.2559],
          [-0.6748, -0.1058,  0.0432,  ..., -0.2968, -0.5743, -0.2810],
          [-0.8713, -0.0636,  0.1954,  ..., -0.1945, -0.4553, -0.3335]]],
        ...,
        [[[-0.4556,  0.0038, -0.0687,  ...,  0.1505,  0.0024, -0.8576],
          [-0.4565, -0.1091, -0.0653,  ...,  0.1021, -0.1404, -0.6612],
          [-0.6019, -0.0401,  0.2697,  ...,  0.1826, -0.1521, -0.7029],
          ...,
          [-0.4349, -0.1358,  0.2099,  ..., -0.1395, -0.0978, -0.2509],
          [-0.4075, -0.1673,  0.0925,  ..., -0.1147, -0.3477, -0.3314],
          [-0.5970, -0.0402,  0.1238,  ...,  0.2255, -0.0471, -0.3936]]],
        [[[-0.7505, -0.0981,  0.1647,  ...,  0.0986, -0.0580, -0.0441],
          [-0.7685, -0.3963,  0.1520,  ...,  0.0376,  0.0117, -0.0608],
          [-0.8177, -0.3725,  0.1784,  ...,  0.1458, -0.0336, -0.0730],
          ...,
          [-0.4715, -0.0635,  0.2111,  ..., -0.0305, -0.0928, -0.1037],
          [-0.6189,  0.0597,  0.2297,  ...,  0.0638, -0.1847, -0.1065],
          [-0.6612, -0.0716,  0.1875,  ...,  0.0873, -0.0757, -0.0695]]],
        [[[-0.7974, -0.4204, -0.0191,  ...,  0.2842,  0.0862, -0.2343],
          [-0.5803, -0.2323, -0.1419,  ...,  0.1589, -0.0244, -0.3518],
          [-0.4814, -0.1679, -0.1009,  ...,  0.0663, -0.0428, -0.5742],
          ...,
          [-0.7422, -0.3208, -0.1506,  ...,  0.2427, -0.1151, -0.4121],
          [-0.8564, -0.5000, -0.0382,  ...,  0.1277, -0.0784, -0.5853],
          [-0.6390, -0.2515, -0.0371,  ...,  0.1445, -0.1709, -0.3772]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-1.5587e-01, -2.9595e-01, -5.9710e-01,  ..., -2.8339e-01,
           -5.2680e-01, -4.1400e-01],
          [-7.1792e-02, -1.9066e-01, -5.1399e-01,  ..., -3.0836e-01,
           -6.6864e-01, -5.0366e-01],
          [-2.1697e-01, -3.1088e-01, -3.0922e-01,  ..., -4.0132e-01,
           -6.6403e-01, -7.9649e-01],
          ...,
          [-5.6437e-01, -6.0611e-01, -5.7764e-01,  ..., -2.8228e-01,
           -5.5398e-01, -3.7430e-01],
          [-6.3541e-01, -5.1442e-01, -7.6735e-01,  ..., -3.7535e-01,
           -8.5738e-01, -5.4614e-01],
          [-4.8248e-01, -4.7655e-01, -9.8017e-01,  ..., -4.6580e-01,
           -6.0769e-01, -5.3468e-01]]],
        [[[-9.4109e-02, -1.6324e-01, -3.7249e-01,  ..., -2.0371e-01,
           -4.2254e-01, -1.9523e-01],
          [-2.3331e-01,  7.6694e-03, -1.2579e-01,  ..., -1.8322e-01,
           -4.8907e-01, -3.4764e-01],
          [-2.6471e-01, -1.3110e-01, -3.4014e-01,  ..., -4.5592e-01,
           -1.6536e-01, -3.6644e-01],
          ...,
          [-2.3030e-01, -1.4687e-01, -1.1713e-02,  ..., -4.8588e-01,
           -4.6065e-01, -1.4416e-01],
          [-5.3647e-01, -7.9439e-02,  1.1562e-01,  ..., -7.9808e-01,
           -1.4929e-01, -1.2762e-01],
          [-4.4270e-01, -3.1141e-01, -1.6992e-01,  ..., -7.5475e-01,
           -2.0422e-01, -2.7894e-01]]],
        [[[ 8.8204e-02, -3.3683e-02, -3.1345e-02,  ..., -4.2705e-01,
           -4.7486e-01, -6.4421e-01],
          [ 2.9892e-01,  1.2810e-01,  1.5435e-01,  ..., -4.2574e-01,
           -4.7971e-01, -5.9146e-01],
          [ 4.1389e-02,  1.7786e-01,  1.3043e-01,  ..., -4.4477e-01,
           -6.2582e-01, -3.8514e-01],
          ...,
          [ 1.2830e-01,  2.6431e-01,  8.0785e-02,  ..., -2.9973e-01,
           -3.5671e-01, -4.1609e-01],
          [-1.5970e-01, -3.2514e-02,  1.4983e-02,  ..., -5.8923e-01,
           -7.2627e-01, -5.1677e-01],
          [-1.3296e-01, -2.3097e-01,  5.7334e-02,  ..., -5.4952e-01,
           -7.9905e-01, -7.0122e-01]]],
        ...,
        [[[-5.6544e-01, -4.6382e-02,  1.9018e-02,  ...,  3.3185e-01,
            1.6765e-02, -1.3968e-01],
          [-6.2112e-01,  2.9810e-02,  3.2124e-02,  ...,  3.5282e-01,
            1.4793e-01, -1.8240e-02],
          [-8.2114e-01, -1.2503e-01,  2.6966e-01,  ...,  1.3272e-02,
            1.6063e-01, -1.9952e-02],
          ...,
          [ 1.1766e-04,  3.7109e-01,  4.3231e-01,  ...,  2.5480e-02,
           -5.9565e-02, -8.4901e-02],
          [ 2.2963e-01,  5.8276e-01,  4.7281e-01,  ...,  1.5898e-01,
           -4.7870e-02, -8.8659e-02],
          [ 1.4762e-01,  4.6994e-01,  2.3723e-01,  ..., -4.4804e-02,
           -3.7002e-01, -9.8964e-02]]],
        [[[-4.1056e-01, -3.0395e-01, -3.0053e-01,  ..., -9.1585e-01,
           -3.8840e-01, -4.6924e-01],
          [-3.2189e-01, -3.0305e-01, -2.3952e-01,  ..., -5.6717e-01,
           -4.9564e-01, -5.8015e-01],
          [-3.1608e-01, -2.8204e-01, -2.1003e-01,  ..., -3.4748e-01,
           -2.9140e-01, -3.8494e-01],
          ...,
          [-5.1214e-01, -5.4746e-01, -3.6959e-01,  ..., -6.7058e-01,
           -6.6802e-01, -4.5778e-01],
          [-3.5540e-01, -3.3748e-01, -1.9106e-01,  ..., -7.4857e-01,
           -7.0621e-01, -5.9081e-01],
          [-4.2070e-01, -4.9507e-01, -3.4988e-01,  ..., -1.0000e+00,
           -7.1803e-01, -5.1335e-01]]],
        [[[ 2.5248e-01,  2.3790e-01, -9.3026e-02,  ...,  3.8800e-01,
           -1.0700e-02, -6.5438e-03],
          [-1.4668e-01, -1.6780e-01, -8.6881e-02,  ...,  3.8818e-01,
            4.2564e-03, -9.1950e-02],
          [-2.4334e-01, -1.7144e-01,  2.6867e-02,  ...,  3.8983e-01,
            2.5838e-02, -2.2650e-01],
          ...,
          [-1.1401e-01, -1.3033e-01,  1.2657e-01,  ..., -2.2420e-01,
           -1.6330e-01,  6.7467e-02],
          [-2.8321e-01, -4.5693e-01,  4.2868e-02,  ..., -6.9230e-02,
           -2.3671e-01, -2.2503e-02],
          [-9.5582e-02,  1.9197e-01,  2.2919e-01,  ..., -2.9022e-02,
           -1.8581e-01, -1.9350e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-1.8687e-02,  1.6257e-01, -3.6817e-02,  ..., -4.6636e-01,
           -4.5904e-01, -5.4519e-01],
          [-1.0827e-01,  1.5661e-01,  2.1671e-01,  ..., -4.0719e-01,
           -6.7114e-01, -7.4825e-01],
          [ 1.1102e-01, -6.1302e-03,  8.2022e-02,  ..., -3.3776e-01,
           -5.1308e-01, -4.0927e-01],
          ...,
          [-2.6308e-01, -2.4667e-01, -7.2102e-02,  ..., -7.8074e-01,
           -6.0187e-01, -3.0978e-01],
          [-2.1287e-01, -1.4941e-01,  1.8303e-01,  ..., -5.6039e-01,
           -6.8704e-01, -3.2973e-01],
          [-3.4560e-02,  5.2053e-02,  9.9403e-02,  ..., -7.5717e-01,
           -5.6330e-01, -2.2008e-01]]],
        [[[-6.7309e-01, -5.8784e-02,  8.9967e-04,  ...,  6.1509e-02,
           -1.8223e-01, -5.3104e-01],
          [-7.0091e-01, -7.6921e-02, -1.0880e-02,  ..., -7.7031e-03,
           -3.0972e-01, -7.7631e-01],
          [-9.8601e-01, -8.0509e-02,  8.4691e-02,  ..., -1.6059e-02,
           -2.4666e-01, -6.0377e-01],
          ...,
          [-5.7612e-01, -8.0055e-02,  4.2027e-01,  ..., -3.2369e-01,
           -6.7486e-01, -6.2905e-01],
          [-6.1419e-01, -1.5956e-01,  3.8022e-01,  ..., -2.2998e-01,
           -4.0298e-01, -6.2978e-01],
          [-6.4400e-01, -7.9326e-02,  2.7384e-01,  ..., -6.3255e-02,
           -1.3290e-01, -4.9361e-01]]],
        [[[-6.2758e-01, -2.4354e-01, -9.5261e-02,  ..., -2.2878e-01,
           -4.8499e-01, -6.4817e-01],
          [-8.9312e-01, -3.3569e-01, -9.0588e-02,  ..., -4.1266e-01,
           -3.8773e-01, -4.7051e-01],
          [-5.3955e-01, -1.1714e-01,  7.0797e-02,  ..., -4.1533e-01,
           -5.7723e-01, -3.2001e-01],
          ...,
          [-5.8198e-01, -2.1838e-01, -1.5389e-01,  ..., -4.8684e-01,
           -3.9528e-01, -4.7789e-01],
          [-5.2066e-01, -2.0500e-01,  5.9982e-02,  ..., -4.5838e-01,
           -2.9234e-01, -3.4070e-01],
          [-5.4190e-01, -2.3803e-01,  1.4007e-01,  ..., -2.3741e-01,
           -1.6095e-01, -4.3643e-01]]],
        ...,
        [[[-4.8256e-02, -9.4233e-02,  5.3581e-02,  ..., -7.2719e-01,
           -8.7765e-01, -6.9189e-01],
          [-2.7224e-01,  4.3764e-02,  1.9775e-01,  ..., -6.5205e-01,
           -7.8441e-01, -6.6824e-01],
          [-2.1377e-01, -1.2877e-01,  1.0000e-01,  ..., -7.0008e-01,
           -4.8965e-01, -6.2335e-01],
          ...,
          [-5.0762e-02, -7.1595e-02,  3.8575e-02,  ..., -3.6725e-01,
           -3.7908e-01, -5.3451e-01],
          [ 3.8303e-03,  2.8875e-02, -2.5469e-02,  ..., -3.1969e-01,
           -4.7343e-01, -3.9641e-01],
          [ 1.6108e-01,  2.1398e-01, -9.8024e-02,  ..., -4.2760e-01,
           -4.0055e-01, -3.7657e-01]]],
        [[[-2.7118e-01, -1.1021e-01,  3.0521e-01,  ...,  2.5567e-01,
           -4.9450e-02,  8.0081e-02],
          [-2.8727e-01,  1.4389e-01,  4.2925e-01,  ...,  2.3660e-01,
            1.0736e-01,  8.0763e-02],
          [-3.9748e-01,  1.8981e-01,  2.9846e-01,  ...,  3.4207e-01,
            8.7035e-02,  9.0139e-02],
          ...,
          [-5.0667e-01,  5.7723e-02,  5.8683e-02,  ...,  1.5284e-01,
           -1.0955e-01,  3.2414e-02],
          [-4.7211e-01,  7.5354e-02, -1.6432e-02,  ...,  2.4571e-01,
            8.1753e-02,  6.2858e-02],
          [-6.8031e-01, -6.6074e-02,  1.6393e-01,  ...,  1.5657e-01,
            1.8758e-01,  6.5947e-02]]],
        [[[-5.9567e-01, -5.5096e-01, -6.4274e-01,  ..., -1.8757e-01,
           -1.2851e-01, -3.6571e-01],
          [-6.1818e-01, -4.1908e-01, -4.6663e-01,  ..., -2.6488e-01,
           -1.7440e-01, -4.0000e-01],
          [-4.3369e-01, -2.9622e-01, -5.5713e-01,  ..., -2.2724e-01,
           -3.7225e-01, -3.4352e-01],
          ...,
          [-5.6909e-01, -4.5463e-01, -3.7596e-01,  ...,  3.9539e-01,
            5.8005e-01,  6.0654e-01],
          [-7.2881e-01, -5.3907e-01, -2.2035e-01,  ..., -1.5202e-01,
            2.8862e-01,  4.4084e-01],
          [-5.9285e-01, -7.7663e-01, -3.8783e-01,  ..., -2.3067e-01,
           -1.5243e-01, -2.9021e-02]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-5.1046e-01, -8.9874e-02,  3.1075e-01,  ..., -1.7819e-01,
           -6.1147e-02, -3.7166e-01],
          [-5.0557e-01,  1.5128e-02,  2.4223e-01,  ..., -4.7665e-03,
           -2.2857e-01, -4.1781e-01],
          [-4.0171e-01,  1.5263e-02,  3.1954e-01,  ...,  6.5960e-02,
           -2.2720e-01, -5.6099e-01],
          ...,
          [-3.0729e-01,  2.9250e-01,  3.0072e-01,  ..., -4.9643e-02,
           -1.8212e-01, -6.8838e-01],
          [-2.5654e-01,  7.6456e-02,  2.6108e-01,  ..., -2.0442e-01,
           -2.4557e-01, -6.4507e-01],
          [-3.5470e-01, -1.7503e-01,  2.4988e-01,  ..., -1.1120e-01,
           -2.4737e-01, -7.1572e-01]]],
        [[[-5.7369e-02,  6.3997e-01,  7.3871e-01,  ...,  2.8640e-01,
           -4.1303e-01,  1.4766e-01],
          [-1.0941e-01,  6.9949e-01,  8.7139e-01,  ...,  3.7212e-01,
           -3.2544e-02,  2.5617e-01],
          [-1.7459e-01,  4.7365e-01,  6.1376e-01,  ...,  2.1100e-01,
           -1.2265e-01,  2.1908e-01],
          ...,
          [-5.6920e-01,  2.0492e-01,  2.6476e-01,  ..., -4.3535e-02,
            7.9752e-02,  2.2751e-01],
          [-8.0676e-01,  1.5652e-02,  2.7918e-01,  ...,  1.9363e-01,
            2.2587e-02,  2.0400e-01],
          [-8.0646e-01, -1.2644e-01,  2.4691e-01,  ...,  1.6464e-01,
            4.0432e-02,  2.3385e-01]]],
        [[[ 2.2948e-01,  2.7433e-01,  2.9381e-01,  ..., -7.4458e-04,
           -1.9670e-01, -4.9143e-01],
          [ 4.9278e-01,  4.8839e-01,  4.9921e-01,  ...,  1.5773e-02,
           -1.9723e-01, -5.2440e-01],
          [ 3.3925e-01,  2.7000e-01,  4.1507e-01,  ..., -1.7986e-01,
           -2.9432e-01, -5.4540e-01],
          ...,
          [-5.4230e-03,  7.0860e-02,  1.6190e-01,  ..., -5.9895e-02,
           -4.8831e-01, -7.2070e-01],
          [-8.2327e-02,  4.7045e-02, -1.1581e-01,  ..., -7.4862e-02,
           -3.2435e-01, -8.8660e-01],
          [ 5.8775e-02, -2.3105e-02, -1.3553e-01,  ..., -2.1592e-01,
           -3.4646e-01, -6.7075e-01]]],
        ...,
        [[[ 1.8873e-01, -1.6097e-01, -1.2569e-01,  ..., -5.3303e-01,
           -6.1901e-01, -2.3887e-01],
          [ 2.6294e-01,  4.0374e-01,  1.0130e-01,  ..., -6.2495e-01,
           -7.1314e-01, -3.0850e-01],
          [ 3.2264e-02,  3.7311e-01,  3.5681e-01,  ..., -9.0248e-01,
           -7.9185e-01, -3.3652e-01],
          ...,
          [ 1.6206e-01,  2.9001e-01, -4.8764e-02,  ..., -5.2900e-01,
           -2.8435e-01, -1.0055e-02],
          [ 1.8468e-01,  2.5798e-01, -9.6633e-02,  ..., -4.8629e-01,
           -2.3813e-01, -9.4936e-03],
          [ 1.6345e-01, -7.1786e-02, -1.4425e-01,  ..., -2.9960e-01,
           -4.0758e-01,  2.8204e-02]]],
        [[[-5.3468e-01, -3.4003e-01, -7.7498e-01,  ..., -3.0430e-01,
           -5.5903e-01, -6.2255e-01],
          [-3.8438e-01, -3.7327e-01, -3.0848e-01,  ..., -1.0574e-01,
           -3.9596e-01, -4.0354e-01],
          [-4.9320e-01, -1.6862e-01, -5.8881e-02,  ..., -2.3987e-01,
           -4.6079e-01, -2.4532e-01],
          ...,
          [-2.0909e-01,  4.8534e-02, -1.3165e-01,  ..., -1.5773e-01,
           -2.9908e-01, -4.7929e-01],
          [-5.7392e-01, -1.4964e-01,  8.5229e-02,  ..., -4.6696e-01,
           -3.6021e-01, -4.3460e-01],
          [-7.3450e-01, -6.9683e-01, -1.1680e-01,  ..., -3.5281e-01,
           -2.7115e-01, -3.7294e-01]]],
        [[[-5.9051e-01,  2.0375e-01,  6.3096e-01,  ...,  1.2892e-01,
           -1.4496e-01, -4.9911e-01],
          [-6.1864e-01,  2.0302e-02,  6.0101e-01,  ..., -3.5063e-01,
           -2.7356e-01, -5.0969e-01],
          [-7.3364e-01, -1.6784e-01,  2.4080e-01,  ..., -4.2212e-02,
           -1.2618e-01, -2.8746e-01],
          ...,
          [-2.8275e-01,  2.7466e-01,  4.9864e-01,  ..., -7.2256e-02,
           -9.4792e-02, -4.0145e-01],
          [-6.3559e-01, -2.6466e-01, -1.4049e-01,  ...,  9.2262e-03,
           -1.1246e-02, -2.2567e-01],
          [-5.6281e-01, -4.1867e-01, -4.0171e-01,  ..., -2.3153e-01,
           -2.9166e-01, -2.8891e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4982, -0.1559,  0.0592,  ...,  0.0383, -0.2846, -0.3623],
          [-0.4272, -0.2924, -0.2760,  ..., -0.0698, -0.1946, -0.3226],
          [-0.1891, -0.5125, -0.2249,  ..., -0.0885, -0.0287, -0.0665],
          ...,
          [ 0.0176, -0.0232, -0.0174,  ..., -0.3844, -0.2737,  0.1905],
          [-0.2465,  0.0583,  0.1173,  ..., -0.1182,  0.2839,  0.2802],
          [-0.3841, -0.1182, -0.1411,  ..., -0.1550,  0.2949,  0.1755]]],
        [[[-0.7117, -0.4902, -0.3505,  ...,  0.0308, -0.2293, -0.4106],
          [-0.4327, -0.1313, -0.0263,  ...,  0.1399, -0.1721, -0.3460],
          [-0.1125,  0.0825, -0.2380,  ...,  0.1958, -0.0094, -0.5198],
          ...,
          [-0.4355, -0.1632, -0.2366,  ...,  0.2679,  0.4289, -0.0800],
          [-0.1362,  0.0481, -0.2782,  ...,  0.3187,  0.2423, -0.1939],
          [-0.1477,  0.1054, -0.0679,  ...,  0.0538, -0.0121,  0.2245]]],
        [[[-0.7322, -0.4302,  0.0205,  ...,  0.2230, -0.2894, -0.4300],
          [-0.7734, -0.6557, -0.2303,  ...,  0.2299, -0.2024, -0.7507],
          [-0.7026, -0.6474, -0.5221,  ..., -0.0016, -0.3212, -0.5826],
          ...,
          [-0.5010,  0.1138,  0.0926,  ..., -0.0114, -0.2490, -0.6961],
          [-0.5215,  0.1199,  0.2412,  ..., -0.0170, -0.2604, -0.4731],
          [-0.7215, -0.0797,  0.1921,  ...,  0.0269, -0.1884, -0.4240]]],
        ...,
        [[[-0.4892, -0.2157, -0.1360,  ..., -0.5249, -0.5350, -0.5976],
          [-0.2857, -0.3145, -0.6392,  ..., -0.6035, -0.3496, -0.3692],
          [-0.4495, -0.4020, -0.5786,  ..., -0.6392, -0.5482, -0.2800],
          ...,
          [-0.4547, -0.2254, -0.2614,  ..., -0.5343, -0.6545, -0.1554],
          [-0.2698, -0.0329, -0.2342,  ..., -0.6919, -0.5670, -0.2006],
          [-0.4734, -0.2404, -0.8039,  ..., -0.5515, -0.4048, -0.1861]]],
        [[[-0.1535, -0.3273, -0.3387,  ..., -0.0645,  0.3774,  0.2745],
          [-0.4988, -0.4318,  0.0648,  ...,  0.0078,  0.3343,  0.2287],
          [-0.3399, -0.0715,  0.1481,  ...,  0.0632, -0.1344,  0.1335],
          ...,
          [-0.1903,  0.0399, -0.1150,  ..., -0.1951, -0.6055, -0.1723],
          [-0.6226, -0.2036, -0.2901,  ..., -0.2272, -0.5063, -0.1841],
          [-0.6465, -0.3664, -0.2663,  ..., -0.1864, -0.5961, -0.3902]]],
        [[[-0.2044,  0.1722,  0.3597,  ..., -0.1579, -0.2434, -0.6112],
          [-0.3568,  0.1209,  0.3208,  ..., -0.1930, -0.2435, -0.6451],
          [-0.5045, -0.0862,  0.0734,  ...,  0.0024, -0.4184, -0.6267],
          ...,
          [-0.7335, -0.4008, -0.3599,  ..., -0.3644, -0.7276, -0.8847],
          [-0.6685, -0.4028, -0.3719,  ..., -0.3242, -0.6803, -0.8622],
          [-0.6368, -0.3052, -0.1581,  ..., -0.2802, -0.6641, -0.7520]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5063, -0.1028,  0.1015,  ..., -0.0316, -0.4865, -0.9210],
          [-0.5118, -0.1290, -0.1885,  ..., -0.0102, -0.4705, -0.7399],
          [-0.5160, -0.1815, -0.2149,  ..., -0.2278, -0.3680, -0.6577],
          ...,
          [-0.5019, -0.0607,  0.3614,  ..., -0.0244, -0.3076, -0.4152],
          [-0.5492, -0.1342,  0.3027,  ..., -0.0057, -0.0731, -0.2937],
          [-0.7349, -0.1360,  0.2829,  ...,  0.1227, -0.0972, -0.4289]]],
        [[[-0.4165, -0.0802, -0.0943,  ..., -0.4848, -0.1701, -0.0559],
          [-0.4306, -0.3727, -0.3903,  ..., -0.4104, -0.1087, -0.1162],
          [-0.3603, -0.3498, -0.1799,  ..., -0.6913, -0.1195, -0.2497],
          ...,
          [ 0.3394,  0.4954,  0.4590,  ..., -0.4284, -0.1422, -0.4731],
          [ 0.1864,  0.4935,  0.6136,  ..., -0.3403, -0.3362, -0.5394],
          [ 0.0902,  0.3598,  0.3630,  ..., -0.5293, -0.2595, -0.2739]]],
        [[[-0.6821, -0.6880, -0.6330,  ...,  0.0856,  0.1006, -0.1047],
          [-0.7525, -0.4586, -0.5048,  ...,  0.1209,  0.0109, -0.3636],
          [-0.5042, -0.2927, -0.1217,  ...,  0.1234,  0.1199, -0.0603],
          ...,
          [-0.5675, -0.3759, -0.3149,  ...,  0.2535,  0.0879, -0.1953],
          [-0.6145, -0.3562, -0.2542,  ...,  0.1719,  0.0866, -0.0701],
          [-0.4455, -0.4901, -0.4669,  ...,  0.2238,  0.0174, -0.0665]]],
        ...,
        [[[-0.6919, -0.3733, -0.1033,  ..., -0.3834, -0.3879, -0.8028],
          [-0.6452, -0.3913, -0.1488,  ..., -0.1165, -0.2645, -0.9244],
          [-0.6614, -0.1574,  0.0484,  ..., -0.1396, -0.2759, -0.6215],
          ...,
          [-0.6225, -0.1801, -0.2006,  ..., -0.3920, -0.3238, -0.5503],
          [-0.5697, -0.0930, -0.1360,  ..., -0.2765, -0.3313, -0.6341],
          [-0.5564,  0.0088, -0.0926,  ..., -0.2342, -0.3206, -0.6894]]],
        [[[-0.3066, -0.0556, -0.0072,  ..., -0.6058, -0.7559, -0.9409],
          [-0.3675, -0.1345, -0.1214,  ..., -0.3652, -0.5829, -0.6651],
          [-0.2897, -0.1678, -0.3142,  ..., -0.3849, -0.6176, -1.0000],
          ...,
          [-0.2605, -0.2561, -0.2724,  ..., -0.3608, -0.5051, -0.6449],
          [-0.2474, -0.2138, -0.0674,  ..., -0.3210, -0.4847, -0.6430],
          [-0.2166, -0.3009, -0.0735,  ..., -0.3034, -0.4369, -0.5720]]],
        [[[-0.3580, -0.4122, -0.5455,  ...,  0.0932, -0.2544, -0.6570],
          [-0.4316, -0.4757, -0.3959,  ..., -0.0411, -0.4239, -0.9079],
          [-0.5362, -0.4801, -0.0148,  ..., -0.1816, -0.5991, -0.9504],
          ...,
          [-0.3999, -0.1704, -0.1890,  ..., -0.0583,  0.3819,  0.5456],
          [-0.6776, -0.4978, -0.3514,  ...,  0.3173,  0.3779,  0.1960],
          [-0.4770, -0.3754, -0.1212,  ...,  0.1868,  0.0875, -0.5432]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4544, -0.1013,  0.1740,  ..., -0.0655, -0.2279, -0.6046],
          [-0.6915, -0.2290,  0.1103,  ..., -0.0695, -0.5954, -0.6189],
          [-0.4039,  0.0546,  0.2445,  ..., -0.1422, -0.4601, -0.5734],
          ...,
          [-0.8866, -0.3085,  0.0506,  ...,  0.0468, -0.1836, -0.5924],
          [-0.7158, -0.2283,  0.0016,  ..., -0.0369, -0.1170, -0.4435],
          [-0.5404, -0.1882,  0.1617,  ..., -0.2416, -0.1886, -0.4203]]],
        [[[ 0.4810,  0.3025,  0.0404,  ..., -0.0767, -0.1152, -0.2175],
          [ 0.4575,  0.4014,  0.3991,  ..., -0.0913, -0.1597, -0.4681],
          [ 0.1883,  0.2529,  0.5271,  ..., -0.3947, -0.3006, -0.4752],
          ...,
          [ 0.0690,  0.0458,  0.2055,  ..., -0.0309, -0.3192, -0.3540],
          [-0.3728,  0.0245,  0.4546,  ..., -0.0093, -0.1789, -0.6773],
          [-0.6074,  0.1295,  0.4522,  ..., -0.3274, -0.3680, -0.7072]]],
        [[[-0.1777,  0.3372,  0.5367,  ...,  0.2036, -0.1580, -0.5817],
          [-0.0905,  0.4775,  0.4903,  ...,  0.3692,  0.0143, -0.6952],
          [-0.0903,  0.4231,  0.3546,  ...,  0.2609,  0.0508, -0.7607],
          ...,
          [-0.3328,  0.3348,  0.5664,  ..., -0.0014, -0.4384, -0.7794],
          [ 0.0810,  0.4134,  0.5905,  ...,  0.0886, -0.3531, -1.0000],
          [ 0.2053,  0.5680,  0.8499,  ..., -0.0403, -0.3285, -0.6900]]],
        ...,
        [[[-0.6586, -0.1859, -0.0942,  ..., -0.7500, -0.5530, -0.6130],
          [-0.5681, -0.3523,  0.0188,  ..., -0.5467, -0.4661, -0.5655],
          [-0.5133, -0.0752, -0.0539,  ..., -0.5077, -0.5915, -0.6624],
          ...,
          [-0.9012,  0.0567,  0.1981,  ..., -0.2750, -0.3187, -0.7634],
          [-0.7336,  0.0365,  0.1863,  ..., -0.2869, -0.4573, -0.6735],
          [-0.6181, -0.1108, -0.0159,  ..., -0.3616, -0.4034, -0.6499]]],
        [[[-0.3657, -0.0750, -0.2474,  ..., -0.0708, -0.5953, -0.5973],
          [-0.5166, -0.1091, -0.1312,  ..., -0.2592, -0.3359, -0.4433],
          [-0.2866,  0.0490, -0.1212,  ..., -0.1230, -0.0488, -0.2488],
          ...,
          [-0.2435,  0.0130, -0.3980,  ..., -0.3016, -0.1082,  0.1134],
          [-0.3773, -0.2440, -0.5332,  ..., -0.3589, -0.3665,  0.0414],
          [-0.3191, -0.2122, -0.5752,  ..., -0.3950, -0.2574, -0.0920]]],
        [[[ 0.2756,  0.2937, -0.1272,  ..., -0.0946, -0.4463, -0.6919],
          [ 0.2617,  0.2533,  0.0372,  ...,  0.0621, -0.2700, -0.5670],
          [ 0.4806,  0.1132,  0.1211,  ..., -0.0455, -0.4758, -0.6963],
          ...,
          [ 0.1103,  0.1538, -0.2963,  ..., -0.0114, -0.2980, -0.4089],
          [-0.0779, -0.1475, -0.0601,  ...,  0.0071, -0.1048, -0.5542],
          [ 0.0157,  0.1480, -0.0214,  ..., -0.2733, -0.3610, -0.5675]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4171, -0.1454, -0.2477,  ..., -0.4739, -0.6252, -0.4500],
          [-0.2852, -0.3087, -0.4243,  ..., -0.7196, -0.5038, -0.5114],
          [-0.3873, -0.3803, -0.5076,  ..., -0.6926, -0.6461, -0.6764],
          ...,
          [-0.5650, -0.3040, -0.1487,  ..., -0.9553, -0.7408, -0.4706],
          [-0.2637, -0.1262, -0.0506,  ..., -0.9069, -0.8287, -0.5344],
          [-0.3799, -0.3321, -0.3200,  ..., -0.9441, -0.9331, -0.6668]]],
        [[[-0.7554, -0.2911, -0.3488,  ..., -0.0171,  0.1723, -0.2793],
          [-0.5326, -0.2386, -0.4707,  ..., -0.0674,  0.1224, -0.1518],
          [-0.5835, -0.4532, -0.5751,  ..., -0.4093,  0.0405,  0.0515],
          ...,
          [-0.4209, -0.4892, -0.4833,  ..., -0.1898, -0.1149, -0.1946],
          [-0.4551, -0.3924, -0.3269,  ..., -0.2069,  0.0016, -0.1269],
          [-0.5113, -0.3554, -0.3803,  ...,  0.0174, -0.0806, -0.1619]]],
        [[[-0.1785,  0.1899,  0.0565,  ..., -0.1799, -0.0612, -0.2660],
          [-0.1364,  0.2970,  0.2425,  ..., -0.0101, -0.4244, -0.4205],
          [-0.3820,  0.1466,  0.1392,  ..., -0.1558, -0.3334, -0.6583],
          ...,
          [-0.3195,  0.2546,  0.4525,  ..., -0.1950, -0.2529, -0.4471],
          [-0.6300,  0.0470,  0.3242,  ..., -0.3870, -0.0561, -0.0268],
          [-0.6749,  0.1053,  0.4534,  ..., -0.2302, -0.0899, -0.0049]]],
        ...,
        [[[-0.2866,  0.3514,  0.4143,  ..., -0.0693, -0.0217, -0.3474],
          [-0.1182,  0.4471,  0.5042,  ..., -0.2848, -0.2408, -0.8233],
          [-0.3246,  0.3905,  0.5478,  ..., -0.0696, -0.1521, -0.9315],
          ...,
          [-0.5133,  0.0195,  0.5095,  ..., -0.0437, -0.3924, -1.0000],
          [-0.4724, -0.0100,  0.5809,  ...,  0.0476, -0.2546, -0.7970],
          [-0.5462, -0.1257,  0.4909,  ..., -0.1118, -0.3184, -0.7527]]],
        [[[ 0.0595, -0.1172, -0.3118,  ..., -0.0902, -0.3455, -0.6165],
          [-0.0668, -0.3058, -0.2231,  ..., -0.1241, -0.1950, -0.5177],
          [-0.5115, -0.5047, -0.0948,  ..., -0.4817, -0.2456, -0.2698],
          ...,
          [-0.3533, -0.3902,  0.0296,  ..., -0.1136, -0.3260, -0.7519],
          [-0.5784, -0.1735, -0.0791,  ..., -0.0930, -0.3893, -0.8038],
          [-0.5053, -0.1291, -0.2236,  ..., -0.1880, -0.3600, -0.5341]]],
        [[[-0.0373,  0.0925,  0.0148,  ..., -0.2943, -0.0147, -0.1461],
          [-0.5003,  0.2289,  0.4693,  ..., -0.1332,  0.0196, -0.0731],
          [-0.2379,  0.1377,  0.3952,  ..., -0.4303, -0.4274, -0.0538],
          ...,
          [-0.0865, -0.2832, -0.4574,  ..., -0.9978, -0.8748, -0.6441],
          [-0.3949, -0.4829, -0.3141,  ..., -0.8386, -0.7454, -0.9502],
          [-0.4790, -0.3119, -0.0239,  ..., -0.8193, -0.4800, -0.5782]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2226, -0.3240, -0.2513,  ..., -0.2093, -0.3329, -0.2320],
          [-0.1129, -0.1882, -0.2787,  ..., -0.2845, -0.3502, -0.1799],
          [-0.3170, -0.3146, -0.4063,  ..., -0.3936, -0.3697, -0.0624],
          ...,
          [-0.4373, -0.2993, -0.2278,  ..., -0.4608, -0.2766,  0.0603],
          [-0.2060, -0.2474, -0.1782,  ..., -0.6158, -0.3815,  0.0920],
          [-0.3491, -0.2076, -0.1645,  ..., -0.3578, -0.1884,  0.2048]]],
        [[[-0.6484, -0.1843, -0.0500,  ...,  0.2710,  0.2781,  0.0287],
          [-0.4413, -0.2830,  0.1079,  ...,  0.4153,  0.3447, -0.1380],
          [-0.6743,  0.1068,  0.3062,  ...,  0.3235,  0.2314, -0.2094],
          ...,
          [-0.4982,  0.0435,  0.3844,  ...,  0.3327,  0.2701,  0.1032],
          [-0.4080, -0.1559,  0.1542,  ...,  0.2181,  0.3033,  0.0901],
          [-0.7866, -0.2743,  0.0257,  ...,  0.2429,  0.3407,  0.0677]]],
        [[[-0.3378, -0.4411, -0.2185,  ..., -0.6584, -0.5711, -0.4902],
          [-0.4538, -0.3623, -0.2796,  ..., -0.4473, -0.3858, -0.3542],
          [-0.3993, -0.4906, -0.1304,  ..., -0.4883, -0.3067, -0.2085],
          ...,
          [-0.4074, -0.6591, -0.4647,  ..., -0.3843, -0.3743, -0.5050],
          [-0.3868, -0.5556, -0.4262,  ..., -0.3360, -0.5091, -0.5358],
          [-0.6086, -0.2986, -0.2450,  ..., -0.4181, -0.4329, -0.5130]]],
        ...,
        [[[-0.0148,  0.2683,  0.4598,  ...,  0.2198,  0.0603, -0.0953],
          [-0.1614,  0.3455,  0.4343,  ...,  0.2827,  0.2338, -0.1316],
          [-0.3046,  0.1474,  0.3047,  ...,  0.0674,  0.1363, -0.0333],
          ...,
          [-0.1972,  0.4113,  0.5736,  ...,  0.1732,  0.1898, -0.0730],
          [-0.4905,  0.0263,  0.5650,  ...,  0.1810, -0.1024, -0.0978],
          [-0.6429,  0.1038,  0.2664,  ..., -0.0376, -0.0348, -0.1277]]],
        [[[-0.6668, -0.4047,  0.1200,  ...,  0.2109,  0.1508, -0.1305],
          [-0.7917, -0.4685, -0.0156,  ...,  0.3394,  0.0610, -0.1847],
          [-0.7840, -0.4106, -0.1673,  ...,  0.3966,  0.0985, -0.2807],
          ...,
          [-0.8218, -0.2585,  0.0573,  ...,  0.0710,  0.1120, -0.0731],
          [-0.7644, -0.1810,  0.0868,  ...,  0.2761,  0.1253, -0.1381],
          [-0.8010, -0.3480,  0.1124,  ...,  0.2100,  0.0451, -0.1340]]],
        [[[ 0.0423,  0.2052,  0.4637,  ...,  0.0845, -0.2630, -0.8927],
          [ 0.1924,  0.2196,  0.3432,  ...,  0.2293, -0.1311, -0.5616],
          [ 0.0428,  0.1118,  0.1961,  ..., -0.0541, -0.2370, -0.3420],
          ...,
          [ 0.1932,  0.3233,  0.3129,  ..., -0.0681,  0.4221,  0.5824],
          [ 0.0725, -0.0360,  0.3073,  ...,  0.2167,  0.5538,  0.6411],
          [ 0.0240,  0.1203,  0.3951,  ..., -0.0377,  0.1905,  0.4768]]]])
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-6.0520e-01, -3.3999e-01, -2.1476e-01,  ...,  1.1686e-01,
            2.4535e-01, -4.6468e-02],
          [-5.2539e-01, -4.3944e-01, -3.5995e-01,  ..., -4.1981e-03,
            1.2258e-01, -5.1455e-01],
          [-7.3961e-01, -3.8975e-01, -6.2981e-01,  ...,  2.3240e-03,
            3.1557e-02, -5.7414e-01],
          ...,
          [-7.9190e-02,  2.9121e-01,  3.6938e-01,  ...,  9.4702e-03,
            9.2754e-02,  3.9346e-02],
          [-3.4861e-01,  4.4533e-02,  2.1903e-01,  ...,  1.6218e-01,
            1.1949e-01,  2.1793e-01],
          [-5.5398e-01, -5.7317e-01, -1.9792e-01,  ...,  1.9281e-01,
            1.9829e-01,  1.2945e-01]]],
        [[[-9.5911e-01, -2.8114e-01,  5.4380e-02,  ...,  7.6268e-02,
            3.3448e-01,  4.1407e-01],
          [-7.3742e-01, -8.5055e-02,  5.6220e-02,  ...,  1.0226e-01,
           -8.3979e-03,  4.2961e-01],
          [-6.2375e-01,  3.0676e-02,  1.4027e-02,  ...,  1.3645e-01,
            2.3618e-01,  5.5943e-01],
          ...,
          [-8.3094e-01, -5.1374e-01,  1.4846e-01,  ...,  9.8316e-02,
            3.8286e-01,  4.0599e-01],
          [-9.7112e-01, -4.2497e-01,  1.6043e-01,  ...,  1.4062e-01,
            4.4516e-01,  2.5503e-01],
          [-7.2447e-01, -8.5880e-01,  6.3663e-02,  ...,  1.9223e-01,
            2.9561e-01,  2.4502e-01]]],
        [[[ 4.4358e-02,  3.5898e-01,  4.0979e-01,  ..., -5.6295e-01,
           -7.4114e-01, -5.7257e-01],
          [ 5.1899e-02,  2.8313e-01,  4.7372e-01,  ..., -4.9794e-01,
           -7.2544e-01, -3.3038e-01],
          [ 1.4428e-01,  5.3428e-01,  3.1673e-01,  ..., -5.2893e-01,
           -5.5608e-01, -2.9112e-01],
          ...,
          [-4.5042e-02, -1.8358e-05,  3.7712e-01,  ..., -2.1705e-01,
           -3.8895e-01, -3.3336e-01],
          [ 1.0007e-01,  2.3173e-01,  3.1904e-01,  ..., -2.5537e-01,
           -5.4028e-01, -5.1176e-01],
          [ 1.8692e-02,  9.5719e-02,  3.8631e-01,  ..., -7.5443e-01,
           -9.1213e-01, -5.5329e-01]]],
        ...,
        [[[-4.6532e-01, -4.1126e-01, -2.1080e-01,  ..., -6.0982e-01,
           -4.5860e-01, -2.2964e-01],
          [-5.1827e-01, -2.5833e-01, -2.7298e-01,  ..., -6.4140e-01,
           -6.9404e-01, -3.9808e-01],
          [-3.0399e-01, -4.1717e-02, -9.9777e-02,  ..., -7.3173e-01,
           -8.2983e-01, -6.3727e-01],
          ...,
          [-4.5963e-01, -6.3694e-02, -2.3533e-01,  ..., -5.9889e-01,
           -5.8051e-01, -6.6631e-01],
          [-4.9287e-01, -2.2117e-03, -1.1172e-01,  ..., -4.6016e-01,
           -3.9954e-01, -5.0549e-01],
          [-1.9317e-01, -6.4828e-02, -3.5849e-01,  ..., -4.5797e-01,
           -3.7556e-01, -5.1592e-01]]],
        [[[-3.1847e-01,  1.7943e-01,  2.3029e-01,  ...,  1.2599e-01,
           -3.0939e-01, -6.7191e-01],
          [-2.1692e-01,  9.8355e-02,  2.2348e-01,  ...,  3.3223e-02,
           -3.6673e-01, -4.9292e-01],
          [-2.6538e-01,  1.2172e-01,  2.9553e-01,  ...,  2.7337e-02,
           -2.1729e-01, -5.0450e-01],
          ...,
          [-3.3018e-01, -2.2490e-01,  2.7909e-01,  ..., -2.8162e-01,
           -2.7722e-01, -6.8201e-01],
          [-2.6551e-01,  2.8950e-02,  3.0021e-01,  ..., -1.3868e-01,
           -3.7101e-01, -5.7934e-01],
          [-1.8634e-01,  1.1946e-01,  1.4228e-01,  ..., -2.2691e-01,
           -4.0181e-01, -6.2800e-01]]],
        [[[-9.1076e-01, -5.3066e-01, -2.6178e-01,  ...,  1.2078e-02,
           -1.0453e-01, -3.0697e-01],
          [-8.3069e-01, -5.1626e-01, -2.4205e-01,  ...,  1.8206e-01,
            4.2685e-02, -4.9662e-02],
          [-6.7603e-01, -4.8075e-01, -1.1760e-01,  ...,  2.2352e-01,
            6.6519e-02, -7.0158e-02],
          ...,
          [-7.9723e-01, -3.0541e-01, -1.7727e-01,  ...,  3.2355e-01,
            2.4127e-01, -2.8469e-01],
          [-6.2761e-01, -1.0122e-01, -4.1870e-02,  ...,  3.2348e-01,
            2.0951e-01, -2.4932e-01],
          [-7.1245e-01, -1.6896e-01, -1.1099e-01,  ...,  2.2871e-01,
           -3.2958e-02, -1.6466e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.1153,  0.0877, -0.1362,  ..., -0.4070,  0.0271,  0.2369],
          [-0.1818, -0.2570, -0.2262,  ..., -0.5222, -0.3049, -0.0646],
          [-0.5280, -0.4277,  0.0889,  ..., -0.4456, -0.3832, -0.3281],
          ...,
          [-0.3101, -0.1735, -0.1090,  ..., -0.0539,  0.1352, -0.0312],
          [-0.3306, -0.1004, -0.1867,  ..., -0.2458,  0.2938,  0.2150],
          [-0.4598, -0.1526, -0.1871,  ..., -0.1285,  0.2133,  0.2720]]],
        [[[-0.0370,  0.3297,  0.5784,  ..., -0.3480, -0.4266,  0.2958],
          [-0.2793,  0.2330,  0.6006,  ..., -0.5669, -0.4555,  0.2812],
          [-0.2653,  0.3364,  0.7313,  ..., -0.6396, -0.4180,  0.2586],
          ...,
          [-0.0169,  0.4317,  0.4212,  ..., -0.2919, -0.3238,  0.2746],
          [-0.0956,  0.4265,  0.6452,  ..., -0.4469, -0.2293,  0.2843],
          [-0.0654,  0.4877,  0.4979,  ..., -0.3380, -0.5179,  0.2534]]],
        [[[-0.0867, -0.1255,  0.0518,  ...,  0.0743,  0.3874,  0.1485],
          [-0.2078, -0.2976, -0.0520,  ...,  0.1975,  0.4864,  0.3188],
          [-0.3555, -0.3926, -0.1949,  ..., -0.0594,  0.2866,  0.1678],
          ...,
          [-0.0741, -0.0093, -0.0335,  ..., -0.4627, -0.4109, -0.4099],
          [-0.1502, -0.2610, -0.0089,  ..., -0.5464, -0.4563, -0.3472],
          [-0.3529, -0.0813, -0.1138,  ..., -0.7107, -0.5021, -0.3206]]],
        ...,
        [[[-0.2023, -0.1075,  0.2380,  ..., -0.3037, -0.3741, -0.6697],
          [-0.1122,  0.1627,  0.3621,  ..., -0.1771, -0.2028, -0.6150],
          [-0.1781,  0.1338,  0.2335,  ..., -0.2281, -0.1609, -0.6372],
          ...,
          [ 0.2133,  0.5721,  0.5425,  ..., -0.2111, -0.5982, -1.0000],
          [ 0.2245,  0.6823,  0.7837,  ..., -0.1964, -0.5457, -0.7712],
          [ 0.0354,  0.5294,  0.7218,  ..., -0.1959, -0.5757, -0.6634]]],
        [[[-0.3354,  0.0767,  0.1396,  ..., -0.0011, -0.0892, -0.0959],
          [-0.0695,  0.3101, -0.1222,  ..., -0.1576, -0.3334, -0.2210],
          [ 0.2643,  0.3203, -0.0487,  ..., -0.4552, -0.2633,  0.0396],
          ...,
          [ 0.1230,  0.2344,  0.0231,  ..., -0.2070,  0.0612,  0.1623],
          [-0.0550,  0.0772, -0.3358,  ..., -0.2012,  0.1141,  0.1573],
          [-0.1450,  0.2215,  0.1316,  ..., -0.2548, -0.2081, -0.0043]]],
        [[[-0.0502,  0.0982, -0.1208,  ..., -0.4367, -0.8653, -0.6864],
          [-0.0759,  0.0452, -0.1659,  ..., -0.4582, -0.8016, -0.5788],
          [-0.1923,  0.0210,  0.1080,  ..., -0.4411, -0.5559, -0.5272],
          ...,
          [-0.1053, -0.0921, -0.2290,  ..., -0.4205, -0.5063, -0.2641],
          [-0.1287, -0.0286, -0.2052,  ..., -0.4515, -0.5370, -0.2960],
          [-0.0964,  0.0047, -0.1050,  ..., -0.4229, -0.4152, -0.5640]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3252, -0.1180,  0.0200,  ..., -0.2972, -0.2830, -0.5361],
          [-0.3719, -0.0897,  0.0423,  ..., -0.3597, -0.3132, -0.6111],
          [-0.4108, -0.2037, -0.0659,  ..., -0.4968, -0.5317, -0.6266],
          ...,
          [-0.5586, -0.1619, -0.0410,  ..., -0.2606, -0.4247, -0.6339],
          [-0.5230, -0.2557, -0.2141,  ..., -0.3204, -0.6073, -0.8379],
          [-0.4069, -0.1201, -0.0691,  ..., -0.2910, -0.5022, -0.9407]]],
        [[[-0.5089, -0.1073,  0.0231,  ..., -0.5289, -0.6436, -0.8116],
          [-0.4933, -0.2867,  0.1069,  ..., -0.5782, -0.6145, -0.7558],
          [-0.5910, -0.3236, -0.0521,  ..., -0.1863, -0.6142, -0.6562],
          ...,
          [-0.4432,  0.1048,  0.1315,  ..., -0.2348, -0.3751, -0.8144],
          [-0.3338,  0.2959,  0.4431,  ..., -0.3147, -0.4921, -0.5939],
          [-0.3640,  0.2717,  0.3608,  ..., -0.2593, -0.6579, -0.6971]]],
        [[[-0.7371, -0.3519, -0.3140,  ...,  0.8647,  0.5556,  0.2406],
          [-0.4286, -0.3413, -0.6689,  ...,  0.7541,  0.5188,  0.3498],
          [-0.1644, -0.3292, -0.6508,  ...,  0.7707,  0.4740,  0.2570],
          ...,
          [-0.2297, -0.1439,  0.0261,  ...,  0.5734,  0.1885, -0.0844],
          [-0.6614, -0.3586, -0.1738,  ...,  0.5545,  0.1834, -0.2712],
          [-0.5952, -0.2932, -0.3755,  ...,  0.4520,  0.0745, -0.1082]]],
        ...,
        [[[-0.4192, -0.3420,  0.1169,  ...,  0.2650,  0.5940,  0.6221],
          [-0.5959, -0.3779,  0.1390,  ...,  0.3038,  0.4366,  0.4427],
          [-0.6102, -0.0631,  0.0794,  ...,  0.2817,  0.3361,  0.2030],
          ...,
          [-0.9112, -0.4148, -0.0481,  ...,  0.0201,  0.2602,  0.3356],
          [-0.9247, -0.2862, -0.0230,  ...,  0.2933,  0.3637,  0.4580],
          [-0.5250, -0.1850,  0.0939,  ...,  0.2121,  0.1504,  0.4063]]],
        [[[-0.4428, -0.5920, -0.4028,  ..., -0.2274, -0.2374, -0.1621],
          [-0.4251, -0.5123, -0.4000,  ..., -0.4223, -0.3652, -0.1331],
          [-0.5555, -0.4937, -0.3551,  ..., -0.4604, -0.4034, -0.1770],
          ...,
          [-0.3306, -0.2109, -0.5051,  ..., -0.0109,  0.2123, -0.0692],
          [-0.4485, -0.2535, -0.5115,  ..., -0.1488,  0.3260,  0.2701],
          [-0.5115, -0.4663, -0.4587,  ..., -0.3752,  0.2355,  0.2218]]],
        [[[-0.3238, -0.1685,  0.1547,  ...,  0.1417,  0.2777,  0.1726],
          [-0.1452, -0.3440, -0.2077,  ..., -0.0719, -0.0208,  0.0487],
          [-0.2852, -0.2770, -0.2980,  ..., -0.2222, -0.3530, -0.3314],
          ...,
          [-0.6044,  0.0374,  0.0524,  ..., -0.3137, -0.5411, -0.7409],
          [-0.3168, -0.1169, -0.1633,  ..., -0.6733, -1.0000, -0.4968],
          [ 0.0470,  0.0652, -0.5256,  ..., -0.8341, -0.4887, -0.3750]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3515, -0.1250, -0.1367,  ..., -0.0827,  0.0402, -0.4302],
          [-0.4924, -0.3722, -0.3899,  ...,  0.0254,  0.0670, -0.3238],
          [-0.9096, -0.5281, -0.2708,  ...,  0.2266, -0.1445, -0.6431],
          ...,
          [-0.4256, -0.3624, -0.5171,  ...,  0.1729,  0.2295,  0.1842],
          [-0.4956, -0.4103, -0.2495,  ...,  0.3731,  0.0409, -0.2865],
          [-0.3533, -0.2843, -0.3076,  ...,  0.3189,  0.0823, -0.5013]]],
        [[[-0.1456,  0.0644,  0.0918,  ..., -0.1064, -0.1611,  0.1633],
          [ 0.0079,  0.0423,  0.0709,  ..., -0.1965, -0.1899,  0.1441],
          [ 0.1428,  0.1175,  0.1052,  ..., -0.1264, -0.1196, -0.0083],
          ...,
          [-0.1247, -0.1696,  0.0800,  ..., -0.1407, -0.3459,  0.1069],
          [-0.1684, -0.1043, -0.3362,  ..., -0.0876, -0.1110,  0.1602],
          [ 0.0567, -0.0347,  0.1684,  ..., -0.0759, -0.1502,  0.2089]]],
        [[[-0.3817,  0.1473,  0.2117,  ..., -0.3858, -0.3890, -0.1843],
          [-0.4665,  0.2726,  0.3861,  ..., -0.2294, -0.4392, -0.1726],
          [-0.5900,  0.2237,  0.2522,  ..., -0.4927, -0.6267, -0.2366],
          ...,
          [-0.4771,  0.0294,  0.3114,  ..., -0.2765, -0.5887, -0.2414],
          [-0.6265, -0.1329,  0.2690,  ..., -0.2263, -0.4565, -0.2147],
          [-0.9178, -0.0651,  0.0981,  ..., -0.2082, -0.2093, -0.1090]]],
        ...,
        [[[ 0.0613,  0.1263, -0.1486,  ..., -0.6093, -0.3541, -0.0777],
          [-0.0024,  0.1301, -0.2152,  ..., -0.4060, -0.4214, -0.0590],
          [ 0.0165, -0.1759, -0.2369,  ..., -0.3355, -0.3670,  0.0077],
          ...,
          [-0.5950, -0.1870, -0.2301,  ..., -0.4143, -0.5752, -0.1626],
          [-0.0869, -0.1532, -0.1543,  ..., -0.5283, -0.6149, -0.1396],
          [-0.0085,  0.0121,  0.0393,  ..., -0.6050, -0.4602, -0.1854]]],
        [[[-0.2770, -0.3086, -0.2106,  ..., -0.6242, -0.4265, -0.5274],
          [-0.4499, -0.3135, -0.1868,  ..., -0.3479, -0.2846, -0.1731],
          [-0.3585, -0.1252, -0.2709,  ..., -0.0122,  0.0390, -0.0498],
          ...,
          [-0.4701, -0.3361, -0.0845,  ...,  0.0930, -0.2116, -0.6086],
          [-0.4357, -0.4961, -0.2550,  ..., -0.0629, -0.4531, -0.7334],
          [-0.4852, -0.5055, -0.2648,  ..., -0.1660, -0.3967, -0.6937]]],
        [[[-0.1513, -0.1149, -0.1449,  ...,  0.4786,  0.5790,  0.2365],
          [-0.1218, -0.1553, -0.3734,  ...,  0.1590,  0.5258,  0.1756],
          [-0.3991, -0.5609, -0.1837,  ...,  0.2466,  0.6554,  0.5520],
          ...,
          [-0.7159, -0.9015, -0.6230,  ..., -0.7035, -0.1810, -0.0493],
          [-0.6529, -0.5253, -0.6222,  ..., -0.3056, -0.2311,  0.0059],
          [-0.5967, -0.4045, -0.3667,  ..., -0.2775, -0.4713, -0.0362]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2203, -0.2896, -0.3414,  ..., -0.4715, -0.7296, -0.6031],
          [-0.6008, -0.2677, -0.3449,  ..., -0.6770, -0.6485, -0.5552],
          [-0.2207, -0.1315, -0.0680,  ..., -0.7399, -0.6265, -0.6998],
          ...,
          [-0.2887, -0.0980, -0.0031,  ..., -0.5210, -0.4343, -0.3677],
          [-0.1400, -0.1418, -0.1147,  ..., -0.5031, -0.5558, -0.4967],
          [-0.0987, -0.0928, -0.0351,  ..., -0.6284, -0.7044, -0.4681]]],
        [[[-0.6738, -0.2710,  0.2823,  ...,  0.2661,  0.1264, -0.0235],
          [-0.4743, -0.0439,  0.3122,  ...,  0.3514,  0.1998,  0.0261],
          [-0.3503,  0.2057,  0.3395,  ...,  0.5373,  0.4379,  0.0490],
          ...,
          [-0.7287,  0.0696,  0.1821,  ...,  0.6305,  0.3856, -0.0122],
          [-0.8551, -0.1167,  0.0409,  ...,  0.4697,  0.3647,  0.0363],
          [-0.7267, -0.1489,  0.2405,  ...,  0.6235,  0.2408,  0.1466]]],
        [[[-0.5083,  0.0595,  0.6102,  ...,  0.2063,  0.0348, -0.4849],
          [-0.6004,  0.1263,  0.4792,  ...,  0.2346,  0.0245, -0.5025],
          [-0.7044, -0.0178,  0.3445,  ..., -0.0215, -0.2908, -0.3671],
          ...,
          [-0.6329, -0.4523, -0.2389,  ...,  0.2447, -0.0919, -0.4637],
          [-0.6008, -0.4792, -0.2467,  ...,  0.0261, -0.3104, -0.6423],
          [-0.5437, -0.3158, -0.0849,  ...,  0.1197, -0.2073, -0.7479]]],
        ...,
        [[[-0.2801, -0.3555, -0.0413,  ...,  0.1345, -0.2244, -0.2861],
          [-0.3082, -0.3185, -0.0107,  ...,  0.0123, -0.2634, -0.2581],
          [-0.2548, -0.2189, -0.2699,  ..., -0.0387, -0.3268, -0.3505],
          ...,
          [-0.4601, -0.4660, -0.1964,  ...,  0.0119, -0.3279, -0.3238],
          [-0.3232, -0.4176, -0.4553,  ...,  0.1644, -0.1274, -0.3233],
          [-0.2673, -0.2130, -0.4643,  ...,  0.2027, -0.1230, -0.5092]]],
        [[[-0.3296, -0.1311,  0.0752,  ...,  0.5675,  0.1970, -0.3832],
          [-0.2786, -0.0085, -0.0577,  ...,  0.5667,  0.2439,  0.0462],
          [-0.0759, -0.0766, -0.0226,  ...,  0.6147,  0.4134,  0.1528],
          ...,
          [-0.7473, -0.7485, -0.4334,  ...,  0.4985,  0.0710, -0.1811],
          [-1.0000, -0.6880, -0.4857,  ...,  0.5379,  0.0872, -0.0888],
          [-0.9835, -0.7512, -0.2564,  ...,  0.5788,  0.2117, -0.1179]]],
        [[[-0.9316, -0.6680, -0.6436,  ..., -0.7648, -0.3632, -0.2494],
          [-0.8649, -0.8025, -0.6689,  ..., -0.7621, -0.4011, -0.3553],
          [-0.8117, -0.7865, -0.4500,  ..., -0.7454, -0.5188, -0.5069],
          ...,
          [-0.4773, -0.3696, -0.2541,  ..., -0.7194, -0.5220, -0.4959],
          [-0.4143, -0.4397, -0.4496,  ..., -0.7893, -0.7647, -0.4397],
          [-0.4008, -0.2701, -0.3390,  ..., -0.5123, -0.3652, -0.2543]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-1.7973e-01,  2.8134e-01,  2.6579e-01,  ..., -2.0928e-01,
           -2.9165e-01, -6.5362e-01],
          [-7.8638e-02,  2.2631e-01, -3.1235e-01,  ..., -5.6774e-02,
           -2.6704e-01, -8.2264e-01],
          [-5.7617e-02,  2.6373e-01, -4.8195e-02,  ..., -2.9521e-01,
           -4.4160e-01, -8.9231e-01],
          ...,
          [-1.5144e-01,  1.6374e-01,  5.4946e-01,  ..., -3.4476e-01,
           -4.4124e-01, -8.1806e-01],
          [-2.1271e-01,  9.8800e-02,  5.4739e-01,  ..., -2.6230e-01,
           -3.4472e-01, -7.5072e-01],
          [-2.7907e-01,  8.3543e-02,  5.5425e-01,  ..., -3.3246e-01,
           -2.9461e-01, -5.7748e-01]]],
        [[[-5.7168e-01,  1.8950e-02, -1.3053e-01,  ...,  3.3961e-01,
            3.4119e-01,  2.3271e-01],
          [-4.3196e-01,  1.3502e-01,  1.4152e-01,  ...,  4.0897e-01,
            6.9459e-02, -2.1122e-01],
          [-4.6502e-01,  2.1337e-02,  3.6022e-01,  ...,  3.3280e-01,
            8.0235e-02, -1.6791e-01],
          ...,
          [-5.9590e-01,  3.0562e-02,  3.8702e-01,  ...,  3.9445e-01,
            5.2864e-01,  2.9009e-01],
          [-5.9407e-01, -2.2627e-01,  9.9126e-02,  ...,  5.9019e-01,
            3.0025e-01,  2.3005e-01],
          [-5.8366e-01, -1.8883e-01,  6.1778e-02,  ...,  5.3736e-01,
            5.7914e-01,  3.7302e-01]]],
        [[[-3.1168e-01,  1.7220e-01,  3.5002e-01,  ...,  3.5975e-01,
            2.0136e-01,  3.1825e-02],
          [-6.6842e-01, -2.1482e-01,  3.5529e-01,  ...,  2.6109e-01,
            2.0950e-01,  4.0816e-02],
          [-5.6432e-01, -7.8927e-02,  3.2157e-01,  ..., -1.5488e-02,
           -3.2460e-02,  1.7997e-03],
          ...,
          [-3.8105e-01,  2.7122e-01,  3.4139e-01,  ..., -1.7485e-02,
            1.7125e-02,  7.5166e-02],
          [-4.2505e-01,  8.3988e-02,  3.2147e-01,  ...,  1.4931e-01,
            2.7752e-02,  9.8180e-02],
          [-2.6329e-01,  1.6119e-01,  2.3495e-01,  ...,  1.6382e-01,
            1.4668e-01,  1.1124e-01]]],
        ...,
        [[[-5.8060e-01, -3.7297e-01, -3.0586e-01,  ..., -3.9458e-01,
           -5.4109e-01, -7.7075e-01],
          [-7.5754e-01, -3.2817e-01, -1.9371e-01,  ..., -5.2476e-01,
           -5.2051e-01, -7.0391e-01],
          [-6.2921e-01, -2.8305e-01, -1.3673e-01,  ..., -4.5260e-01,
           -5.8398e-01, -7.0287e-01],
          ...,
          [-7.7071e-01, -5.7576e-01, -2.3306e-01,  ..., -3.7513e-01,
           -4.7890e-01, -7.0524e-01],
          [-8.1409e-01, -4.4194e-01, -1.0237e-01,  ..., -3.8286e-01,
           -4.5931e-01, -7.2046e-01],
          [-6.8142e-01, -3.0801e-01, -1.6608e-01,  ..., -4.2926e-01,
           -4.1901e-01, -7.6540e-01]]],
        [[[-9.7357e-02, -8.6932e-02,  4.1987e-02,  ...,  3.4759e-01,
            3.8671e-01,  4.3334e-01],
          [ 4.2887e-03,  8.7440e-04,  1.1236e-01,  ...,  4.3638e-01,
            5.7947e-01,  6.6431e-01],
          [-1.1652e-01, -8.3624e-02, -1.2921e-01,  ...,  3.0628e-01,
            4.5513e-01,  6.1518e-01],
          ...,
          [-1.9037e-01, -3.4132e-01, -3.6311e-01,  ...,  4.0581e-02,
           -3.9976e-02, -6.0216e-01],
          [-8.1783e-02, -1.3699e-01, -2.1934e-01,  ...,  2.0588e-01,
            1.2887e-01, -4.4041e-01],
          [ 1.0339e-01,  2.0017e-01, -2.2737e-02,  ...,  1.9911e-01,
            9.7060e-02,  9.7970e-02]]],
        [[[-7.7206e-01, -1.9364e-01, -1.1582e-01,  ...,  5.3979e-01,
            3.0935e-01,  1.7734e-01],
          [-6.9960e-01, -2.3827e-01, -5.1625e-02,  ...,  3.7951e-01,
            3.4087e-01,  2.7753e-01],
          [-5.9503e-01, -3.0762e-01,  1.2214e-01,  ...,  3.0216e-01,
            4.9636e-01,  1.8668e-01],
          ...,
          [-5.6181e-01,  7.7407e-02,  2.9210e-01,  ...,  2.9416e-01,
            2.6834e-01,  4.5644e-02],
          [-5.5236e-01,  1.5776e-01,  3.9678e-01,  ...,  4.4228e-01,
            3.2036e-01,  1.4958e-01],
          [-4.7442e-01,  5.2352e-02,  2.5949e-01,  ...,  5.6705e-01,
            4.1905e-01, -9.3675e-03]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0430,  0.3140, -0.0802,  ..., -0.4835, -0.6920, -0.8147],
          [-0.1462,  0.2092,  0.0326,  ..., -0.5855, -0.9077, -0.7398],
          [-0.0578,  0.2762,  0.2394,  ..., -0.7101, -0.7295, -0.6801],
          ...,
          [-0.1363,  0.1914, -0.0296,  ..., -0.7249, -0.6253, -0.4251],
          [ 0.0902,  0.2235, -0.2215,  ..., -1.0000, -0.7836, -0.5538],
          [ 0.3665,  0.3105,  0.1383,  ..., -0.7086, -0.6459, -0.5096]]],
        [[[-0.4448, -0.2393, -0.2324,  ..., -0.0325, -0.3445, -0.9046],
          [-0.6359, -0.5489, -0.4767,  ..., -0.1448, -0.4841, -0.8813],
          [-0.4859, -0.4121, -0.6377,  ..., -0.3358, -0.7848, -0.8866],
          ...,
          [-0.4625, -0.4022, -0.4701,  ..., -0.1788, -0.6045, -0.9040],
          [-0.5347, -0.7270, -0.5556,  ..., -0.1791, -0.4077, -0.8077],
          [-0.3582, -0.3582, -0.3709,  ..., -0.2922, -0.4269, -0.9009]]],
        [[[-0.4946, -0.2629, -0.0287,  ...,  0.5066,  0.1517, -0.2441],
          [-0.3649, -0.6631, -0.4682,  ...,  0.4638,  0.2094, -0.1141],
          [-0.4240, -0.5248, -0.5145,  ...,  0.3828, -0.0625, -0.1510],
          ...,
          [-0.6629, -0.6347, -0.7334,  ...,  0.2633,  0.0146, -0.1408],
          [-0.8772, -0.9537, -0.8665,  ...,  0.2202, -0.1766, -0.2892],
          [-0.5607, -0.4612, -0.7359,  ...,  0.2361, -0.3240, -0.4826]]],
        ...,
        [[[-0.8243, -0.0345,  0.4942,  ..., -0.0052, -0.1531, -0.2985],
          [-0.6526,  0.0374,  0.4133,  ..., -0.4096, -0.2109, -0.2316],
          [-0.5701,  0.0879,  0.1066,  ..., -0.7458, -0.2923, -0.2833],
          ...,
          [-0.7458, -0.5186,  0.1955,  ..., -0.0474, -0.0300, -0.1715],
          [-0.7455, -0.0012,  0.3470,  ..., -0.2818, -0.1041, -0.1343],
          [-0.8059,  0.1805,  0.2214,  ..., -0.2258, -0.2840, -0.2755]]],
        [[[-0.6342,  0.0220,  0.2815,  ...,  0.3423, -0.1709, -0.6025],
          [-0.4599, -0.0618,  0.0976,  ...,  0.3392,  0.0525, -0.4505],
          [-0.6437, -0.1699, -0.0041,  ...,  0.0819, -0.0723, -0.3879],
          ...,
          [-0.3950,  0.1711,  0.3508,  ...,  0.1193, -0.3690, -0.8965],
          [-0.3689,  0.1445,  0.2065,  ...,  0.2394, -0.1276, -0.5884],
          [-0.2702,  0.0345,  0.2468,  ...,  0.1163,  0.1300, -0.3935]]],
        [[[-0.6272,  0.1149,  0.2952,  ...,  0.0323, -0.0127, -0.4093],
          [-0.3631,  0.3750,  0.5645,  ..., -0.2372, -0.1600, -0.5002],
          [-0.1378,  0.2872,  0.5077,  ..., -0.1079, -0.3921, -0.8598],
          ...,
          [-0.7184,  0.0254,  0.0086,  ...,  0.0636,  0.0078, -0.3203],
          [-0.5388, -0.0186,  0.0439,  ...,  0.0298,  0.0061, -0.6428],
          [-0.6606, -0.0418,  0.3298,  ...,  0.1665, -0.2745, -0.7140]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2824,  0.4631,  0.8332,  ...,  0.1772,  0.0711, -0.3140],
          [-0.7036,  0.1775,  0.4907,  ..., -0.4764, -0.2175, -0.0336],
          [-0.7103,  0.1611,  0.5846,  ..., -0.4731, -0.0954, -0.2349],
          ...,
          [-0.3234,  0.4044,  0.4613,  ...,  0.4342,  0.2614, -0.1288],
          [-0.3273,  0.3674,  0.1232,  ...,  0.4156,  0.4922, -0.0292],
          [-0.3356,  0.2350,  0.1096,  ...,  0.1542,  0.3581,  0.0679]]],
        [[[-0.4883,  0.2359,  0.3713,  ...,  0.2436,  0.0945,  0.0077],
          [-0.3645,  0.2019,  0.3252,  ...,  0.3077,  0.0556,  0.0876],
          [-0.4674,  0.0638,  0.3623,  ...,  0.3917, -0.0246,  0.0541],
          ...,
          [-0.3266,  0.0029,  0.1599,  ...,  0.0948,  0.1401,  0.0548],
          [-0.4349, -0.0591,  0.3779,  ...,  0.2443,  0.3484,  0.0870],
          [-0.4287,  0.0865,  0.3632,  ...,  0.1850,  0.4203,  0.1579]]],
        [[[-0.3148, -0.2980, -0.3695,  ..., -0.3182, -0.2948, -0.3702],
          [-0.1690, -0.2183, -0.6335,  ..., -0.3247, -0.5808, -0.4016],
          [-0.2272, -0.2409, -0.4080,  ..., -0.2661, -0.5554, -0.4088],
          ...,
          [-0.5521, -0.3648, -0.3547,  ..., -0.6722, -0.5640, -0.4943],
          [-0.3011, -0.3283, -0.5041,  ..., -0.7724, -0.7965, -0.8400],
          [-0.4249, -0.4800, -0.5669,  ..., -0.7205, -0.7903, -0.9568]]],
        ...,
        [[[ 0.1022, -0.0873, -0.2811,  ..., -0.4270, -0.0468,  0.1018],
          [-0.1373, -0.0561, -0.2462,  ..., -0.5179, -0.2265,  0.1036],
          [-0.1124, -0.3307, -0.2344,  ..., -0.4853, -0.1823,  0.1066],
          ...,
          [ 0.0420,  0.1536,  0.2063,  ...,  0.1466,  0.4354,  0.5552],
          [ 0.4047,  0.5601,  0.5424,  ..., -0.0767,  0.1975,  0.4967],
          [ 0.3169,  0.5475,  0.4750,  ..., -0.2103, -0.2093,  0.2762]]],
        [[[-0.6017, -0.1400,  0.1734,  ..., -0.1050, -0.1720, -0.7077],
          [-0.5787, -0.3951,  0.0337,  ..., -0.1733, -0.2766, -1.0000],
          [-0.6859, -0.4403, -0.2555,  ..., -0.1713, -0.3025, -0.9424],
          ...,
          [-0.6526, -0.3176, -0.0022,  ..., -0.2665, -0.3160, -0.6193],
          [-0.7816, -0.3065, -0.0738,  ..., -0.0622, -0.2805, -0.6335],
          [-0.5644, -0.3064, -0.0893,  ..., -0.1526, -0.5418, -0.7425]]],
        [[[-0.5179,  0.0895,  0.3967,  ...,  0.3477,  0.2217, -0.1567],
          [-0.6169, -0.2794,  0.1776,  ...,  0.3366,  0.3127, -0.0350],
          [-0.4823,  0.0203,  0.2001,  ...,  0.1976,  0.3387, -0.0344],
          ...,
          [-0.3850,  0.1921,  0.3050,  ...,  0.4906,  0.3208, -0.0582],
          [-0.3370,  0.2275,  0.5059,  ...,  0.4545,  0.1340, -0.1244],
          [-0.6490,  0.1248,  0.5679,  ...,  0.4726,  0.0477, -0.2258]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4248, -0.2585,  0.0117,  ..., -0.2420, -0.2638, -0.9362],
          [-0.4155, -0.1167,  0.0956,  ..., -0.2092, -0.2437, -0.7016],
          [-0.5011,  0.0038,  0.0281,  ..., -0.3479, -0.1885, -0.6215],
          ...,
          [-0.5500, -0.1953,  0.0634,  ..., -0.3075, -0.2344, -0.7221],
          [-0.7179, -0.3253,  0.0909,  ..., -0.2429, -0.2069, -0.5595],
          [-0.6596, -0.1307,  0.0424,  ..., -0.3479, -0.4343, -0.6950]]],
        [[[-0.3444, -0.4336, -0.5318,  ...,  0.2436,  0.3828,  0.0277],
          [-0.4708, -0.4092, -0.2987,  ...,  0.4497,  0.6499,  0.3286],
          [-0.6439, -0.6237, -0.4763,  ...,  0.3135,  0.4699,  0.2654],
          ...,
          [-0.3405, -0.0889, -0.0768,  ...,  0.6028,  0.2753, -0.3125],
          [-0.3955, -0.1374, -0.0812,  ...,  0.4511,  0.0977, -0.4734],
          [-0.3655, -0.3088, -0.5034,  ...,  0.4791,  0.1371, -0.1813]]],
        [[[-0.5512, -0.0012,  0.2072,  ...,  0.1327, -0.0621,  0.0242],
          [-0.6346, -0.0896,  0.1627,  ...,  0.0012, -0.1435, -0.0643],
          [-0.6036, -0.3051, -0.0517,  ..., -0.0757, -0.1589, -0.3039],
          ...,
          [-0.8702, -0.2300,  0.1216,  ..., -0.1517,  0.0106, -0.1413],
          [-0.5128, -0.3456, -0.0270,  ..., -0.0930,  0.2101,  0.0090],
          [-0.6203, -0.1067,  0.0739,  ...,  0.2769,  0.3658,  0.0477]]],
        ...,
        [[[ 0.0263,  0.2219,  0.2422,  ..., -0.4267, -0.5803, -0.6080],
          [ 0.2209,  0.3078,  0.1564,  ..., -0.2688, -0.2154, -0.5896],
          [ 0.3760,  0.3005,  0.0262,  ..., -0.2966, -0.0712, -0.2850],
          ...,
          [ 0.3789,  0.3603,  0.3957,  ..., -0.0687, -0.4161, -0.4787],
          [ 0.5063,  0.4516,  0.2200,  ..., -0.1500, -0.2557, -0.5039],
          [ 0.3692,  0.4013,  0.3612,  ..., -0.4210, -0.3250, -0.2977]]],
        [[[-0.6546, -0.3091, -0.3621,  ...,  0.1318,  0.3288,  0.3459],
          [-0.7022, -0.6247, -0.2366,  ...,  0.0866,  0.4606,  0.4599],
          [-0.7329, -0.3206, -0.0984,  ...,  0.0478,  0.4266,  0.5271],
          ...,
          [-0.7182, -0.6320, -0.0291,  ..., -0.1560,  0.3186,  0.4232],
          [-0.6474, -0.4409, -0.2366,  ..., -0.0641,  0.1223,  0.3972],
          [-0.7262, -0.1435, -0.3551,  ...,  0.0109,  0.0464,  0.1605]]],
        [[[ 0.0449,  0.1936,  0.2736,  ..., -0.7290, -0.6031, -0.5374],
          [ 0.2289,  0.2729,  0.1250,  ..., -0.6856, -1.0000, -0.6283],
          [ 0.3192,  0.3337, -0.0355,  ..., -0.5785, -0.4742, -0.4855],
          ...,
          [ 0.3798,  0.2361,  0.2312,  ..., -0.5228, -0.4154, -0.3922],
          [ 0.3085,  0.1381, -0.0014,  ..., -0.5337, -0.3717, -0.3664],
          [ 0.1633,  0.0947, -0.0799,  ..., -0.3059, -0.3369, -0.3451]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-6.6102e-01, -1.7313e-01,  3.7031e-03,  ...,  7.7830e-01,
            5.7036e-01,  1.0480e-01],
          [-3.5009e-01, -4.4367e-02,  1.0910e-01,  ...,  8.8603e-01,
            6.8428e-01,  1.7159e-01],
          [-2.9094e-01,  2.0953e-01,  3.8548e-01,  ...,  8.8440e-01,
            6.0581e-01,  3.5601e-01],
          ...,
          [-2.2190e-01,  1.8314e-01,  2.7090e-01,  ...,  7.4318e-01,
            5.2275e-01,  2.6425e-01],
          [-3.5906e-01, -4.6266e-02,  3.4066e-01,  ...,  6.2042e-01,
            6.3062e-01,  4.0979e-01],
          [-3.9736e-01, -1.8785e-01,  2.0669e-01,  ...,  3.5455e-01,
            6.2360e-01,  2.9171e-01]]],
        [[[-7.4899e-01, -4.7170e-01, -6.3580e-01,  ..., -3.7864e-01,
           -3.3611e-01, -6.2380e-01],
          [-7.4851e-01, -4.7097e-01, -5.1404e-01,  ..., -2.7774e-01,
           -3.3616e-01, -5.3287e-01],
          [-7.3762e-01, -3.9263e-01, -4.6112e-01,  ...,  2.8897e-02,
           -7.2022e-03, -2.9592e-01],
          ...,
          [-2.2270e-01,  5.4493e-02,  1.3479e-01,  ..., -1.7823e-01,
           -1.4954e-01, -4.0613e-01],
          [-1.5439e-01,  2.2712e-01,  3.3529e-01,  ..., -2.8280e-01,
           -2.0944e-01, -2.4506e-01],
          [-3.1009e-01,  4.8797e-02,  1.8488e-01,  ..., -1.6235e-01,
           -1.2420e-02,  1.7612e-02]]],
        [[[-2.5199e-01,  2.5053e-02, -1.1995e-01,  ...,  1.3843e-01,
           -2.0670e-01,  2.5515e-02],
          [-2.9277e-01,  1.9200e-01,  2.6364e-01,  ...,  3.6215e-02,
           -1.1670e-01,  3.3583e-02],
          [-3.6251e-01,  7.0892e-02,  1.9729e-01,  ..., -1.5514e-01,
           -2.4290e-01,  1.1037e-02],
          ...,
          [-6.8296e-01, -2.2456e-03,  1.9190e-01,  ..., -2.5116e-01,
           -1.7732e-01, -5.8180e-02],
          [-5.9118e-01, -1.2735e-01,  2.0527e-01,  ..., -1.1371e-01,
           -2.2764e-01,  2.5366e-02],
          [-6.8066e-01, -3.3344e-01,  3.8195e-04,  ..., -2.5478e-01,
           -2.0066e-01,  1.4540e-02]]],
        ...,
        [[[-4.0143e-01, -3.6239e-01, -2.1575e-01,  ..., -6.8857e-01,
           -6.6422e-01, -1.9830e-01],
          [-5.1332e-01, -4.5437e-01, -2.7593e-01,  ..., -7.1781e-01,
           -4.3896e-01, -1.7264e-01],
          [-9.9770e-01, -6.0703e-01, -1.8175e-01,  ..., -6.7741e-01,
           -5.7290e-01, -1.9060e-01],
          ...,
          [-4.6441e-01, -2.6298e-01, -1.2503e-01,  ..., -4.0097e-01,
           -3.4924e-01, -2.8752e-02],
          [-2.7909e-01, -2.9444e-01, -3.2990e-02,  ..., -8.8960e-01,
           -4.9369e-01, -3.3162e-02],
          [-2.5102e-01, -2.8009e-01, -1.4840e-01,  ..., -6.9363e-01,
           -5.2469e-01, -3.7802e-02]]],
        [[[-1.2312e-01, -1.4611e-01, -1.7425e-01,  ..., -2.8394e-01,
           -4.7503e-01, -7.3060e-01],
          [-1.0325e-01, -1.9924e-01, -2.2909e-01,  ..., -3.5183e-01,
           -4.7335e-01, -8.4011e-01],
          [-3.0368e-01, -1.0365e-01, -2.5156e-01,  ..., -4.3974e-01,
           -7.7874e-01, -1.0000e+00],
          ...,
          [-2.9314e-01, -4.9439e-01, -3.6365e-01,  ..., -7.2136e-01,
           -9.6029e-01, -4.4131e-01],
          [-4.8692e-01, -2.5514e-01, -4.8261e-01,  ..., -6.8213e-01,
           -7.1012e-01, -3.4844e-01],
          [-3.8431e-01, -1.1142e-01, -2.5141e-01,  ..., -7.5919e-01,
           -7.6916e-01, -3.6773e-01]]],
        [[[-9.6722e-01,  1.4537e-01,  4.0691e-01,  ...,  9.8972e-02,
           -5.8861e-02,  1.4813e-02],
          [-8.4266e-01,  1.2758e-01,  3.0721e-01,  ...,  9.7103e-02,
           -3.8236e-01, -5.4649e-02],
          [-8.7153e-01,  1.9909e-01,  6.5239e-01,  ...,  9.1684e-02,
           -1.7136e-01, -1.0592e-01],
          ...,
          [-2.2414e-01,  8.4145e-02,  4.8548e-01,  ...,  1.3301e-01,
           -3.3363e-02, -6.4736e-03],
          [-1.9377e-01,  1.6719e-01,  5.7875e-01,  ...,  1.0972e-01,
           -6.0081e-01, -3.5453e-02],
          [-2.2741e-01,  4.6640e-01,  7.9947e-01,  ...,  2.1945e-01,
           -6.2497e-01, -6.7296e-02]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2692,  0.1662,  0.2958,  ...,  0.6271,  0.3990,  0.0459],
          [-0.3042,  0.1969,  0.4005,  ...,  0.6793,  0.4694,  0.1890],
          [-0.5216,  0.1911,  0.6625,  ...,  0.8631,  0.6732,  0.2276],
          ...,
          [-0.5492, -0.0040,  0.2524,  ...,  0.2774,  0.1012, -0.1093],
          [-0.7731, -0.1576,  0.1160,  ...,  0.0454, -0.2005, -0.1776],
          [-0.7896, -0.3738, -0.0425,  ...,  0.0813, -0.2015, -0.0637]]],
        [[[-0.3385, -0.0907,  0.1799,  ..., -0.1618,  0.0611,  0.1947],
          [-0.4582,  0.0500,  0.2618,  ..., -0.0525,  0.1156,  0.1709],
          [-0.4807,  0.0474,  0.3180,  ..., -0.2298, -0.0236,  0.1707],
          ...,
          [-0.9849, -0.1177,  0.2856,  ...,  0.0754,  0.0128,  0.1348],
          [-0.8692,  0.0177,  0.1928,  ...,  0.0744,  0.2436,  0.3045],
          [-1.0000, -0.0442, -0.0954,  ...,  0.2954,  0.3422,  0.0579]]],
        [[[-0.1762, -0.0099, -0.0946,  ..., -0.6046, -0.3758, -0.2724],
          [-0.0725,  0.0262,  0.0566,  ..., -0.5245, -0.6798, -0.4391],
          [-0.0468, -0.1255, -0.0370,  ..., -0.4232, -0.5951, -0.3787],
          ...,
          [-0.1108, -0.0751, -0.0796,  ..., -0.2974, -0.2535, -0.5231],
          [-0.1109,  0.0046,  0.0203,  ..., -0.1945, -0.1192, -0.1727],
          [-0.2753, -0.0481, -0.0140,  ..., -0.3705, -0.2993, -0.0992]]],
        ...,
        [[[-0.5530, -0.1150,  0.1437,  ..., -0.0902, -0.3503, -0.8174],
          [-0.7071, -0.2931, -0.1364,  ..., -0.1564, -0.3935, -0.7726],
          [-0.5212, -0.2489, -0.2779,  ..., -0.1068, -0.2905, -0.7737],
          ...,
          [-0.4223, -0.2400, -0.2862,  ..., -0.2694, -0.3566, -0.7795],
          [-0.3649, -0.1073, -0.3276,  ..., -0.3786, -0.3434, -0.7901],
          [-0.4109, -0.0472, -0.0929,  ..., -0.4135, -0.4779, -1.0000]]],
        [[[-0.4094,  0.4288,  0.3361,  ...,  0.2847,  0.2937, -0.1633],
          [-0.5388,  0.3565,  0.3966,  ...,  0.1736,  0.2900, -0.0549],
          [-0.3708,  0.2653,  0.4323,  ...,  0.1703,  0.0966,  0.0697],
          ...,
          [-0.0294,  0.4955,  0.5462,  ...,  0.1414,  0.1867, -0.0483],
          [ 0.0286,  0.3423, -0.1348,  ...,  0.2775, -0.1782, -0.1732],
          [-0.0987,  0.2043,  0.2847,  ...,  0.1100, -0.2348, -0.2357]]],
        [[[-0.1576,  0.4424,  0.5362,  ...,  0.2246, -0.1315, -0.1546],
          [-0.1931,  0.4488,  0.4354,  ...,  0.3293,  0.0234, -0.0321],
          [-0.3681,  0.2406,  0.2141,  ...,  0.2364, -0.2019, -0.1878],
          ...,
          [-0.5139, -0.0705,  0.0756,  ...,  0.0224, -0.0659, -0.3666],
          [-0.4579, -0.1886,  0.1343,  ...,  0.2480,  0.0026, -0.4671],
          [-0.5858, -0.1893,  0.1898,  ...,  0.2652, -0.1387, -0.4332]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.3404,  0.2440, -0.4176,  ..., -0.6357, -0.5758, -0.2291],
          [ 0.1149,  0.1823,  0.2528,  ..., -0.7060, -0.4641, -0.4928],
          [-0.2650,  0.0941,  0.3539,  ..., -0.4612, -0.2453, -0.1658],
          ...,
          [ 0.3127,  0.3144,  0.1215,  ..., -0.2078, -0.4702, -0.1736],
          [ 0.1195,  0.1399, -0.0675,  ..., -0.1386, -0.2687,  0.0402],
          [ 0.1896,  0.3587,  0.0108,  ..., -0.3122, -0.0758,  0.1369]]],
        [[[-0.2714,  0.2206,  0.1629,  ..., -0.0480, -0.2083,  0.3283],
          [-0.3072, -0.0412, -0.0040,  ...,  0.1108,  0.0564,  0.2947],
          [-0.5686, -0.2717, -0.2347,  ...,  0.2955, -0.0077,  0.3212],
          ...,
          [-0.0904,  0.5035,  0.6788,  ...,  0.4701,  0.2402,  0.2803],
          [-0.2822,  0.1530,  0.2860,  ...,  0.3052,  0.1356,  0.3213],
          [-0.0988,  0.3691,  0.4758,  ...,  0.0832, -0.2668,  0.2459]]],
        [[[-0.6350, -0.3919,  0.0301,  ...,  0.4753,  0.7088,  0.5835],
          [-0.6631, -0.5454, -0.0097,  ...,  0.2419,  0.4964,  0.3034],
          [-0.5913, -0.4286, -0.1552,  ...,  0.3088,  0.6617,  0.5589],
          ...,
          [-0.8534, -0.3282, -0.1305,  ...,  0.1865,  0.4999,  0.4331],
          [-1.0000, -0.3578, -0.0579,  ...,  0.2731,  0.5829,  0.3959],
          [-0.9431, -0.3688,  0.0793,  ...,  0.4086,  0.7521,  0.6280]]],
        ...,
        [[[-0.3450, -0.2973, -0.1854,  ..., -0.8535, -0.6225, -0.7764],
          [-0.3789, -0.2156, -0.2682,  ..., -0.9783, -0.8236, -0.7041],
          [-0.2206, -0.0547, -0.1398,  ..., -0.7219, -1.0000, -0.7274],
          ...,
          [-0.7734, -0.6215, -0.5742,  ..., -0.4884, -0.8365, -0.9556],
          [-0.7016, -0.5582, -0.5011,  ..., -0.4657, -0.6457, -0.7201],
          [-0.4392, -0.4700, -0.5820,  ..., -0.4887, -0.5938, -0.7263]]],
        [[[-0.1956, -0.1597, -0.1583,  ..., -0.5787, -0.3943, -0.3778],
          [-0.1072, -0.0856, -0.2754,  ..., -0.5752, -0.4977, -0.6008],
          [ 0.0675, -0.0290,  0.0660,  ..., -0.4441, -0.6103, -0.8006],
          ...,
          [ 0.4251,  0.5929,  0.4792,  ..., -0.3117, -0.0930, -0.5253],
          [ 0.0661,  0.3737,  0.2406,  ..., -0.2134, -0.2712, -0.5177],
          [ 0.2551,  0.2793,  0.2990,  ..., -0.4501, -0.4260, -0.4499]]],
        [[[-0.0618, -0.1595, -0.3327,  ..., -0.3764, -0.0987,  0.3190],
          [-0.1710, -0.1087, -0.0890,  ..., -0.5883, -0.0629,  0.3474],
          [-0.7091, -0.3466, -0.2946,  ..., -0.2989, -0.0938,  0.3311],
          ...,
          [-0.3783, -0.2320, -0.2865,  ..., -0.5834, -0.1857,  0.1648],
          [-0.4198, -0.0820, -0.3157,  ..., -0.4995, -0.1410,  0.1956],
          [-0.2491, -0.0090, -0.3832,  ..., -0.5880, -0.3555,  0.1650]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.2265,  0.2291,  0.2315,  ..., -0.2892, -0.4891, -0.3794],
          [-0.0030, -0.0308,  0.2634,  ..., -0.3072, -0.4912, -0.8205],
          [-0.0501, -0.0285,  0.2018,  ..., -0.5285, -0.5217, -0.7334],
          ...,
          [ 0.0645,  0.2634,  0.4938,  ..., -0.3373, -0.4032, -0.3244],
          [ 0.1095,  0.4346,  0.5394,  ..., -0.3963, -0.3371, -0.3649],
          [ 0.2615,  0.3270,  0.2456,  ..., -0.3326, -0.4200, -0.2883]]],
        [[[-0.2417, -0.1377,  0.1717,  ..., -0.0656, -0.4633, -0.5071],
          [-0.3134,  0.1036,  0.2527,  ...,  0.1218, -0.1111, -0.3796],
          [-0.3711,  0.0765,  0.2713,  ...,  0.1102, -0.1288, -0.2841],
          ...,
          [-0.4882,  0.1668,  0.3160,  ...,  0.3017, -0.1168, -0.5610],
          [-0.4703,  0.1130,  0.2572,  ...,  0.1393, -0.1841, -0.5546],
          [-0.6919, -0.1219,  0.0367,  ...,  0.1048, -0.1205, -0.6007]]],
        [[[-0.1651, -0.0571,  0.2038,  ..., -0.4413, -0.2816, -0.0429],
          [-0.2086, -0.0978,  0.0558,  ..., -0.3332, -0.3742,  0.0175],
          [-0.2199, -0.4372, -0.1628,  ..., -0.3608, -0.3454,  0.0184],
          ...,
          [-0.1611,  0.3311,  0.4656,  ..., -0.2294, -0.4059, -0.0768],
          [-0.2505,  0.2137,  0.3139,  ..., -0.3875, -0.4568, -0.1342],
          [ 0.1074,  0.4309,  0.4885,  ..., -1.0000, -0.3442, -0.0259]]],
        ...,
        [[[-0.3079, -0.6963, -0.3175,  ..., -0.2225, -0.0831,  0.1432],
          [-0.0755, -0.4968, -0.3458,  ..., -0.5537, -0.1876,  0.0694],
          [-0.0568, -0.0142, -0.2793,  ..., -0.8013, -0.4039, -0.0493],
          ...,
          [-0.3706, -0.1801, -0.1201,  ...,  0.1132, -0.0820, -0.1160],
          [-0.0665, -0.1100, -0.3248,  ..., -0.0187, -0.1414, -0.3303],
          [-0.0488, -0.2511, -0.0868,  ..., -0.2266, -0.1169, -0.0852]]],
        [[[-0.5404, -0.2461, -0.1645,  ...,  0.0424,  0.0072, -0.4149],
          [-1.0000, -0.4293, -0.2655,  ..., -0.0058, -0.1859, -0.6140],
          [-0.4988, -0.4449, -0.2952,  ..., -0.0085, -0.0744, -0.6395],
          ...,
          [-0.6444, -0.2682, -0.4276,  ...,  0.1715, -0.0856, -0.4131],
          [-0.4947, -0.2402, -0.6198,  ...,  0.2782,  0.1731, -0.2500],
          [-0.6452, -0.3440, -0.4153,  ...,  0.2937,  0.0874, -0.3681]]],
        [[[-0.1643, -0.1429, -0.3693,  ..., -0.7072, -0.7437, -0.7029],
          [-0.2723, -0.2162, -0.3428,  ..., -0.7638, -0.6753, -0.6261],
          [-0.6443, -0.4779, -0.3592,  ..., -0.4364, -0.6485, -0.6412],
          ...,
          [-0.4474, -0.2723, -0.1228,  ..., -0.3410, -0.5642, -0.5445],
          [-0.4890, -0.3880, -0.1768,  ..., -0.3585, -0.4897, -0.6497],
          [-0.5094, -0.3999, -0.2928,  ..., -0.4057, -0.5389, -0.6821]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0521,  0.0461, -0.3019,  ..., -0.1475, -0.2872, -0.5461],
          [-0.1046, -0.0016, -0.3130,  ..., -0.0776, -0.5663, -0.9552],
          [-0.2304, -0.0883, -0.1440,  ..., -0.1012, -0.3570, -0.4978],
          ...,
          [-0.3502, -0.1241, -0.2002,  ...,  0.2964,  0.1883,  0.6157],
          [-0.5068, -0.1094,  0.0859,  ...,  0.1289,  0.4520,  0.6309],
          [-0.2964, -0.1092, -0.0413,  ..., -0.1493,  0.2781,  0.4923]]],
        [[[-0.4873,  0.1676,  0.3300,  ...,  0.1028,  0.1660, -0.2973],
          [-0.4527,  0.0994,  0.4332,  ...,  0.1568,  0.1761, -0.0992],
          [-0.7212, -0.2503,  0.2795,  ...,  0.2268,  0.1512, -0.1049],
          ...,
          [-0.6136,  0.1633,  0.4442,  ...,  0.0156, -0.0045, -0.5366],
          [-0.9921, -0.1603,  0.2351,  ...,  0.0565, -0.2428, -0.6468],
          [-0.7199, -0.2124,  0.1563,  ..., -0.2450, -0.6193, -0.6075]]],
        [[[ 0.5012,  0.5949,  0.5285,  ..., -0.0516, -0.5531, -0.1850],
          [ 0.6316,  0.4363,  0.2160,  ...,  0.0377, -0.3585, -0.1138],
          [ 0.7431,  0.4800,  0.2356,  ..., -0.2767, -0.3971, -0.2026],
          ...,
          [-0.0414,  0.0883,  0.0715,  ..., -0.4485, -0.3820, -0.3935],
          [ 0.1733,  0.4610,  0.2097,  ..., -0.5166, -0.5129, -0.4295],
          [ 0.5607,  0.5912,  0.3627,  ..., -0.5329, -0.5955, -0.5110]]],
        ...,
        [[[-0.0676, -0.2239, -0.1367,  ...,  0.2210,  0.0808,  0.1330],
          [-0.2605, -0.3493, -0.2528,  ...,  0.2336, -0.0683, -0.0714],
          [-0.4049, -0.1999, -0.3463,  ...,  0.3151, -0.0918, -0.3939],
          ...,
          [-0.1765, -0.1418, -0.7583,  ...,  0.1185, -0.0121, -0.0484],
          [ 0.0166,  0.0749, -0.4005,  ...,  0.0739, -0.1466, -0.0180],
          [-0.1093, -0.0593, -0.2180,  ...,  0.0276, -0.1122, -0.0581]]],
        [[[-0.5038, -0.0092, -0.0590,  ...,  0.1424,  0.2724, -0.3948],
          [-0.5676, -0.2876, -0.0298,  ...,  0.3260,  0.2067, -0.3517],
          [-0.6061, -0.2281,  0.0576,  ...,  0.5073,  0.2198, -0.1664],
          ...,
          [-0.5257, -0.1630,  0.3539,  ...,  0.2724,  0.3010, -0.4433],
          [-0.4353, -0.2325,  0.1591,  ...,  0.4184,  0.2873, -0.4503],
          [-0.3299,  0.0644,  0.3544,  ...,  0.3298,  0.2024, -0.4406]]],
        [[[-0.3227,  0.3435,  0.6124,  ..., -0.0389, -0.4288,  0.3256],
          [-0.3792,  0.0314,  0.4862,  ..., -0.0870, -0.4877,  0.3282],
          [-0.4478, -0.0299,  0.0954,  ..., -0.2931, -0.5568,  0.3530],
          ...,
          [-0.7486,  0.1013,  0.2954,  ...,  0.1679, -0.2998,  0.3487],
          [-0.5919, -0.1651, -0.3100,  ..., -0.2015, -0.4636,  0.3559],
          [-0.7484, -0.1317,  0.0501,  ..., -0.7418, -0.4712,  0.3294]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0809,  0.1189, -0.0529,  ...,  0.2443,  0.4613,  0.2524],
          [-0.2904, -0.0071,  0.0295,  ..., -0.0871,  0.0378,  0.1986],
          [-0.4107, -0.3733, -0.4196,  ..., -0.0889, -0.2159,  0.0495],
          ...,
          [-0.5907, -0.2485, -0.2508,  ..., -0.1017, -0.0259, -0.1905],
          [-0.6774, -0.1906, -0.2046,  ...,  0.1283,  0.1190,  0.0670],
          [-0.7147, -0.4030, -0.2926,  ...,  0.2747,  0.2552,  0.1756]]],
        [[[-0.0828,  0.3886,  0.4843,  ..., -0.8838, -0.7195, -0.5371],
          [ 0.0788,  0.5553,  0.4553,  ..., -0.5166, -0.5627, -0.7636],
          [ 0.3511,  0.3682,  0.2922,  ..., -0.7160, -0.8342, -0.9668],
          ...,
          [-0.3656, -0.5516, -0.3484,  ..., -0.5758, -0.7655, -0.4670],
          [-0.2905, -0.2888, -0.3047,  ..., -0.5675, -0.7711, -0.4801],
          [-0.4104, -0.4392, -0.2280,  ..., -0.7828, -0.6428, -0.3826]]],
        [[[-0.2672, -0.1462, -0.2249,  ..., -0.6055, -0.8042, -0.7424],
          [-0.1019, -0.1767, -0.2489,  ..., -0.7211, -0.8598, -0.8239],
          [-0.1798, -0.4320, -0.4157,  ..., -0.6745, -0.6295, -0.5676],
          ...,
          [-0.3784, -0.4551, -0.3476,  ..., -0.5942, -0.3428, -0.3042],
          [-0.2221, -0.2897, -0.2397,  ..., -0.4301, -0.3924, -0.5171],
          [-0.2347, -0.2656, -0.1123,  ..., -0.3534, -0.3808, -0.3137]]],
        ...,
        [[[-0.2256, -0.3408, -0.3029,  ..., -0.0434, -0.2847, -0.0915],
          [-0.4008, -0.3428, -0.6264,  ..., -0.0871, -0.1895, -0.0431],
          [-0.2817, -0.3665, -0.6729,  ...,  0.0325, -0.1025, -0.0746],
          ...,
          [-0.3018, -0.1312,  0.0793,  ..., -0.3474, -0.4620, -0.2560],
          [-0.4080, -0.2865, -0.0722,  ..., -0.3348, -0.4687, -0.2057],
          [-0.8539, -0.2888, -0.3265,  ..., -0.2934, -0.4381, -0.1634]]],
        [[[-0.6197, -0.3820, -0.2246,  ..., -0.0718,  0.0893, -0.3064],
          [-0.6758, -0.5204, -0.4695,  ..., -0.1039, -0.0106, -0.4691],
          [-0.8825, -0.9421, -0.6731,  ..., -0.1347, -0.0292, -0.4417],
          ...,
          [-0.2949, -0.1506,  0.1983,  ...,  0.0844,  0.2070,  0.2433],
          [-0.4023, -0.3097,  0.1157,  ...,  0.0051,  0.2709,  0.3339],
          [-0.4223, -0.3012, -0.0888,  ..., -0.0035,  0.2269,  0.2105]]],
        [[[-0.4881, -0.3398, -0.2031,  ..., -0.2314, -0.4928, -0.7635],
          [-0.5675, -0.4246, -0.2844,  ..., -0.4075, -0.5938, -0.8999],
          [-0.2333, -0.1824, -0.3125,  ..., -0.3366, -0.2876, -0.2763],
          ...,
          [-0.0499, -0.0967, -0.0273,  ..., -0.4626, -0.4498, -0.7022],
          [-0.0940, -0.0812, -0.0191,  ..., -0.4623, -0.5122, -0.5321],
          [-0.3671, -0.1044,  0.0478,  ..., -0.4445, -0.5867, -0.4981]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4124, -0.6395, -0.4160,  ..., -0.6468, -0.2271, -0.2133],
          [-0.4452, -0.6942, -0.7427,  ..., -0.7674, -0.2984, -0.4910],
          [-0.6726, -0.8630, -0.6596,  ..., -0.2891, -0.3386, -0.6608],
          ...,
          [-0.2081, -0.2221, -0.2244,  ..., -0.3121, -0.1034, -0.2134],
          [-0.4800, -0.6001, -0.4371,  ..., -0.4733, -0.3096, -0.2602],
          [-0.2806, -0.3303, -0.5816,  ..., -0.4077, -0.5182, -0.5178]]],
        [[[-0.1086, -0.2014, -0.3007,  ..., -0.6193, -0.8136, -0.4807],
          [-0.3958, -0.3574, -0.0347,  ..., -0.5579, -0.8502, -0.5340],
          [-0.2352, -0.1402, -0.1544,  ..., -0.5897, -1.0000, -0.7131],
          ...,
          [-0.4341, -0.4626, -0.3103,  ...,  0.0666,  0.0671,  0.2144],
          [-0.0300, -0.1845, -0.0592,  ..., -0.2487, -0.2024,  0.1723],
          [ 0.0640, -0.0126, -0.0231,  ..., -0.6003, -0.2567,  0.1038]]],
        [[[-0.3391, -0.1520,  0.1494,  ...,  0.4174,  0.1008, -0.1741],
          [-0.0485,  0.0132,  0.4806,  ...,  0.6123, -0.0015, -0.2658],
          [ 0.0491,  0.2306,  0.4752,  ...,  0.6730,  0.1956, -0.5724],
          ...,
          [-0.0755,  0.2667,  0.2873,  ...,  0.8868,  0.5018, -0.8532],
          [-0.1750,  0.2246,  0.3288,  ...,  0.9223,  0.4399, -0.8092],
          [ 0.1458, -0.1248, -0.0010,  ...,  0.8117,  0.1829, -0.8642]]],
        ...,
        [[[-0.8307, -0.7164, -0.6405,  ..., -0.5765, -0.4830, -0.6887],
          [-0.4098, -0.3877, -0.3865,  ..., -0.3617, -0.4412, -0.7872],
          [-0.3007, -0.3305, -0.3582,  ..., -0.5559, -0.5915, -0.7153],
          ...,
          [-0.2041, -0.0752, -0.3849,  ..., -0.6390, -0.7038, -0.5992],
          [-0.1600, -0.2364, -0.2808,  ..., -0.6232, -0.5641, -0.6391],
          [-0.4065, -0.4713, -0.3480,  ..., -0.7913, -0.6044, -0.8039]]],
        [[[-0.8205, -0.0675,  0.4178,  ...,  0.1393,  0.0174, -0.2842],
          [-0.8504, -0.1366,  0.0891,  ...,  0.2296, -0.1538, -0.5864],
          [-0.6249, -0.1457,  0.2097,  ...,  0.2421, -0.1013, -0.4621],
          ...,
          [-0.6624,  0.1569,  0.6268,  ...,  0.4872,  0.0493, -0.4967],
          [-0.7205,  0.0264,  0.4656,  ...,  0.4804,  0.2416, -0.2278],
          [-0.6673,  0.0685,  0.6582,  ...,  0.1587,  0.0742, -0.4446]]],
        [[[-0.5137, -0.0538, -0.0063,  ...,  0.0421, -0.1222, -0.0870],
          [-0.6484, -0.1168,  0.1473,  ..., -0.0304, -0.3213, -0.0507],
          [-0.6480, -0.0706,  0.1487,  ..., -0.0746, -0.4732, -0.0594],
          ...,
          [-0.5188, -0.1192,  0.1857,  ..., -0.0490, -0.0472,  0.0052],
          [-0.5261,  0.0914,  0.3697,  ...,  0.0118, -0.4305,  0.0107],
          [-0.6386, -0.0526,  0.2767,  ...,  0.0099, -0.3713, -0.0714]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.6192, -0.1866, -0.1274,  ..., -0.3163, -0.0453, -0.0341],
          [-0.2501, -0.2909, -0.2303,  ..., -0.2455,  0.0168, -0.0741],
          [ 0.0715, -0.1229, -0.2239,  ..., -0.2147, -0.0810, -0.1601],
          ...,
          [-0.6518, -0.3529, -0.2558,  ..., -0.6980, -0.6115, -0.7023],
          [-0.3657, -0.1759, -0.2159,  ..., -0.6430, -0.5544, -0.5375],
          [-0.2908, -0.3402, -0.5028,  ..., -0.8109, -0.5629, -0.5164]]],
        [[[-0.6356, -0.3038, -0.0620,  ..., -0.0276, -0.2846, -0.5696],
          [-0.9407, -0.3538, -0.3222,  ..., -0.0328, -0.2926, -0.5594],
          [-0.9196, -0.4238, -0.3212,  ...,  0.0303, -0.1973, -0.7360],
          ...,
          [-0.7031, -0.1361,  0.1266,  ...,  0.0133, -0.0625, -0.4616],
          [-0.4768, -0.1186,  0.1971,  ..., -0.0246, -0.1100, -0.4847],
          [-0.4832, -0.1360,  0.1761,  ...,  0.1288, -0.0595, -0.4690]]],
        [[[-0.7445, -0.0634,  0.3306,  ..., -0.4337, -0.2191, -0.6511],
          [-0.8320, -0.2603,  0.1850,  ..., -0.0402, -0.1791, -0.6375],
          [-0.7214, -0.3595, -0.0155,  ...,  0.1567, -0.1238, -0.5932],
          ...,
          [-0.5477,  0.1614,  0.2390,  ..., -0.0997, -0.1065, -0.6836],
          [-0.4259,  0.1021,  0.1444,  ..., -0.0203, -0.2877, -0.6483],
          [-0.6005, -0.0929, -0.0676,  ...,  0.0835, -0.3005, -0.6827]]],
        ...,
        [[[-0.3896, -0.1034,  0.1858,  ..., -0.0610, -0.2162, -0.0849],
          [-0.5408, -0.0176,  0.1402,  ..., -0.0046, -0.0725, -0.0837],
          [-0.6101, -0.1516,  0.0039,  ..., -0.0037, -0.0913, -0.1275],
          ...,
          [-0.4691, -0.1418,  0.1427,  ..., -0.0543, -0.1297, -0.0633],
          [-0.6402, -0.2064,  0.1102,  ...,  0.0862, -0.2234, -0.0623],
          [-0.4546, -0.1194, -0.0175,  ..., -0.0361, -0.2858, -0.0923]]],
        [[[-0.5540, -0.4616, -0.1204,  ..., -0.3934, -0.6201, -0.7295],
          [-0.7178, -0.1790,  0.0337,  ..., -0.2028, -0.5512, -0.8855],
          [-0.6216, -0.0265,  0.2115,  ..., -0.1846, -0.3297, -0.8693],
          ...,
          [-0.7097, -0.1815, -0.1795,  ..., -0.4026, -0.7176, -0.6005],
          [-0.5691, -0.1160, -0.2179,  ..., -0.4428, -0.3949, -0.7757],
          [-0.5344, -0.0426, -0.0948,  ..., -0.2614, -0.3887, -0.7356]]],
        [[[-0.5946, -0.1060, -0.2330,  ..., -0.2374, -0.4576, -0.6092],
          [-0.6215, -0.2249, -0.1215,  ..., -0.2133, -0.3043, -0.4053],
          [-0.6295,  0.0086,  0.0572,  ..., -0.3324, -0.2225, -0.5672],
          ...,
          [-0.7627, -0.1953,  0.2520,  ..., -0.1034, -0.1955, -0.4352],
          [-0.7398, -0.2315,  0.2801,  ..., -0.0442, -0.2415, -0.6948],
          [-0.6002, -0.0866,  0.1760,  ..., -0.0263, -0.3425, -0.6618]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 1.9017e-01,  2.2717e-01,  1.7877e-01,  ..., -1.1396e-01,
           -3.6838e-01, -2.5742e-01],
          [-2.0757e-01, -1.4008e-02,  2.9830e-01,  ..., -2.5937e-01,
           -5.3105e-01, -3.4625e-01],
          [-2.6018e-01, -3.1060e-01,  1.3013e-01,  ..., -3.2632e-01,
           -5.1373e-01, -6.0173e-01],
          ...,
          [ 7.1309e-03,  1.8902e-02,  1.6602e-01,  ..., -4.0307e-01,
           -3.6650e-01, -6.2267e-01],
          [ 5.2573e-02, -6.6410e-02, -1.5643e-01,  ..., -5.2892e-01,
           -6.1550e-01, -6.0115e-01],
          [ 1.1671e-01, -1.9973e-01, -1.8190e-01,  ..., -4.6499e-01,
           -6.1465e-01, -5.5790e-01]]],
        [[[ 6.5206e-02, -1.1885e-02, -1.5570e-01,  ...,  6.9236e-01,
            4.0936e-01, -1.8678e-01],
          [-2.2743e-01, -4.2629e-02, -1.7983e-01,  ...,  8.0904e-01,
            5.7087e-01, -2.9687e-02],
          [-2.4100e-01, -1.1875e-01, -3.3719e-01,  ...,  8.9295e-01,
            5.8401e-01,  1.0092e-01],
          ...,
          [-3.9953e-01, -1.6382e-01,  2.7084e-02,  ...,  5.9574e-01,
            1.8480e-01, -1.4925e-01],
          [-2.4336e-01, -1.7456e-01, -1.6002e-01,  ...,  5.6896e-01,
            2.4843e-01, -1.8537e-01],
          [-6.2133e-02, -8.2874e-02, -2.4543e-01,  ...,  7.0208e-01,
            5.2294e-01,  6.6183e-02]]],
        [[[-6.7403e-01, -2.6630e-01, -4.4128e-02,  ...,  1.4260e-01,
           -1.3000e-02, -2.0189e-01],
          [-8.1474e-01, -1.6686e-01,  1.1451e-01,  ...,  9.8322e-02,
           -9.7446e-02, -1.6959e-01],
          [-5.3987e-01, -1.3903e-02,  1.2909e-01,  ...,  1.8243e-02,
            6.0749e-03, -2.7367e-01],
          ...,
          [-6.4641e-01, -2.4549e-01,  2.8330e-02,  ...,  1.1035e-01,
           -1.2201e-01, -3.0448e-01],
          [-4.8131e-01, -2.9567e-01, -9.8300e-02,  ...,  1.8826e-01,
            1.3387e-01, -1.6723e-01],
          [-5.4576e-01, -2.6812e-01, -1.1076e-01,  ..., -4.2816e-02,
            4.1901e-02, -1.9925e-01]]],
        ...,
        [[[-2.2706e-01,  7.0160e-02,  3.0176e-02,  ..., -3.2356e-01,
           -1.9338e-01, -6.5533e-01],
          [-2.8180e-01, -1.6892e-01,  2.7472e-02,  ..., -4.7925e-01,
           -1.7205e-01, -4.2595e-01],
          [-5.6282e-01, -5.3224e-01, -2.1291e-01,  ..., -4.9163e-01,
           -1.6405e-01, -5.1665e-01],
          ...,
          [-3.3458e-01, -1.1286e-01, -4.1568e-02,  ..., -7.8716e-01,
           -5.4021e-01, -3.4236e-01],
          [-1.5976e-01, -2.3086e-01, -2.3699e-01,  ..., -6.1977e-01,
           -6.1752e-01, -4.2102e-01],
          [-1.1201e-01, -3.1425e-01, -2.4325e-01,  ..., -4.7054e-01,
           -5.8956e-01, -4.4506e-01]]],
        [[[-6.0572e-01, -6.0207e-01, -6.5602e-01,  ..., -2.4796e-01,
           -2.5894e-01, -6.6603e-01],
          [-6.0307e-01, -7.5433e-01, -3.6950e-01,  ...,  6.6273e-02,
            1.0507e-02, -3.7337e-01],
          [-3.4316e-01, -5.6705e-02,  1.4378e-01,  ...,  2.2813e-01,
            2.1825e-01, -9.5367e-07],
          ...,
          [-6.3898e-01, -3.3801e-01, -4.2891e-01,  ..., -2.6593e-01,
           -2.0513e-01, -3.8974e-01],
          [-5.6631e-01, -3.1254e-01, -4.6095e-01,  ..., -8.0173e-02,
            1.9108e-02, -2.3729e-01],
          [-5.6586e-01, -5.0498e-01, -3.1038e-01,  ..., -1.0751e-01,
            3.5701e-02, -2.9648e-01]]],
        [[[-8.1540e-03, -2.7890e-03, -3.3153e-02,  ..., -1.9131e-01,
           -1.3389e-01, -2.0074e-02],
          [-3.2640e-02, -9.1287e-02, -1.2914e-01,  ..., -5.8336e-01,
           -1.9394e-01, -3.3933e-02],
          [ 7.0101e-03, -6.2744e-02,  1.1620e-01,  ..., -3.7838e-01,
           -5.2577e-01, -1.8569e-01],
          ...,
          [-1.7476e-01,  2.7210e-02, -1.5170e-01,  ..., -6.8987e-01,
           -5.6466e-01, -4.1163e-01],
          [-4.0960e-01,  3.0728e-02, -7.3529e-02,  ..., -5.1285e-01,
           -5.4339e-01, -3.7339e-01],
          [-1.2814e-01,  6.4700e-02, -2.7679e-01,  ..., -4.1571e-01,
           -4.4894e-01, -6.2839e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0332, -0.1748,  0.2156,  ..., -0.2988, -0.3950, -0.5156],
          [ 0.1677, -0.0257, -0.0141,  ..., -0.5423, -0.6386, -0.5783],
          [ 0.1049,  0.1726,  0.0311,  ..., -0.4555, -0.6484, -0.6369],
          ...,
          [-0.1899,  0.1061,  0.1168,  ..., -0.8713, -0.7467, -0.6585],
          [-0.2945, -0.2658,  0.0224,  ..., -0.7869, -0.9126, -0.8605],
          [-0.0542, -0.0432,  0.0204,  ..., -0.7013, -0.8570, -0.7372]]],
        [[[-0.6201, -0.3524, -0.0115,  ..., -0.5274, -0.7316, -0.9783],
          [-0.6532, -0.3464, -0.1286,  ..., -0.1821, -0.5755, -1.0000],
          [-0.5803, -0.2141, -0.0721,  ..., -0.0749, -0.3062, -0.8335],
          ...,
          [-0.6729, -0.2848, -0.0320,  ..., -0.3991, -0.5935, -0.8212],
          [-0.5929, -0.3145, -0.3088,  ..., -0.1814, -0.3973, -0.7885],
          [-0.7087, -0.1677,  0.0322,  ..., -0.0749, -0.4092, -0.8232]]],
        [[[-0.0960,  0.0114, -0.1987,  ...,  0.1099,  0.0029, -0.3981],
          [ 0.0454,  0.0895, -0.0121,  ...,  0.2760,  0.0765, -0.3829],
          [-0.1636, -0.4204, -0.3924,  ...,  0.1873,  0.0019, -0.4751],
          ...,
          [-0.6233, -0.4490, -0.4125,  ..., -0.4207, -0.4369, -0.2202],
          [-0.3304, -0.3676, -0.5144,  ..., -0.4020, -0.5316, -0.4289],
          [-0.4937, -0.2880, -0.1326,  ..., -0.5582, -0.3324, -0.4629]]],
        ...,
        [[[ 0.1447,  0.3108,  0.3932,  ..., -0.4841, -0.5957, -0.3079],
          [ 0.2154,  0.3569,  0.2994,  ..., -0.4059, -0.4119, -0.3877],
          [ 0.0701, -0.0193,  0.0193,  ..., -0.4185, -0.3989, -0.4733],
          ...,
          [-0.1333,  0.0054,  0.1840,  ..., -0.1919, -0.4400, -0.4844],
          [-0.0293, -0.2797, -0.0911,  ..., -0.4124, -0.4284, -0.4983],
          [-0.2157, -0.0903, -0.0266,  ..., -0.3578, -0.4174, -0.4754]]],
        [[[-0.4370, -0.0215, -0.1516,  ..., -0.2963, -0.0339, -0.0708],
          [-0.1963, -0.2195, -0.3023,  ..., -0.2699, -0.1645, -0.0634],
          [-0.2008, -0.1616, -0.0140,  ..., -0.2846, -0.0886,  0.0190],
          ...,
          [ 0.0555, -0.0989, -0.0266,  ..., -0.3523, -0.3853, -0.6241],
          [-0.1179, -0.2621, -0.3103,  ..., -0.5435, -0.3671, -0.5208],
          [-0.3960, -0.1947,  0.0418,  ..., -0.6777, -0.2732, -0.4934]]],
        [[[-0.2499,  0.1533,  0.5008,  ...,  0.0261, -0.2981, -0.7702],
          [ 0.0838,  0.5602,  0.5284,  ..., -0.1444, -0.3004, -0.8758],
          [ 0.2067,  0.7401,  0.7653,  ..., -0.0561, -0.2518, -0.5956],
          ...,
          [-0.2274,  0.2801,  0.5823,  ..., -0.2886, -0.4001, -0.9533],
          [-0.2728,  0.4455,  0.3601,  ..., -0.3572, -0.2522, -0.5775],
          [-0.3119,  0.3735,  0.6136,  ..., -0.1828, -0.2200, -0.5601]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5522, -0.4366,  0.2622,  ...,  0.0321,  0.1728, -0.2138],
          [-0.4423,  0.0678,  0.2337,  ...,  0.1976,  0.1608, -0.3136],
          [-0.2569,  0.1949,  0.2441,  ...,  0.0701, -0.0069, -0.4513],
          ...,
          [-0.1221,  0.3553,  0.0968,  ...,  0.3151,  0.1923, -0.0564],
          [-0.0425,  0.4256,  0.3724,  ...,  0.3418,  0.3174,  0.0050],
          [-0.1810,  0.2948,  0.3491,  ...,  0.2764,  0.3100, -0.1864]]],
        [[[-0.5991,  0.0013,  0.4180,  ..., -0.1040, -0.2407, -0.4949],
          [-0.7195, -0.4119,  0.1978,  ...,  0.0562, -0.3280, -0.5583],
          [-0.7258, -0.1764,  0.2089,  ...,  0.1296, -0.1815, -0.7069],
          ...,
          [-0.2891,  0.0652,  0.0527,  ..., -0.3410, -0.4740, -0.8523],
          [-0.2984,  0.0143, -0.0338,  ..., -0.1959, -0.5220, -1.0000],
          [-0.3315,  0.0194,  0.1502,  ..., -0.0799, -0.3443, -0.5340]]],
        [[[-0.4150, -0.1600, -0.2607,  ..., -0.4650, -0.2738,  0.3218],
          [-0.3745, -0.2407, -0.5834,  ..., -0.3524, -0.3718,  0.1769],
          [-0.1616, -0.1912, -0.3452,  ..., -0.2389, -0.3311,  0.0437],
          ...,
          [-0.4213, -0.4410, -0.1620,  ...,  0.0682,  0.0289,  0.0747],
          [-0.3237, -0.3003, -0.6513,  ...,  0.1591,  0.1591,  0.2120],
          [-0.5452, -0.3512, -0.5389,  ...,  0.1420,  0.0158,  0.3505]]],
        ...,
        [[[-0.1121, -0.0058,  0.1034,  ..., -0.4353, -0.2202,  0.0526],
          [-0.1396, -0.0933,  0.2650,  ..., -0.4747, -0.4859,  0.0078],
          [-0.0375,  0.0888,  0.1074,  ..., -0.0688, -0.1781, -0.0369],
          ...,
          [ 0.2353,  0.2963,  0.2061,  ..., -0.4801, -0.3237, -0.1353],
          [ 0.1690,  0.1551,  0.2853,  ..., -0.4217, -0.1668, -0.0555],
          [-0.1070,  0.1504,  0.1585,  ..., -0.3666, -0.1610, -0.0427]]],
        [[[-0.6168, -0.4495, -0.6725,  ..., -0.0231, -0.3642, -0.3786],
          [-0.7290, -0.5367, -0.8013,  ..., -0.0211, -0.3093, -0.3330],
          [-0.6580, -0.3960, -0.8652,  ...,  0.0770, -0.1151, -0.1782],
          ...,
          [-0.3255, -0.3762, -0.5782,  ..., -0.0593, -0.0813, -0.7699],
          [-0.3951, -0.3402, -0.4785,  ..., -0.0651, -0.1145, -0.8771],
          [-0.7072, -0.5045, -0.4610,  ..., -0.2359, -0.1261, -0.6275]]],
        [[[-0.3350,  0.2071,  0.2414,  ...,  0.2985,  0.2538, -0.2739],
          [-0.3996,  0.2335,  0.3419,  ...,  0.2795, -0.0072, -0.3962],
          [-0.5138,  0.1017,  0.3772,  ...,  0.2247, -0.1085, -0.4309],
          ...,
          [-0.5312, -0.0447,  0.1059,  ...,  0.2508, -0.1506, -0.1302],
          [-0.4408,  0.1908,  0.2975,  ...,  0.1027, -0.1166, -0.3173],
          [-0.4655,  0.2490,  0.3227,  ...,  0.0435, -0.0753, -0.2488]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5122, -0.1952,  0.2312,  ...,  0.0944, -0.3611, -0.4691],
          [-0.4077,  0.1542,  0.2925,  ..., -0.3134, -0.5223, -0.7762],
          [-0.4394,  0.1587,  0.3910,  ..., -0.7132, -0.7225, -0.8435],
          ...,
          [-0.6332,  0.1760,  0.2413,  ...,  0.1069, -0.2897, -0.4278],
          [-0.6879,  0.2428,  0.4696,  ...,  0.0694,  0.0220, -0.3255],
          [-0.7045,  0.3240,  0.4229,  ...,  0.0916,  0.0398, -0.5151]]],
        [[[-0.3424, -0.0220,  0.4536,  ..., -0.0173,  0.1907, -0.1311],
          [-0.4733, -0.1676,  0.1824,  ...,  0.1682,  0.2034,  0.1166],
          [-0.6908, -0.2937, -0.1837,  ...,  0.3312,  0.1316,  0.0507],
          ...,
          [-0.4596, -0.0328,  0.1873,  ...,  0.2676,  0.0099, -0.3078],
          [-0.1402,  0.2315,  0.1541,  ..., -0.1221, -0.0317, -0.3471],
          [-0.0491,  0.3728,  0.2934,  ..., -0.1560, -0.0244, -0.2770]]],
        [[[-0.4915, -0.3238, -0.3226,  ..., -0.3100, -0.2610, -0.6169],
          [-0.2434, -0.3020, -0.3658,  ..., -0.3795, -0.2465, -0.5002],
          [-0.3281, -0.3095, -0.3177,  ..., -0.5263, -0.5331, -0.7532],
          ...,
          [-0.0045,  0.1131,  0.1284,  ..., -0.7166, -0.5800, -0.6773],
          [-0.0282,  0.0447, -0.1293,  ..., -0.2691, -0.1200, -0.5042],
          [-0.2131,  0.1233,  0.0853,  ..., -0.2336, -0.0013, -0.2057]]],
        ...,
        [[[-0.2874, -0.1827,  0.5025,  ...,  0.2658,  0.0056, -0.2989],
          [-0.1523, -0.0865,  0.4749,  ...,  0.4695,  0.0751, -0.1640],
          [ 0.0366,  0.2951,  0.6171,  ...,  0.5413, -0.2025, -0.1892],
          ...,
          [-0.2505,  0.2315,  0.0904,  ..., -0.1038, -0.2109, -0.4184],
          [-0.2076,  0.4093,  0.6589,  ..., -0.1051, -0.1095, -0.4056],
          [-0.5268,  0.2704,  0.8234,  ..., -0.0050, -0.1291, -0.3219]]],
        [[[ 0.2924,  0.3225,  0.3002,  ...,  0.0403, -0.1022, -0.5638],
          [ 0.2145,  0.4765,  0.4691,  ..., -0.0043, -0.1781, -0.1541],
          [ 0.2554,  0.5547,  0.4722,  ..., -0.0014, -0.3443, -0.1486],
          ...,
          [ 0.2455,  0.3309, -0.0105,  ..., -0.3231, -0.3404, -0.4251],
          [ 0.2721,  0.4614,  0.2684,  ..., -0.0804, -0.3174, -0.2688],
          [ 0.3254,  0.5369,  0.3430,  ..., -0.0895, -0.1689, -0.1361]]],
        [[[-0.5885, -0.3554, -0.2271,  ..., -0.1438, -0.3610, -0.5576],
          [-0.6488, -0.4647, -0.1843,  ..., -0.4159, -0.3890, -0.8043],
          [-0.6220, -0.2697, -0.1815,  ..., -0.4258, -0.5265, -0.5084],
          ...,
          [-0.7217, -0.3009, -0.3732,  ..., -0.0722, -0.2828, -0.5212],
          [-0.6298, -0.0589,  0.1248,  ..., -0.0766, -0.1933, -0.5683],
          [-0.6113,  0.0751,  0.2187,  ..., -0.2353, -0.2259, -0.4879]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3479, -0.3485, -0.2557,  ...,  0.1794,  0.0061, -0.6116],
          [-0.5578, -0.4809, -0.3288,  ...,  0.1266, -0.0364, -0.7541],
          [-0.6428, -0.3432, -0.4028,  ...,  0.0845, -0.1020, -0.6425],
          ...,
          [-0.4992, -0.2785, -0.5223,  ...,  0.1022, -0.0022, -0.3993],
          [-0.5225, -0.4351, -0.3102,  ...,  0.0689, -0.0577, -0.4223],
          [-0.4444, -0.6087, -0.4342,  ...,  0.0543, -0.1671, -0.4760]]],
        [[[-0.6062, -0.2148, -0.1153,  ...,  0.2082, -0.0680, -0.6056],
          [-0.6893, -0.1950, -0.0553,  ...,  0.1530, -0.1448, -0.6294],
          [-0.5230,  0.0208,  0.0623,  ...,  0.0046, -0.0746, -0.7621],
          ...,
          [-0.4354,  0.1454,  0.2507,  ..., -0.2055, -0.4595, -0.7206],
          [-0.5338, -0.0186,  0.1229,  ...,  0.0078, -0.1524, -0.5807],
          [-0.8839, -0.3826, -0.1635,  ...,  0.1551, -0.1496, -0.6495]]],
        [[[-0.4004, -0.0373, -0.1844,  ..., -0.1243, -0.2133, -0.3429],
          [-0.2564, -0.1308, -0.0833,  ..., -0.3486, -0.1546, -0.3513],
          [-0.0760, -0.1978, -0.2043,  ..., -0.2500, -0.0911, -0.4819],
          ...,
          [-0.2608,  0.1385,  0.0053,  ..., -0.0492, -0.2722, -0.4943],
          [-0.3047,  0.1296, -0.0298,  ..., -0.0177, -0.3919, -1.0000],
          [-0.1457,  0.0161, -0.0762,  ..., -0.1825, -0.1742, -0.4783]]],
        ...,
        [[[-0.2251,  0.1049, -0.0660,  ..., -0.4509, -0.4809, -0.6266],
          [-0.2029, -0.0201, -0.1259,  ..., -0.4648, -0.5002, -0.7444],
          [-0.2067, -0.1942, -0.1285,  ..., -0.4805, -0.6207, -0.8252],
          ...,
          [-0.2174,  0.1016,  0.0170,  ..., -0.3435, -0.4041, -0.6359],
          [-0.4669,  0.1429,  0.1142,  ..., -0.4015, -0.3808, -0.7871],
          [-0.3988,  0.1956,  0.2756,  ..., -0.6667, -0.4839, -0.4133]]],
        [[[-0.3316,  0.2217,  0.0964,  ...,  0.0886,  0.2902, -0.2650],
          [-0.4195,  0.2870,  0.2686,  ...,  0.0960,  0.2828, -0.2675],
          [-0.4681,  0.2398, -0.0167,  ..., -0.0094,  0.2404, -0.2401],
          ...,
          [-0.1171,  0.2125,  0.4556,  ...,  0.2754,  0.3149, -0.0061],
          [-0.2919,  0.1714,  0.4461,  ...,  0.2495,  0.2023, -0.2133],
          [-0.3240,  0.3044,  0.3915,  ...,  0.1515,  0.1574, -0.4711]]],
        [[[-0.7707,  0.2005,  0.4290,  ...,  0.1396,  0.0196,  0.1957],
          [-0.6182,  0.0254,  0.1972,  ..., -0.0019, -0.1050,  0.1927],
          [-0.5906,  0.1068,  0.3611,  ..., -0.0501, -0.2599,  0.1830],
          ...,
          [-0.3220,  0.0228,  0.1618,  ..., -0.0614, -0.2877,  0.1808],
          [-0.3502, -0.1602,  0.0831,  ..., -0.0874, -0.1418,  0.2005],
          [-0.4585, -0.1872,  0.0010,  ..., -0.0665, -0.1423,  0.1915]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.6367e-01,  8.3293e-02,  2.9004e-01,  ...,  1.1999e-01,
           -1.2829e-01, -4.1519e-01],
          [-3.8114e-01,  5.9701e-02,  2.0552e-01,  ...,  1.9497e-01,
           -2.5509e-01, -2.7259e-01],
          [-6.7412e-01,  7.1220e-02,  4.3895e-01,  ...,  3.5411e-01,
           -1.6834e-01, -2.4548e-01],
          ...,
          [-5.2212e-01,  3.7708e-02,  2.7561e-01,  ...,  3.5777e-01,
            2.2310e-01, -1.9656e-01],
          [-5.8016e-01, -1.8828e-02,  3.6156e-01,  ...,  8.9932e-02,
            5.7878e-02, -1.5371e-01],
          [-7.3072e-01, -3.8756e-02,  2.3302e-01,  ...,  2.1745e-01,
            2.6768e-02, -1.0996e-01]]],
        [[[-2.5007e-01, -1.7751e-01, -3.7785e-01,  ..., -2.9445e-01,
            1.0450e-02, -1.2186e-01],
          [-4.2525e-01, -4.7826e-01, -5.4966e-01,  ..., -2.8152e-01,
           -2.5077e-01, -2.9558e-01],
          [-3.9791e-01, -2.7748e-01, -5.3851e-01,  ...,  1.7106e-02,
            1.3166e-02, -2.0405e-01],
          ...,
          [-5.2040e-01, -7.1710e-01, -2.9242e-01,  ..., -8.8819e-02,
           -2.7427e-01, -3.0467e-01],
          [-3.2459e-01, -2.5675e-01, -4.4747e-01,  ..., -4.9055e-02,
           -1.4925e-01, -4.3700e-01],
          [-2.8045e-01, -1.6932e-01, -5.3715e-01,  ..., -2.5617e-01,
           -3.3884e-01, -8.6406e-01]]],
        [[[-6.2558e-01,  6.9045e-02,  4.2574e-01,  ...,  1.8705e-01,
            1.7366e-01,  3.3010e-01],
          [-9.5735e-01, -2.1508e-01,  2.8602e-01,  ...,  1.5511e-01,
            2.9695e-03,  2.2119e-01],
          [-6.8626e-01, -2.4024e-01,  1.0311e-01,  ..., -1.0692e-01,
            1.0291e-01,  4.9123e-01],
          ...,
          [-5.6276e-01,  3.3079e-02,  1.4377e-01,  ...,  1.0863e-01,
            1.2868e-01,  3.2347e-01],
          [-6.3768e-01, -1.9342e-01,  1.0686e-01,  ..., -8.9880e-02,
           -1.2733e-01,  6.1034e-02],
          [-6.1859e-01,  8.9915e-02,  4.3873e-01,  ..., -9.5120e-02,
            1.8370e-02,  2.7167e-01]]],
        ...,
        [[[-4.2173e-01, -3.3097e-01, -3.9544e-01,  ..., -4.5679e-01,
           -3.7346e-01, -4.3059e-01],
          [-2.5512e-01, -3.1001e-01, -4.6176e-01,  ..., -3.5816e-01,
           -4.4760e-01, -4.9492e-01],
          [-3.1090e-01, -2.1425e-01, -2.2111e-01,  ..., -3.9155e-01,
           -4.5805e-01, -6.5157e-01],
          ...,
          [-2.9160e-01, -3.2561e-01, -3.0093e-01,  ..., -1.5919e-01,
           -1.5018e-01, -5.2682e-01],
          [-3.2754e-01, -3.9277e-01, -4.2749e-01,  ..., -1.0113e-01,
            1.7820e-02, -3.7006e-01],
          [-4.2636e-01, -3.8485e-01, -8.5986e-01,  ..., -1.7329e-01,
            7.9760e-02,  2.1315e-02]]],
        [[[-8.8211e-02,  2.3574e-01,  4.6531e-02,  ..., -2.8196e-01,
           -7.5904e-01, -4.8343e-01],
          [-6.1497e-02, -1.2368e-01,  1.4163e-01,  ..., -2.0729e-01,
           -3.8605e-01, -3.0331e-01],
          [ 1.0871e-01, -5.3338e-02,  9.3736e-02,  ..., -4.0265e-01,
           -1.5637e-01, -2.6278e-01],
          ...,
          [ 1.7186e-01,  3.3493e-01,  1.8558e-01,  ..., -4.9111e-02,
           -1.4768e-01, -5.7793e-01],
          [-6.5821e-02,  3.4331e-02,  3.7726e-01,  ..., -1.2819e-01,
           -5.0542e-01, -3.6793e-01],
          [ 2.3792e-01,  2.9636e-01,  3.9393e-01,  ..., -3.0725e-01,
           -5.1904e-01, -1.6446e-01]]],
        [[[-3.7078e-01,  1.4469e-02,  2.6667e-01,  ...,  2.7634e-01,
            5.5202e-02, -4.1746e-01],
          [-5.6588e-01, -1.5896e-01,  2.7756e-01,  ...,  2.2385e-01,
            5.7645e-02, -4.4036e-01],
          [-7.7108e-01, -3.1403e-01,  2.1440e-01,  ...,  3.4559e-02,
            1.5295e-02, -4.7786e-01],
          ...,
          [-5.7572e-01, -4.3543e-01,  2.2565e-03,  ...,  1.9771e-02,
           -1.2792e-02, -3.7497e-01],
          [-4.0741e-01, -1.9328e-01,  2.3302e-01,  ..., -4.0925e-02,
           -2.9667e-01, -5.3218e-01],
          [-2.5340e-01, -9.2870e-04,  3.1544e-01,  ...,  7.2841e-02,
           -3.5167e-01, -6.3447e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3185,  0.3142,  0.1832,  ...,  0.2517, -0.0921, -0.1814],
          [-0.2278,  0.0418,  0.0724,  ...,  0.0259,  0.0778, -0.2409],
          [-0.0518,  0.2177,  0.1774,  ...,  0.1998,  0.0273, -0.4748],
          ...,
          [-0.6834, -0.4061, -0.2118,  ..., -0.2971, -0.0432, -0.1266],
          [-0.3105, -0.1756, -0.2109,  ..., -0.3032, -0.1208, -0.0882],
          [-0.1330,  0.0443, -0.3953,  ..., -0.1880, -0.2642, -0.2845]]],
        [[[-0.4836, -0.2866, -0.3320,  ..., -0.8023, -0.7083, -0.7874],
          [-0.6077, -0.3606, -0.3222,  ..., -0.7951, -0.6662, -0.6116],
          [-0.6623, -0.4071, -0.5014,  ..., -0.6846, -0.6903, -0.6722],
          ...,
          [-0.4783, -0.1910, -0.4540,  ..., -0.6236, -0.5433, -0.4569],
          [-0.4690, -0.2973, -0.5402,  ..., -0.7409, -0.5340, -0.4781],
          [-0.4019, -0.3864, -0.4423,  ..., -0.7286, -0.5725, -0.5782]]],
        [[[-0.8813, -0.3633, -0.1526,  ..., -0.2577, -0.4475, -0.6673],
          [-0.7230, -0.3895, -0.1963,  ..., -0.2431, -0.6159, -0.5897],
          [-0.5842, -0.1282,  0.0410,  ..., -0.3070, -0.8573, -1.0000],
          ...,
          [-0.6651, -0.3669,  0.0571,  ..., -0.4869, -0.4865, -0.6752],
          [-0.6181, -0.3179,  0.0405,  ..., -0.5620, -0.5404, -0.6328],
          [-0.6849, -0.2895, -0.0591,  ..., -0.6471, -0.5110, -0.6212]]],
        ...,
        [[[-0.4605, -0.4108, -0.1842,  ...,  0.7082,  0.4694,  0.2532],
          [-0.7001, -0.3293, -0.2977,  ...,  0.7282,  0.5102,  0.2746],
          [-0.2432, -0.3848, -0.2141,  ...,  0.7548,  0.2720, -0.0067],
          ...,
          [-0.4741, -0.3538, -0.4331,  ...,  0.8072,  0.3569, -0.1228],
          [-0.3137, -0.3193, -0.4996,  ...,  0.7942,  0.3355,  0.0328],
          [-0.3808, -0.4676, -0.4150,  ...,  0.6988,  0.3944,  0.0793]]],
        [[[ 0.5051,  0.4150,  0.1704,  ..., -0.3902, -0.6002, -0.4838],
          [ 0.0969,  0.5768,  0.4816,  ..., -0.5649, -0.5609, -0.5300],
          [ 0.2755,  0.4932,  0.6972,  ..., -1.0000, -0.5664, -0.2729],
          ...,
          [ 0.3257,  0.0771,  0.2288,  ..., -0.5438, -0.8106, -0.4892],
          [ 0.2896,  0.3872,  0.2286,  ..., -0.5286, -0.9049, -0.4790],
          [ 0.2872,  0.3610,  0.4191,  ..., -0.4353, -0.5669, -0.2576]]],
        [[[ 0.0688,  0.1457,  0.2764,  ..., -0.4316, -0.4656, -0.2753],
          [-0.2284, -0.0784, -0.1684,  ..., -0.7235, -0.2475, -0.1051],
          [-0.2164,  0.1190, -0.1165,  ..., -0.1580, -0.0625,  0.0204],
          ...,
          [-0.4536,  0.0044, -0.0776,  ..., -0.4340, -0.3443,  0.2751],
          [-0.0565,  0.4383,  0.2737,  ..., -0.5004, -0.4329,  0.1616],
          [ 0.4896,  0.5647,  0.4740,  ..., -0.2451, -0.0836,  0.0656]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-4.1492e-01, -4.3773e-01, -1.6029e-01,  ..., -3.0888e-01,
           -5.5013e-01, -2.9010e-01],
          [-5.4597e-01, -4.5812e-01, -1.3157e-01,  ..., -3.7311e-01,
           -4.7498e-01, -3.8451e-01],
          [-2.8887e-01, -2.8969e-01,  1.6529e-01,  ..., -5.6968e-01,
           -1.7987e-01, -2.3729e-01],
          ...,
          [-1.3821e-01, -1.2588e-01, -1.3466e-02,  ..., -4.9483e-02,
           -3.6213e-01, -4.6372e-01],
          [-4.9673e-03, -3.8810e-01, -1.7602e-01,  ..., -2.7434e-01,
           -5.1181e-01, -3.3110e-01],
          [-3.8290e-02,  4.2709e-02,  1.0049e-01,  ..., -1.5064e-01,
           -1.4872e-01, -1.3476e-01]]],
        [[[-5.2391e-01,  8.0614e-03,  2.8786e-01,  ..., -3.6459e-01,
           -4.7991e-01, -5.1182e-01],
          [-4.1576e-01, -3.9647e-02,  8.9244e-02,  ..., -3.5866e-01,
           -5.1964e-01, -6.4129e-01],
          [-8.7106e-02, -3.2601e-01, -2.3996e-02,  ..., -3.1774e-01,
           -6.0192e-01, -8.7205e-01],
          ...,
          [-6.5027e-01, -1.0506e-01, -5.5229e-02,  ..., -4.6430e-01,
           -2.8229e-01, -3.1656e-01],
          [-3.7939e-01, -1.9375e-02, -2.1146e-01,  ..., -2.6425e-01,
           -3.8872e-01, -2.6242e-01],
          [-4.7422e-01, -3.4900e-02, -2.4549e-01,  ..., -2.1697e-01,
           -3.1024e-01, -3.3370e-01]]],
        [[[ 2.6196e-01,  3.1882e-01,  2.3670e-01,  ..., -2.6035e-01,
           -4.6082e-02, -5.9878e-01],
          [ 3.2053e-02,  2.1860e-01,  2.4356e-01,  ...,  6.2472e-02,
           -1.0364e-01, -8.2619e-01],
          [-1.6079e-01,  6.7116e-02,  2.8246e-01,  ...,  1.1263e-01,
           -1.9200e-01, -8.3258e-01],
          ...,
          [-6.7936e-02, -6.2728e-02, -2.1753e-01,  ..., -5.1634e-01,
           -3.6312e-01, -6.4056e-01],
          [-3.4062e-01, -4.3155e-01,  9.7814e-03,  ..., -6.9330e-01,
           -3.5578e-01, -5.6385e-01],
          [-6.5138e-03, -1.2495e-01,  6.1764e-02,  ..., -1.2927e-01,
           -2.0292e-01, -9.9633e-01]]],
        ...,
        [[[-2.5513e-01, -1.1645e-02, -2.3963e-02,  ...,  6.1258e-02,
           -2.0344e-01, -1.7489e-01],
          [-3.1757e-01, -3.9487e-01, -4.8632e-01,  ...,  5.2238e-04,
           -1.1721e-01, -6.4385e-02],
          [-3.2689e-01, -2.7578e-01, -2.3980e-01,  ..., -2.8819e-01,
            1.0633e-02,  1.1887e-01],
          ...,
          [-1.4616e-01,  2.4764e-01,  3.5272e-01,  ...,  1.9398e-01,
            1.5916e-02, -5.5726e-01],
          [ 1.1080e-01,  1.6920e-01,  1.1810e-01,  ...,  1.5859e-01,
           -9.0248e-02, -4.5296e-01],
          [-2.1109e-01, -2.9216e-01, -3.7380e-02,  ...,  1.9359e-01,
            8.1754e-02, -4.3634e-01]]],
        [[[-3.1184e-01,  8.4097e-02,  2.0411e-01,  ..., -3.1545e-01,
           -3.7429e-02,  2.1618e-01],
          [-4.4301e-01, -4.3593e-02,  1.0143e-01,  ..., -5.9015e-01,
           -3.3985e-01,  1.2590e-01],
          [-3.5181e-01, -2.2383e-01, -3.6279e-01,  ..., -5.8199e-01,
           -4.2255e-01,  3.1487e-02],
          ...,
          [-2.8786e-01, -3.6671e-01, -1.4296e-01,  ..., -8.2007e-01,
           -3.1306e-01,  1.0495e-01],
          [ 6.9049e-02, -2.4280e-01, -6.4499e-02,  ..., -5.9272e-01,
           -2.9910e-01,  1.8742e-01],
          [-2.4318e-02, -4.2133e-02, -6.0641e-02,  ..., -7.3891e-01,
           -8.6085e-02,  2.5070e-01]]],
        [[[-5.6997e-01, -2.5080e-01, -2.5133e-02,  ...,  1.5389e-01,
            2.4673e-01,  1.4605e-01],
          [-7.2530e-01, -5.2159e-01, -2.5357e-01,  ...,  2.1786e-01,
            6.1393e-02, -5.2908e-02],
          [-5.0211e-01, -2.6144e-01, -2.4829e-01,  ...,  1.5265e-01,
            3.7527e-02, -2.1344e-02],
          ...,
          [-7.8853e-01, -1.4701e-01,  2.6458e-01,  ...,  1.3116e-01,
            1.6534e-01, -3.8270e-02],
          [-7.0975e-01, -2.2227e-01,  2.1792e-01,  ...,  2.1296e-01,
            1.8213e-01, -8.4797e-02],
          [-6.1092e-01, -4.7115e-01,  2.8262e-02,  ...,  2.4504e-01,
            1.4625e-01, -1.0359e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4587, -0.2212, -0.4690,  ...,  0.3842,  0.1423,  0.1427],
          [-0.4088, -0.1336, -0.4091,  ...,  0.3864,  0.3213,  0.4637],
          [-0.4204, -0.2224, -0.6211,  ..., -0.0032,  0.3996,  0.5224],
          ...,
          [-0.4221, -0.0413, -0.1155,  ..., -0.1281,  0.3121, -0.0200],
          [-0.3634, -0.4429, -0.1705,  ..., -0.0733,  0.4359,  0.0761],
          [-0.2225, -0.6568, -0.5768,  ..., -0.2012,  0.3265, -0.0137]]],
        [[[ 0.4414,  0.5498,  0.4707,  ..., -0.9639, -0.3521, -0.0542],
          [ 0.3007,  0.4711,  0.4500,  ..., -0.8349, -0.5708, -0.0783],
          [ 0.3091,  0.3191,  0.3879,  ..., -0.4517, -0.2423, -0.1051],
          ...,
          [ 0.2097,  0.4974,  0.1667,  ..., -0.3179, -0.0885, -0.1386],
          [ 0.3302,  0.3653, -0.0750,  ..., -0.3554, -0.1099, -0.0654],
          [ 0.1688,  0.2237, -0.3857,  ..., -0.4599, -0.1130,  0.0507]]],
        [[[-0.4462,  0.1396,  0.0807,  ..., -0.0759, -0.1851, -0.4075],
          [-0.5218,  0.1030,  0.2075,  ..., -0.1521, -0.2995, -0.4184],
          [-0.6348, -0.1119,  0.0386,  ..., -0.0242, -0.2125, -0.8013],
          ...,
          [-0.3813, -0.1289, -0.1033,  ..., -0.1033, -0.1978, -0.4640],
          [-0.5181, -0.1106, -0.0763,  ..., -0.0676, -0.0660, -0.4595],
          [-0.5741,  0.0758,  0.2305,  ..., -0.2384, -0.0181, -0.4542]]],
        ...,
        [[[ 0.1838, -0.0920, -0.4829,  ..., -0.7146, -0.7927, -0.5283],
          [-0.0190,  0.2016, -0.2189,  ..., -0.4306, -0.7296, -0.3346],
          [ 0.0532,  0.2187, -0.4939,  ..., -0.4701, -0.7325, -0.3208],
          ...,
          [-0.5839, -0.2290, -0.1957,  ..., -0.4793, -0.4680, -0.1123],
          [-0.2704, -0.2635, -0.0732,  ..., -0.2583, -0.5966, -0.1772],
          [-0.2702, -0.2423, -0.0519,  ..., -0.3698, -0.6019, -0.1994]]],
        [[[-0.1563,  0.2275,  0.2845,  ..., -0.3857, -0.1039,  0.1094],
          [-0.2058,  0.1758,  0.0945,  ..., -0.2996, -0.1559,  0.2085],
          [-0.0568,  0.0243, -0.0064,  ..., -0.0818, -0.2023,  0.2370],
          ...,
          [-0.0529,  0.1581, -0.3182,  ..., -0.5636, -0.4805, -0.2008],
          [-0.1418,  0.1102, -0.1855,  ..., -0.8603, -0.5137, -0.2547],
          [-0.2788, -0.0969,  0.0261,  ..., -0.9003, -0.6237, -0.4818]]],
        [[[-0.4261,  0.2863,  0.4399,  ..., -0.2964, -0.1902, -0.3279],
          [-0.4999,  0.1992,  0.1960,  ...,  0.0239, -0.1165, -0.3795],
          [-0.4685,  0.2200,  0.2982,  ..., -0.0039, -0.2520, -0.7002],
          ...,
          [-0.4819, -0.3000,  0.2956,  ...,  0.0476, -0.1931, -0.3339],
          [-0.3329, -0.1115,  0.1912,  ..., -0.0572, -0.0340, -0.5148],
          [-0.3060, -0.0687,  0.2034,  ...,  0.0871,  0.0597, -0.4307]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 1.2096e-01,  4.6915e-01,  5.4146e-01,  ..., -5.8693e-01,
           -5.2577e-01, -5.2008e-01],
          [-1.6885e-02,  3.5389e-01,  3.1523e-01,  ..., -8.2781e-01,
           -6.0112e-01, -7.0718e-01],
          [-5.8239e-02,  2.2871e-01,  2.4246e-01,  ..., -5.5333e-01,
           -5.4864e-01, -5.4298e-01],
          ...,
          [-1.4157e-01, -4.5955e-04, -2.6034e-01,  ..., -3.5775e-01,
           -4.2063e-01, -2.7854e-01],
          [ 2.3623e-02, -6.3585e-02, -6.2501e-03,  ..., -3.7098e-01,
           -5.2492e-01, -3.2468e-01],
          [-8.1418e-02,  1.0403e-01,  1.3483e-01,  ..., -3.2214e-01,
           -5.7645e-01, -3.4841e-01]]],
        [[[ 8.1513e-03,  2.6915e-01,  2.7833e-02,  ..., -3.5961e-01,
           -5.3617e-01, -8.2153e-01],
          [ 7.7060e-02,  2.0429e-01,  6.3387e-02,  ..., -2.9754e-01,
           -5.5689e-01, -1.0000e+00],
          [-2.0556e-01, -5.7229e-02,  2.3353e-02,  ..., -2.9080e-01,
           -4.8363e-01, -6.5498e-01],
          ...,
          [ 3.4316e-02, -1.0052e-02,  1.1687e-03,  ..., -8.2442e-02,
           -2.4513e-01, -4.5673e-01],
          [-3.3895e-01, -1.0396e-01,  2.0090e-01,  ..., -2.8542e-01,
           -1.7107e-01, -6.5020e-01],
          [ 3.6285e-02,  1.9863e-01,  3.8592e-01,  ..., -2.5335e-01,
           -1.8063e-01, -3.7735e-01]]],
        [[[-1.8221e-01, -3.4540e-01, -7.4456e-02,  ...,  5.3839e-01,
            2.9912e-01,  2.5440e-01],
          [ 1.3028e-03, -1.9556e-01, -2.4569e-01,  ...,  2.3303e-01,
            3.3237e-01,  2.7288e-01],
          [ 2.1979e-01,  7.6286e-02,  2.4400e-01,  ...,  2.4573e-02,
            2.7448e-01,  8.4213e-03],
          ...,
          [-1.1803e-01,  3.7607e-02,  3.7248e-02,  ...,  7.4547e-01,
            2.9548e-01,  2.2197e-01],
          [ 2.5931e-01,  3.5687e-01, -4.5532e-02,  ...,  8.5064e-01,
            4.7553e-01,  1.9892e-01],
          [ 1.2394e-01,  1.9114e-01, -2.5221e-02,  ...,  8.8236e-01,
            5.2272e-01,  9.7674e-02]]],
        ...,
        [[[-3.4658e-01, -4.2267e-03, -1.4915e-02,  ..., -3.2905e-01,
           -2.9128e-01, -4.8655e-01],
          [-3.3108e-01, -9.1334e-02, -1.8870e-01,  ..., -1.5211e-01,
           -3.0075e-01, -5.3980e-01],
          [-3.4566e-01,  1.7545e-02,  4.1136e-02,  ..., -3.8649e-01,
           -4.8302e-01, -5.3195e-01],
          ...,
          [-5.0388e-01, -1.6641e-01,  1.3274e-01,  ..., -3.3247e-01,
           -3.0435e-01, -4.8408e-01],
          [-3.3240e-01, -1.6917e-01,  3.5499e-02,  ..., -3.3195e-01,
           -4.0212e-01, -6.1597e-01],
          [-2.8851e-01, -1.8257e-01, -1.7783e-01,  ..., -2.5460e-01,
           -3.9302e-01, -5.6271e-01]]],
        [[[-9.1111e-02, -1.6030e-01,  1.4573e-02,  ..., -5.1625e-01,
           -5.4184e-01, -5.6878e-01],
          [-5.2807e-02, -1.3035e-01,  7.8726e-03,  ..., -3.0926e-01,
           -5.2144e-01, -5.9222e-01],
          [ 2.7259e-02,  7.5209e-02, -1.2791e-01,  ..., -3.7151e-01,
           -4.8381e-01, -6.6887e-01],
          ...,
          [-2.1150e-01, -2.7698e-01, -5.3951e-02,  ..., -4.3278e-01,
           -3.8176e-01, -5.9812e-01],
          [-2.8014e-01, -7.8307e-02, -3.1901e-02,  ..., -4.3912e-01,
           -3.9773e-01, -5.3287e-01],
          [-4.5291e-01, -4.2173e-02, -1.2350e-02,  ..., -7.3892e-01,
           -5.5888e-01, -7.4782e-01]]],
        [[[-6.8840e-01, -2.9601e-01, -9.6035e-02,  ...,  4.6067e-01,
            3.5019e-01,  3.2796e-01],
          [-7.3914e-01, -4.1696e-01,  3.4339e-03,  ...,  5.9274e-02,
            2.1525e-01,  3.6361e-01],
          [-5.5198e-01, -2.9689e-01,  1.4551e-01,  ...,  2.3530e-01,
            2.1351e-01,  3.8433e-01],
          ...,
          [-5.6491e-01, -1.0165e-01, -1.8889e-01,  ...,  5.9396e-01,
            3.7228e-01,  2.1808e-01],
          [-4.0354e-01, -7.6925e-02, -7.5780e-02,  ...,  4.7196e-01,
            3.8519e-01,  1.8798e-01],
          [-5.4112e-01, -2.2837e-01, -3.8674e-02,  ...,  1.4487e-01,
            3.4909e-01,  3.5048e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.3394e-01,  1.6812e-01,  3.1961e-01,  ...,  2.7039e-02,
            1.9364e-02, -4.5543e-01],
          [-4.6865e-01,  1.3983e-01,  3.1114e-01,  ..., -1.9282e-01,
           -8.7068e-02, -3.5595e-01],
          [-2.9110e-01,  2.1209e-01,  1.7356e-01,  ..., -3.1229e-02,
           -1.0280e-01, -4.2694e-01],
          ...,
          [ 2.9032e-01,  7.1450e-01,  9.1020e-01,  ...,  1.1992e-02,
           -3.3951e-01, -5.6100e-01],
          [ 2.1896e-01,  6.5480e-01,  8.8454e-01,  ..., -8.4622e-02,
           -3.6578e-01, -6.7442e-01],
          [ 7.3521e-02,  2.6052e-01,  6.3150e-01,  ...,  4.3328e-02,
           -2.5629e-01, -6.0363e-01]]],
        [[[-2.8792e-01, -2.0669e-01, -4.9216e-01,  ..., -2.6055e-01,
           -3.0116e-01, -1.8111e-01],
          [-2.2350e-01, -3.2612e-01, -5.0876e-01,  ..., -4.6539e-01,
           -5.0030e-01, -2.6423e-01],
          [-2.5191e-01, -3.6198e-01, -4.9930e-01,  ..., -6.0143e-01,
           -4.7655e-01, -3.1437e-01],
          ...,
          [ 3.5350e-02,  3.5739e-01,  5.6477e-01,  ..., -3.5409e-01,
           -5.1629e-01, -6.1901e-01],
          [ 2.3476e-01,  1.6649e-01,  4.5920e-01,  ..., -4.1451e-01,
           -5.0744e-01, -6.2879e-01],
          [ 5.0839e-01,  5.1757e-01,  5.5045e-01,  ..., -5.1161e-01,
           -7.4662e-01, -6.9574e-01]]],
        [[[-3.8362e-01, -3.4548e-01, -3.9813e-01,  ...,  3.5839e-01,
            2.4118e-01, -2.1105e-01],
          [-4.0268e-01, -2.1686e-01, -4.1995e-01,  ...,  1.3449e-01,
           -8.0281e-02, -4.0525e-02],
          [-4.1805e-01, -2.9915e-01, -6.3865e-01,  ..., -1.5665e-01,
           -4.9389e-01, -1.4855e-01],
          ...,
          [-9.1672e-01, -5.7408e-01, -3.1301e-01,  ..., -1.0190e-01,
           -8.5566e-02, -5.0198e-01],
          [-6.6562e-01, -4.8369e-01, -2.8339e-01,  ..., -2.4675e-01,
           -3.3394e-01, -7.8582e-01],
          [-3.7815e-01, -2.4168e-01, -2.3490e-01,  ..., -1.8005e-01,
           -1.5630e-01, -6.7607e-01]]],
        ...,
        [[[-5.9097e-01,  4.6366e-02,  2.5807e-01,  ...,  3.6334e-02,
           -1.3394e-02, -2.5793e-01],
          [-5.7214e-01,  6.7178e-02,  2.8360e-01,  ...,  1.8760e-01,
            8.7649e-02, -2.2776e-01],
          [-7.3609e-01, -1.0377e-01,  1.1813e-01,  ...,  1.7382e-01,
           -1.3751e-01, -5.9009e-01],
          ...,
          [-5.3772e-01,  6.2765e-02,  1.7488e-01,  ...,  1.5328e-02,
           -2.2324e-01, -6.4253e-01],
          [-8.1766e-01,  9.0671e-02,  1.5920e-01,  ..., -1.8530e-01,
           -4.7228e-01, -7.0753e-01],
          [-5.3154e-01,  1.5603e-01,  2.0563e-01,  ..., -3.5882e-01,
           -5.0022e-01, -5.9315e-01]]],
        [[[-4.1382e-01, -3.7167e-01, -1.7381e-01,  ...,  3.3644e-01,
            2.4614e-01, -2.4286e-01],
          [-3.9414e-01, -1.2650e-01, -1.8066e-04,  ...,  2.8394e-01,
            2.5106e-01, -1.6176e-01],
          [-4.7473e-01, -8.5264e-02,  2.1798e-01,  ...,  2.1081e-01,
            4.1414e-02, -4.7195e-01],
          ...,
          [-8.0677e-01, -3.3514e-01, -1.5411e-01,  ...,  1.3632e-01,
            5.5827e-02, -2.2094e-01],
          [-1.0000e+00, -3.6283e-01, -1.2014e-01,  ...,  1.7095e-01,
           -1.9980e-02, -3.1982e-01],
          [-6.2193e-01, -9.8440e-02,  4.5942e-02,  ...,  1.3571e-01,
           -7.0129e-02, -3.1057e-01]]],
        [[[-1.5708e-01,  3.6169e-02,  2.9386e-01,  ...,  3.1920e-02,
            2.0166e-01, -2.0967e-01],
          [-1.0947e-01,  1.5435e-01, -2.3017e-02,  ...,  8.9593e-02,
           -6.5705e-02, -1.0138e-01],
          [-1.1920e-01,  4.0851e-02, -5.4628e-02,  ...,  9.6007e-02,
            1.5349e-01, -1.0093e-01],
          ...,
          [ 3.8416e-02, -6.6855e-02, -1.0835e-01,  ...,  6.6839e-02,
           -2.8655e-01, -2.2149e-01],
          [-4.7575e-01, -2.5758e-01, -1.4853e-01,  ...,  2.6161e-01,
            9.2652e-03, -2.7543e-01],
          [-6.0267e-02, -7.1786e-02, -1.6989e-01,  ...,  2.2388e-01,
            2.9855e-01,  1.7352e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.1386,  0.2085, -0.3211,  ..., -0.3081, -0.2761,  0.0243],
          [ 0.2129,  0.1281, -0.3342,  ..., -0.2553, -0.2903, -0.1460],
          [-0.0373, -0.0858, -0.0045,  ..., -0.0704, -0.2366, -0.4294],
          ...,
          [-0.1425, -0.2520, -0.2403,  ..., -0.4925, -0.6240, -0.5784],
          [ 0.0130,  0.0123, -0.0950,  ..., -0.4965, -0.8144, -0.9163],
          [-0.2227,  0.1729,  0.0088,  ..., -0.3392, -0.4247, -0.8270]]],
        [[[-0.0411,  0.2870,  0.2949,  ..., -0.0955, -0.1333, -0.4664],
          [-0.1806,  0.3641,  0.5372,  ..., -0.0225, -0.0735, -0.5227],
          [ 0.0210,  0.5861,  0.6671,  ...,  0.0562, -0.1321, -0.5266],
          ...,
          [-0.4267,  0.2879,  0.7054,  ..., -0.2373, -0.0837, -0.4998],
          [-0.1271,  0.4784,  0.4534,  ..., -0.2867, -0.2876, -0.7062],
          [-0.0721,  0.5887,  0.6251,  ..., -0.0899, -0.2516, -0.6470]]],
        [[[-0.2207, -0.2038, -0.3763,  ...,  0.0462,  0.0241, -0.1731],
          [-0.4279, -0.4200, -0.2380,  ..., -0.0606,  0.0713, -0.0508],
          [-0.4550, -0.3982, -0.4238,  ..., -0.0744, -0.0022, -0.1289],
          ...,
          [-0.3276, -0.5420, -0.5284,  ...,  0.2225, -0.0829, -0.1504],
          [-0.3677, -0.5387, -0.5463,  ...,  0.1486, -0.0773, -0.1837],
          [-0.5447, -0.4080, -0.5691,  ...,  0.1653, -0.0706, -0.2174]]],
        ...,
        [[[-0.2774, -0.4363, -0.3368,  ..., -0.3003, -0.2455, -0.4120],
          [-0.3888, -0.3668,  0.0091,  ..., -0.2763, -0.2857, -0.3793],
          [-0.5856, -0.1964,  0.0036,  ..., -0.2946, -0.4243, -0.5517],
          ...,
          [-0.2490, -0.6414, -0.3224,  ...,  0.2392,  0.1107,  0.1518],
          [-0.4509, -0.8792, -0.1600,  ...,  0.2699,  0.1566, -0.1273],
          [-0.5434, -0.4776,  0.0288,  ...,  0.1512, -0.1254, -0.5489]]],
        [[[ 0.0255, -0.1645, -0.0354,  ...,  0.9081,  0.6368, -0.1259],
          [ 0.0890, -0.0940, -0.0591,  ...,  0.8947,  0.5607, -0.3028],
          [-0.0757,  0.0516,  0.1241,  ...,  0.8494,  0.5715, -0.3113],
          ...,
          [-0.3225, -0.3626, -0.4668,  ...,  1.0000,  0.5317, -0.3335],
          [-0.5425, -0.2200,  0.0496,  ...,  0.9566,  0.6034, -0.2052],
          [-0.8436, -0.3621,  0.1744,  ...,  0.9671,  0.5854, -0.1875]]],
        [[[-0.9358, -0.2302,  0.5446,  ...,  0.0473,  0.0865,  0.2698],
          [-1.0000, -0.2306,  0.5720,  ...,  0.1101,  0.2896,  0.3526],
          [-0.7285, -0.0279,  0.4079,  ...,  0.0462,  0.1412,  0.4806],
          ...,
          [-0.0035,  0.2836,  0.0384,  ...,  0.0375,  0.0347,  0.5083],
          [-0.1764,  0.1974,  0.2396,  ...,  0.1789,  0.1724,  0.4306],
          [-0.3427,  0.0929,  0.3280,  ..., -0.1337, -0.2455,  0.0986]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5795, -0.0520,  0.1681,  ..., -0.0228, -0.0911, -0.1895],
          [-0.4135, -0.2129, -0.0708,  ..., -0.0558, -0.1587, -0.3402],
          [-0.3479, -0.1851,  0.0413,  ..., -0.1784,  0.0178, -0.2754],
          ...,
          [-0.1009,  0.3353,  0.5591,  ..., -0.4263, -0.1859, -0.5359],
          [-0.2946, -0.0803,  0.2908,  ..., -0.1011, -0.1272, -0.3570],
          [-0.4874,  0.0189,  0.2631,  ...,  0.1129, -0.1090, -0.1481]]],
        [[[-0.5762, -0.0219,  0.4654,  ..., -0.0512, -0.0356, -0.5355],
          [-0.6125,  0.1384,  0.4777,  ..., -0.0539, -0.0501, -0.2928],
          [-0.5791,  0.0903,  0.1698,  ..., -0.0562, -0.1804, -0.3597],
          ...,
          [-0.8535, -0.2068,  0.0264,  ...,  0.0562, -0.0092, -0.4781],
          [-0.8674, -0.1779, -0.1420,  ..., -0.0403, -0.1132, -0.3139],
          [-0.7390, -0.0570,  0.0727,  ..., -0.1349, -0.3659, -0.2803]]],
        [[[-0.3292, -0.3242, -0.5366,  ..., -0.2529, -0.4180, -0.3552],
          [-0.2762, -0.2582, -0.4938,  ..., -0.3273, -0.4303, -0.3065],
          [-0.2498, -0.2629, -0.1342,  ..., -0.7177, -0.4463, -0.1683],
          ...,
          [-0.2039, -0.0212, -0.1252,  ..., -0.3871, -0.5278, -0.3146],
          [-0.4231, -0.1152, -0.1424,  ..., -0.4684, -0.5280, -0.3300],
          [-0.4890, -0.1426, -0.3670,  ..., -0.3533, -0.3014, -0.2490]]],
        ...,
        [[[-0.4126,  0.1895,  0.3692,  ...,  0.1708,  0.1863,  0.1177],
          [-0.4852, -0.0274,  0.0314,  ...,  0.3298, -0.1364, -0.0819],
          [-0.5049, -0.3274,  0.0233,  ...,  0.3178, -0.0714,  0.2155],
          ...,
          [-0.6849,  0.0063,  0.3918,  ...,  0.0863,  0.0909,  0.3712],
          [-0.5693, -0.1101,  0.3349,  ..., -0.0078,  0.0615,  0.3053],
          [-0.5020,  0.0097,  0.3645,  ...,  0.2402,  0.0166,  0.0582]]],
        [[[-0.3809, -0.1808, -0.3969,  ..., -0.0459, -0.0121, -0.5089],
          [-0.3897, -0.1437, -0.2335,  ..., -0.0993,  0.0240, -0.4440],
          [-0.5706, -0.0797,  0.2070,  ..., -0.1834, -0.1320, -0.6759],
          ...,
          [-0.6940, -0.1523, -0.0562,  ..., -0.2395, -0.2111, -0.5973],
          [-0.6451, -0.1406,  0.0282,  ..., -0.5722, -0.4426, -0.6403],
          [-0.5612, -0.2477, -0.1249,  ..., -0.3356, -0.5278, -0.7951]]],
        [[[-0.3069, -0.2505, -0.3094,  ...,  0.4300,  0.2213, -0.5180],
          [-0.2053, -0.0959, -0.1926,  ...,  0.4614,  0.2903, -0.4171],
          [-0.4666, -0.1452, -0.0313,  ...,  0.5509,  0.2948, -0.4594],
          ...,
          [-0.1311, -0.4203, -0.0063,  ...,  0.6194,  0.3401, -0.5003],
          [-0.1757, -0.2035,  0.1380,  ...,  0.6318,  0.3489, -0.7310],
          [-0.4350, -0.2007,  0.1116,  ...,  0.6000,  0.3548, -0.5874]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.0658, -0.0264, -0.2417,  ..., -0.2077, -0.1366,  0.0499],
          [-0.2720, -0.2741, -0.5353,  ..., -0.1920, -0.2917,  0.0517],
          [-0.6627, -0.5084, -0.3252,  ..., -0.4034, -0.2157,  0.0340],
          ...,
          [-0.2528, -0.4868, -0.3109,  ..., -0.6936, -0.5884, -0.2197],
          [-0.6417, -0.6590, -0.3771,  ..., -0.7995, -0.5179, -0.1852],
          [-0.9038, -0.4169, -0.5412,  ..., -0.8170, -0.5472, -0.2568]]],
        [[[-0.2471,  0.3842,  0.6298,  ..., -0.1699, -0.3204, -0.8392],
          [-0.3228,  0.4192,  0.5992,  ..., -0.0024, -0.3779, -0.9213],
          [-0.1397,  0.3110,  0.2695,  ..., -0.2815, -0.3071, -0.9746],
          ...,
          [-0.3218,  0.0451,  0.2411,  ..., -0.1686, -0.2778, -1.0000],
          [-0.1638,  0.3837,  0.5104,  ..., -0.2331, -0.3344, -0.8440],
          [-0.2388,  0.3634,  0.3937,  ..., -0.2585, -0.3157, -0.9483]]],
        [[[-0.3641,  0.0944,  0.2344,  ..., -0.0805, -0.0990, -0.1335],
          [-0.3470,  0.1509,  0.3493,  ...,  0.2305,  0.0050, -0.1796],
          [-0.5927, -0.1397,  0.1401,  ...,  0.1808,  0.0631, -0.1553],
          ...,
          [-0.5866,  0.1175,  0.4653,  ..., -0.0552, -0.1826, -0.2444],
          [-0.5668, -0.0743,  0.3118,  ..., -0.1095, -0.4089, -0.2607],
          [-0.8589, -0.1637,  0.0316,  ..., -0.0491, -0.2498, -0.2076]]],
        ...,
        [[[-0.3869,  0.1571,  0.2145,  ...,  0.5522,  0.1895, -0.1980],
          [-0.2440,  0.1134, -0.2031,  ...,  0.2447,  0.1907, -0.2411],
          [-0.2999,  0.1833,  0.0848,  ...,  0.2451, -0.0685, -0.1886],
          ...,
          [-0.7581, -0.0190,  0.0773,  ...,  0.5882,  0.1009, -0.2004],
          [-0.8766, -0.2864,  0.2166,  ...,  0.4111,  0.0655, -0.2561],
          [-0.8456,  0.0765,  0.4793,  ...,  0.3808,  0.2606, -0.1768]]],
        [[[-0.0245, -0.3148, -0.5803,  ...,  0.3704, -0.0306, -0.5081],
          [-0.2802, -0.2996, -0.2718,  ...,  0.2970, -0.0064, -0.4865],
          [-0.2815, -0.0861, -0.1333,  ...,  0.1961,  0.0652, -0.6677],
          ...,
          [-0.3891, -0.4397, -0.5946,  ..., -0.3085, -0.3189, -0.4616],
          [-0.3070, -0.4008, -0.4875,  ..., -0.1092, -0.3052, -0.2911],
          [-0.1768, -0.0932, -0.3026,  ...,  0.0014,  0.0322, -0.1826]]],
        [[[-0.2527,  0.1765,  0.4089,  ...,  0.0140, -0.1071, -0.0446],
          [-0.3507, -0.0978,  0.2871,  ...,  0.1785,  0.0941, -0.0445],
          [-0.2682,  0.0609,  0.3692,  ...,  0.1591,  0.0809, -0.0533],
          ...,
          [-0.5548, -0.1853,  0.1819,  ...,  0.0419, -0.0818, -0.0890],
          [-0.5069, -0.1042,  0.0322,  ..., -0.1627, -0.1438, -0.0709],
          [-0.4670, -0.0108,  0.2505,  ...,  0.0696, -0.0219,  0.0077]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2107, -0.0144, -0.1250,  ..., -0.3821, -0.4049, -0.4175],
          [-0.3989, -0.3636, -0.3648,  ..., -0.3618, -0.2903, -0.2314],
          [-0.5311, -0.6695, -0.4961,  ..., -0.5913, -0.5219, -0.1871],
          ...,
          [-0.2288, -0.1468, -0.1498,  ..., -0.6611, -0.7521, -0.8422],
          [-0.1021, -0.0628, -0.0828,  ..., -0.6965, -0.8608, -0.9936],
          [-0.2194, -0.2548, -0.5976,  ..., -0.6338, -0.6805, -0.7550]]],
        [[[-0.3907, -0.0924,  0.0666,  ..., -0.0276, -0.1731, -0.8867],
          [-0.2823,  0.1111,  0.1551,  ...,  0.0266, -0.2530, -0.5680],
          [-0.3947,  0.1096,  0.2667,  ..., -0.0279, -0.3505, -0.7597],
          ...,
          [-0.5645, -0.3394, -0.0708,  ..., -0.0944, -0.2688, -0.5519],
          [-0.7379, -0.2203, -0.1728,  ..., -0.2229, -0.2826, -0.5692],
          [-0.5886, -0.0920, -0.2147,  ..., -0.2880, -0.4080, -0.6578]]],
        [[[ 0.5395,  0.2010, -0.0612,  ..., -0.0158, -0.4364, -0.4078],
          [ 0.5454,  0.2634, -0.0954,  ..., -0.0910, -0.1970, -0.5877],
          [ 0.3254,  0.2064,  0.2711,  ...,  0.0718, -0.1210, -0.6431],
          ...,
          [ 0.3884,  0.3400,  0.5176,  ..., -0.3638, -0.3237, -0.2062],
          [-0.0126,  0.5033,  0.4176,  ..., -0.3108, -0.2751, -0.0720],
          [ 0.1080,  0.4195,  0.5072,  ..., -0.3658, -0.3473, -0.1162]]],
        ...,
        [[[-0.1484, -0.0336, -0.0195,  ...,  0.9072,  0.4368, -0.6497],
          [-0.2205, -0.0357,  0.1198,  ...,  1.0000,  0.6720, -0.6414],
          [-0.4763, -0.3009, -0.1207,  ...,  0.9735,  0.6903, -0.5044],
          ...,
          [ 0.2243, -0.0130,  0.1396,  ...,  0.1561,  0.2941, -0.3956],
          [ 0.0784,  0.2830,  0.2817,  ..., -0.1086,  0.0407, -0.5842],
          [-0.2229,  0.2457, -0.0626,  ...,  0.2134,  0.2362, -0.4627]]],
        [[[-0.0667,  0.5446,  0.7378,  ..., -0.1789, -0.2549, -0.6378],
          [ 0.1412,  0.6518,  0.6714,  ..., -0.2004, -0.3598, -0.5524],
          [ 0.2498,  0.6635,  0.7837,  ...,  0.0470, -0.3538, -0.6585],
          ...,
          [-0.1524,  0.5079,  0.7704,  ..., -0.2247, -0.5225, -0.5858],
          [-0.1765,  0.5356,  0.7674,  ..., -0.4126, -0.5804, -0.7117],
          [-0.4442,  0.3166,  0.6724,  ..., -0.3322, -0.5797, -0.8156]]],
        [[[-0.0256, -0.1476, -0.0877,  ..., -0.3460, -0.4465, -0.5573],
          [-0.1367, -0.3247, -0.0454,  ..., -0.4749, -0.4339, -0.4562],
          [-0.2338, -0.3039, -0.1895,  ..., -0.4915, -0.7212, -0.4413],
          ...,
          [-0.2970, -0.1512, -0.2153,  ..., -0.2542, -0.2720, -0.5699],
          [-0.3296, -0.2359, -0.0332,  ..., -0.2785, -0.1753, -0.4865],
          [-0.2285, -0.3978, -0.2117,  ..., -0.2681, -0.2722, -0.4311]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.5389,  0.1605,  0.1583,  ..., -0.1816,  0.2026,  0.1990],
          [ 0.5812,  0.2298,  0.1171,  ..., -0.2665,  0.0025,  0.0254],
          [ 0.2926,  0.3494,  0.5434,  ..., -0.6512,  0.2196,  0.2868],
          ...,
          [ 0.2423,  0.0963,  0.2208,  ..., -0.7434,  0.1362,  0.0491],
          [ 0.0590,  0.2178,  0.1315,  ..., -0.9385, -0.1780, -0.1308],
          [ 0.3412,  0.4684, -0.0514,  ..., -0.3236, -0.3257,  0.1352]]],
        [[[ 0.4348,  0.3914,  0.2394,  ..., -0.4950, -0.4548, -0.2892],
          [ 0.4117,  0.4900,  0.2567,  ..., -0.6019, -0.7194, -0.5414],
          [ 0.5357,  0.3398,  0.1157,  ..., -0.2819, -0.6653, -0.6290],
          ...,
          [ 0.2094,  0.1609,  0.1755,  ..., -0.3303, -0.6250, -0.2744],
          [ 0.2643,  0.4133,  0.5272,  ..., -0.2972, -0.4193, -0.5667],
          [ 0.4574,  0.4130,  0.5509,  ..., -0.3833, -0.4347, -0.7609]]],
        [[[-0.6160,  0.1224,  0.4017,  ..., -0.1935, -0.3308, -0.4053],
          [-0.6181, -0.0019,  0.1697,  ...,  0.1510, -0.1058, -0.5690],
          [-0.3880, -0.1458, -0.1876,  ...,  0.2199, -0.1575, -0.5317],
          ...,
          [-0.9394, -0.3590,  0.1766,  ...,  0.3299,  0.2172, -0.2311],
          [-0.6601, -0.4679,  0.0220,  ...,  0.2793,  0.1042, -0.0123],
          [-0.5238, -0.1689,  0.0307,  ...,  0.3391,  0.2427, -0.1485]]],
        ...,
        [[[-0.3850,  0.0651,  0.2524,  ..., -0.0192, -0.0118,  0.1169],
          [-0.3310,  0.1442,  0.3678,  ..., -0.1692, -0.0978,  0.0368],
          [-0.2613,  0.2763,  0.2508,  ..., -0.0271, -0.0675,  0.0689],
          ...,
          [-0.4328,  0.0154,  0.4413,  ..., -0.0328, -0.2083,  0.0630],
          [-0.4490,  0.1850,  0.2560,  ..., -0.1098, -0.2743,  0.0887],
          [-0.4989,  0.1286,  0.2190,  ...,  0.1114, -0.0179,  0.1023]]],
        [[[-0.6028, -0.3546, -0.3093,  ..., -0.5628, -0.5105, -0.5317],
          [-0.9348, -0.5198, -0.1651,  ..., -0.3955, -0.3890, -0.4412],
          [-0.7032, -0.1967, -0.1385,  ..., -0.4008, -0.4860, -0.3992],
          ...,
          [-0.3512, -0.0076, -0.0850,  ..., -0.5459, -0.1556, -0.3011],
          [-0.6158, -0.1810, -0.2286,  ..., -0.4315, -0.1328, -0.1446],
          [-1.0000, -0.4775, -0.1315,  ..., -0.3184, -0.1200, -0.1439]]],
        [[[-0.5846, -0.1584,  0.2107,  ...,  0.2698,  0.8510,  0.8452],
          [-0.6753, -0.2457,  0.1246,  ...,  0.3810,  0.7811,  0.7912],
          [-0.7482, -0.2429,  0.0287,  ...,  0.4428,  0.8654,  0.7912],
          ...,
          [-0.5491,  0.0907,  0.2565,  ...,  0.4858,  0.8675,  0.9257],
          [-0.6811, -0.0481,  0.2556,  ...,  0.4158,  0.8951,  1.0000],
          [-0.5509, -0.0906,  0.2560,  ...,  0.3705,  0.7915,  0.9021]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4149,  0.0848,  0.1913,  ..., -0.2712, -0.3885, -0.1880],
          [-0.5606,  0.0391,  0.0449,  ..., -0.0257, -0.2086, -0.1283],
          [-0.6668,  0.0201,  0.0856,  ...,  0.0522, -0.2100, -0.1469],
          ...,
          [-0.3205,  0.0729,  0.0281,  ..., -0.2864, -0.2301, -0.1119],
          [-0.3662,  0.0275, -0.1122,  ..., -0.1419, -0.1715, -0.2067],
          [-0.5445, -0.2207, -0.0629,  ..., -0.0978, -0.1949, -0.1530]]],
        [[[-0.3544,  0.0768,  0.4245,  ..., -0.2268, -0.2675, -0.4114],
          [-0.4511, -0.4461,  0.0604,  ..., -0.5599, -0.4918, -0.3792],
          [-0.2961, -0.2304, -0.0833,  ..., -0.4869, -0.4274, -0.9158],
          ...,
          [-0.2998,  0.5188,  0.5143,  ..., -0.0541, -0.0363, -0.6205],
          [-0.1501,  0.5141,  0.5642,  ..., -0.1650, -0.0263, -0.2854],
          [-0.3344,  0.1746,  0.3028,  ..., -0.2180, -0.1851, -0.1999]]],
        [[[-0.8388, -0.4347, -0.0882,  ..., -0.4745, -0.4256, -0.1329],
          [-0.2574, -0.1465, -0.1369,  ..., -0.7479, -0.5988, -0.3967],
          [-0.2185, -0.1350, -0.3578,  ..., -0.6297, -0.5802, -0.7610],
          ...,
          [-0.3063, -0.3463, -0.2577,  ..., -0.5601, -0.5169, -0.5225],
          [-0.2707, -0.3267, -0.4952,  ..., -0.4003, -0.2954, -0.5463],
          [-0.6234, -0.2862, -0.5110,  ..., -0.3634, -0.0668, -0.2314]]],
        ...,
        [[[-0.4648, -0.2284,  0.4248,  ...,  0.1271,  0.3634,  0.2313],
          [-0.5031,  0.0596,  0.4304,  ...,  0.0958,  0.3983,  0.2904],
          [-0.5677, -0.0441,  0.2253,  ..., -0.0141,  0.2301, -0.0303],
          ...,
          [-0.5707, -0.1181, -0.1666,  ...,  0.0025,  0.3998,  0.4448],
          [-0.6126, -0.1859, -0.1173,  ..., -0.2968,  0.2413,  0.5573],
          [-0.6650, -0.0367,  0.0156,  ...,  0.2012,  0.3363,  0.4650]]],
        [[[-0.9091,  0.0540,  0.2494,  ...,  0.1737,  0.0162, -0.0485],
          [-0.3933,  0.1221,  0.4237,  ..., -0.1446, -0.0642, -0.4045],
          [-0.0676,  0.0905,  0.2625,  ..., -0.0104,  0.1448, -0.3413],
          ...,
          [ 0.1280,  0.2079,  0.3161,  ..., -0.6450, -0.1046, -0.3968],
          [-0.0157,  0.3956,  0.2872,  ..., -0.0158, -0.0975, -0.6714],
          [ 0.0732,  0.3658,  0.0732,  ...,  0.1103,  0.1472, -0.4530]]],
        [[[-0.2820,  0.2525,  0.2764,  ...,  0.0264,  0.1284, -0.0094],
          [-0.4917,  0.0432,  0.2647,  ...,  0.2044,  0.0286,  0.0710],
          [-0.8661, -0.4157, -0.0671,  ...,  0.0404, -0.0416,  0.1660],
          ...,
          [-0.4800,  0.0550,  0.2478,  ...,  0.0774, -0.3455,  0.0450],
          [-0.5759, -0.2421,  0.1678,  ..., -0.0591,  0.0291,  0.0509],
          [-0.6691, -0.0280,  0.0311,  ..., -0.0694,  0.0835,  0.0923]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-5.1210e-01, -3.0860e-02, -1.6323e-01,  ..., -5.6115e-01,
           -2.8237e-01, -3.9489e-01],
          [-1.3703e-01,  1.2722e-02, -3.4357e-01,  ..., -2.1929e-01,
           -2.2100e-01, -2.3633e-01],
          [ 1.2001e-01,  1.5719e-01, -2.0061e-01,  ..., -1.9624e-01,
           -2.1520e-01, -1.4993e-01],
          ...,
          [-1.4105e-01, -1.5364e-01, -1.0177e-01,  ..., -2.5252e-01,
           -3.6821e-01, -5.1737e-01],
          [-2.2560e-01, -2.1551e-01, -4.6930e-01,  ..., -2.2702e-01,
           -3.3480e-01, -5.2949e-01],
          [-3.2017e-01, -1.7804e-01, -1.1616e-03,  ..., -3.0691e-01,
           -4.6055e-01, -6.4323e-01]]],
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3909, -0.2335, -0.3224,  ..., -0.0511, -0.0118, -0.3308],
          [-0.7170, -0.7167, -0.5256,  ...,  0.1795,  0.1445, -0.1529],
          [-0.5945, -0.4593, -0.6121,  ...,  0.2697,  0.0346, -0.2615],
          ...,
          [-0.3059, -0.4623, -0.2894,  ...,  0.4135,  0.2734,  0.0946],
          [-0.4061, -0.3021, -0.5180,  ...,  0.1854,  0.2063,  0.1195],
          [-0.4564, -0.2582, -0.3307,  ...,  0.2533,  0.2527,  0.1290]]],
        [[[-0.4586, -0.3675,  0.0844,  ...,  0.6253,  0.5554, -0.3945],
          [-0.3013, -0.2891, -0.1070,  ...,  0.6506,  0.6028, -0.3336],
          [-0.3245, -0.3084, -0.2523,  ...,  0.5331,  0.5515, -0.1355],
          ...,
          [-0.2890, -0.1709, -0.2009,  ...,  0.1253, -0.1427, -0.8458],
          [-0.4312,  0.0231, -0.0494,  ...,  0.3459, -0.2803, -1.0000],
          [-0.4265, -0.1019, -0.1114,  ...,  0.4337,  0.0738, -0.6107]]],
        [[[-0.0324,  0.0185,  0.0436,  ...,  0.1134,  0.1513, -0.0766],
          [-0.1664,  0.1808,  0.2401,  ...,  0.0674,  0.0833, -0.2454],
          [-0.3899,  0.1258,  0.1094,  ...,  0.0306,  0.1683, -0.2239],
          ...,
          [ 0.3400,  0.1855,  0.2697,  ...,  0.0591, -0.0583, -0.3925],
          [ 0.3494,  0.2722,  0.1074,  ..., -0.2259, -0.1353, -0.2672],
          [ 0.1746,  0.2626,  0.0490,  ..., -0.1034, -0.1717, -0.2080]]],
        ...,
        [[[ 0.0070,  0.0436, -0.0414,  ..., -0.4755, -0.6636, -0.5697],
          [-0.2041, -0.1763, -0.2554,  ..., -0.6649, -0.4720, -0.2655],
          [-0.6250, -0.2773, -0.2695,  ..., -0.7070, -0.7734, -0.2255],
          ...,
          [ 0.1679,  0.2280, -0.0603,  ..., -0.7728, -0.4991, -0.2749],
          [ 0.0903,  0.1976, -0.2102,  ..., -0.4802, -0.7591, -0.4066],
          [-0.3497, -0.0235, -0.0958,  ..., -0.1399, -0.4097, -0.7149]]],
        [[[-0.1758,  0.0760, -0.1733,  ..., -0.8047, -0.5505, -0.5207],
          [-0.2762, -0.1083, -0.1900,  ..., -1.0000, -0.6182, -0.4849],
          [-0.3083, -0.1888, -0.5371,  ..., -0.4832, -0.5585, -0.6599],
          ...,
          [-0.2257, -0.2176, -0.2530,  ..., -0.2660, -0.4534, -0.4884],
          [-0.3591, -0.1569, -0.0143,  ..., -0.4362, -0.2612, -0.3156],
          [-0.3080, -0.1464, -0.2192,  ..., -0.3527, -0.3630, -0.2477]]],
        [[[-0.5019,  0.2610,  0.3465,  ..., -0.3085, -0.2183, -0.4096],
          [-0.5759,  0.0849,  0.3940,  ...,  0.1735, -0.0136, -0.1325],
          [-0.1408,  0.4014,  0.5649,  ...,  0.1487, -0.1644, -0.4379],
          ...,
          [-0.4892,  0.1455,  0.2619,  ...,  0.3876,  0.0200, -0.3599],
          [-0.5849,  0.1303,  0.0999,  ...,  0.2854,  0.2159, -0.3683],
          [-0.4790,  0.0839, -0.0134,  ...,  0.0812,  0.1830, -0.2727]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.6255, -0.2814, -0.1563,  ...,  0.0625,  0.0205, -0.4381],
          [-0.7393, -0.4811, -0.1588,  ..., -0.0521, -0.1570, -0.5310],
          [-0.5499, -0.1438, -0.1176,  ..., -0.0062, -0.2199, -0.6245],
          ...,
          [-0.5833,  0.0438,  0.1098,  ..., -0.0253, -0.0318, -0.3082],
          [-0.5710,  0.0470,  0.1390,  ..., -0.2712, -0.3357, -0.3531],
          [-0.6136, -0.2393, -0.1945,  ..., -0.0253, -0.0863, -0.2435]]],
        [[[ 0.1637,  0.5535,  0.5305,  ...,  0.0587, -0.1029, -0.4124],
          [ 0.1060, -0.1345,  0.3432,  ..., -0.0012, -0.2111, -0.5995],
          [ 0.0598,  0.1219,  0.0114,  ...,  0.3532, -0.0769, -0.8780],
          ...,
          [-0.0386,  0.0744,  0.4792,  ...,  0.8906,  0.3681, -0.5461],
          [ 0.3797,  0.6778,  0.5245,  ...,  0.8219, -0.0989, -0.6893],
          [ 0.5946,  0.8504,  0.5233,  ...,  0.7785,  0.3251, -0.1998]]],
        [[[-0.1862, -0.0743, -0.0237,  ..., -0.7461, -0.5840, -0.7066],
          [-0.2542, -0.1191, -0.1890,  ..., -0.4916, -0.5429, -0.7056],
          [-0.1295,  0.0122,  0.0636,  ..., -0.5682, -0.8704, -0.7334],
          ...,
          [-0.2146,  0.0419, -0.0904,  ..., -0.6032, -0.4829, -0.7404],
          [-0.0658,  0.0642, -0.0291,  ..., -0.6139, -0.8231, -0.8690],
          [-0.3335, -0.1997, -0.1139,  ..., -0.5213, -0.6386, -0.6674]]],
        ...,
        [[[-0.5704, -0.7724, -0.7966,  ..., -0.5167, -0.5546, -0.6152],
          [-0.7138, -0.8711, -0.4868,  ..., -0.5020, -0.7964, -0.6700],
          [-0.9195, -0.7243, -0.2723,  ..., -0.4636, -0.6288, -0.3749],
          ...,
          [-0.4564, -0.3501, -0.2362,  ..., -0.7583, -0.6546, -0.5934],
          [-0.4296, -0.5212, -0.2149,  ..., -0.7669, -0.6348, -0.5898],
          [-0.4039, -0.3439, -0.1994,  ..., -0.6670, -0.8059, -0.8101]]],
        [[[-0.0083, -0.0920, -0.1557,  ..., -0.0594, -0.0402, -0.0463],
          [-0.1979, -0.7744, -0.0870,  ...,  0.1179,  0.2411,  0.0433],
          [-0.0386, -0.2507, -0.0802,  ..., -0.0920,  0.0742, -0.0410],
          ...,
          [ 0.3060, -0.2474,  0.1507,  ..., -0.1012,  0.4278,  0.4157],
          [ 0.3337,  0.0974,  0.2038,  ...,  0.1600,  0.2951,  0.1967],
          [ 0.0326,  0.0483,  0.0664,  ...,  0.1631,  0.1937,  0.2157]]],
        [[[-0.2191,  0.1376,  0.0677,  ..., -0.2923, -0.4730, -0.1095],
          [-0.2282,  0.0989,  0.0886,  ..., -0.2789, -0.2613, -0.0169],
          [-0.2118, -0.1414, -0.1531,  ..., -0.6696, -0.4126, -0.0165],
          ...,
          [-0.0600, -0.1399, -0.0010,  ..., -0.6052, -0.4679, -0.0803],
          [-0.0287,  0.0821,  0.0906,  ..., -0.4629, -0.2577,  0.0133],
          [-0.1833, -0.1850, -0.1132,  ..., -0.3147, -0.2581,  0.0105]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.8270, -0.1161,  0.2646,  ...,  0.3163,  0.3376, -0.0868],
          [-0.7556,  0.0909,  0.2277,  ...,  0.2015,  0.2431, -0.2798],
          [-0.4844,  0.0452,  0.1836,  ...,  0.2342,  0.1248, -0.4522],
          ...,
          [-0.7813, -0.1941, -0.1280,  ...,  0.1455, -0.2023, -0.6698],
          [-0.7002, -0.2115,  0.1472,  ...,  0.1146, -0.3221, -0.5134],
          [-0.9130, -0.4634,  0.0603,  ...,  0.0996, -0.3117, -0.5797]]],
        [[[-0.4413,  0.1605,  0.2944,  ...,  0.0435, -0.0213, -0.4863],
          [-0.6006, -0.1660,  0.2363,  ...,  0.1764, -0.0351, -0.2662],
          [-0.6360, -0.0876,  0.1706,  ...,  0.2351,  0.0779, -0.2584],
          ...,
          [-0.6317,  0.0183,  0.3997,  ..., -0.0598, -0.2453, -0.4424],
          [-0.4882,  0.1232,  0.4817,  ...,  0.0561, -0.2996, -0.5099],
          [-0.5525, -0.2031,  0.3601,  ..., -0.0019, -0.2017, -0.2823]]],
        [[[-0.3290, -0.0514, -0.1682,  ..., -0.6148, -0.4753,  0.1084],
          [-0.4327, -0.1366, -0.3080,  ..., -0.5311, -0.5908,  0.0099],
          [-0.3066, -0.3179, -0.6421,  ..., -0.3495, -0.4137, -0.0193],
          ...,
          [-0.2979, -0.1806, -0.1949,  ..., -0.3108, -0.0860,  0.2606],
          [-0.2736, -0.2437, -0.1854,  ..., -0.1193, -0.1543,  0.2563],
          [-0.0988,  0.0964,  0.1356,  ..., -0.1809, -0.1723,  0.3109]]],
        ...,
        [[[-0.4952, -0.6600, -0.3209,  ...,  0.2527,  0.1038, -0.0728],
          [-0.3774, -0.4491, -0.3573,  ...,  0.2690,  0.1515,  0.1134],
          [-0.4019, -0.5635, -0.5247,  ...,  0.1150,  0.1961,  0.2577],
          ...,
          [-0.2442, -0.3492, -0.1353,  ...,  0.0950, -0.1009, -0.3825],
          [-0.2990, -0.2845, -0.1593,  ...,  0.1874, -0.1291, -0.4833],
          [-0.2338, -0.1672,  0.0657,  ...,  0.1875,  0.0033, -0.1631]]],
        [[[ 0.0504,  0.2880,  0.1413,  ..., -0.4267, -0.5251, -0.5843],
          [ 0.1459,  0.3393,  0.0308,  ..., -0.4599, -0.2788, -0.4781],
          [ 0.2219,  0.2263,  0.2577,  ..., -0.4200, -0.3367, -0.6142],
          ...,
          [ 0.1455,  0.3531,  0.2284,  ..., -0.4241, -0.5859, -0.4678],
          [-0.1517,  0.4064,  0.3901,  ..., -0.7078, -0.4638, -0.4015],
          [-0.0204,  0.4281,  0.2663,  ..., -0.5991, -0.1432, -0.2280]]],
        [[[-0.5300,  0.0372,  0.1856,  ...,  0.4820,  0.2886,  0.3910],
          [-0.7108, -0.2332,  0.0935,  ...,  0.3425,  0.2569,  0.3644],
          [-0.9078, -0.2400,  0.1241,  ...,  0.5523,  0.5405,  0.3194],
          ...,
          [-0.8962, -0.1874,  0.1493,  ...,  0.3524,  0.3447,  0.5048],
          [-0.8375, -0.0639,  0.1635,  ...,  0.4640,  0.5614,  0.5049],
          [-0.9493, -0.1657,  0.0544,  ...,  0.4265,  0.4476,  0.3579]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-7.6795e-01, -3.3516e-01, -2.9322e-01,  ..., -6.8218e-02,
           -2.2970e-01, -6.3821e-01],
          [-5.5988e-01, -2.3069e-01, -3.2283e-01,  ..., -3.8500e-02,
           -2.9583e-01, -6.5920e-01],
          [-6.1077e-01, -3.1283e-01, -1.6918e-01,  ..., -2.7103e-01,
           -4.9311e-01, -4.8678e-01],
          ...,
          [-7.4462e-01, -3.5777e-01, -1.0610e-01,  ...,  1.3085e-01,
           -2.5803e-01, -4.3943e-01],
          [-4.9407e-01, -3.3728e-01, -2.0260e-01,  ...,  7.8490e-02,
           -3.3095e-01, -6.5775e-01],
          [-3.6112e-01,  4.5349e-02,  1.0190e-01,  ...,  6.5613e-04,
           -3.0360e-01, -5.0099e-01]]],
        [[[-3.4009e-01, -1.3294e-01, -2.0903e-01,  ..., -5.8360e-01,
           -5.6395e-01, -4.5089e-01],
          [-2.7318e-01, -4.7598e-02,  2.1274e-01,  ..., -6.1444e-01,
           -4.6207e-01, -3.7275e-01],
          [-4.2318e-03,  1.5598e-01,  3.0871e-01,  ..., -7.0544e-01,
           -5.2649e-01, -3.1626e-01],
          ...,
          [ 1.5417e-01,  2.9782e-01,  2.0839e-01,  ..., -4.6158e-01,
           -1.0000e+00, -6.6916e-01],
          [-1.1202e-01, -1.5356e-01, -1.6122e-02,  ..., -5.6768e-01,
           -7.8745e-01, -5.7496e-01],
          [-1.7550e-02,  3.7253e-02,  1.0328e-01,  ..., -6.9681e-01,
           -6.0600e-01, -4.7486e-01]]],
        [[[-6.1153e-01, -2.8832e-01,  1.0699e-02,  ...,  2.4717e-01,
            2.1204e-01, -2.7775e-01],
          [-5.3927e-01, -2.0962e-01,  1.9879e-01,  ...,  4.7291e-01,
            2.2607e-01, -4.3694e-01],
          [-3.5835e-01,  1.5415e-01,  2.2914e-01,  ...,  4.7200e-01,
            8.3596e-02, -4.3757e-01],
          ...,
          [-5.8109e-01, -5.7153e-02,  1.3320e-02,  ...,  2.3758e-01,
           -1.3328e-01, -6.6155e-01],
          [-3.3859e-01, -1.6381e-01,  2.3243e-01,  ...,  2.3168e-01,
           -2.9099e-02, -4.6724e-01],
          [-2.0930e-01,  2.1105e-01,  2.3820e-01,  ...,  2.9501e-01,
           -6.2664e-02, -2.9078e-01]]],
        ...,
        [[[-2.3561e-01, -3.7524e-01, -3.1236e-01,  ..., -2.5572e-01,
           -4.7443e-01, -1.0000e+00],
          [-2.3140e-01, -8.7716e-02, -3.1869e-01,  ..., -9.7062e-02,
           -2.8772e-01, -6.6644e-01],
          [-1.6465e-01,  7.0610e-02, -1.1860e-01,  ..., -2.2836e-01,
           -4.1823e-01, -6.4700e-01],
          ...,
          [-5.3360e-02,  5.5290e-02, -1.0773e-01,  ..., -2.6567e-01,
           -1.5709e-02, -3.7737e-01],
          [-1.7082e-01, -1.5038e-01, -1.8792e-01,  ..., -3.0843e-01,
            5.6168e-02, -2.9622e-01],
          [-1.5525e-01, -1.7532e-01, -1.4052e-01,  ..., -2.4783e-01,
            1.0623e-01, -1.9812e-03]]],
        [[[-2.5156e-01, -1.2752e-01, -2.8186e-01,  ..., -7.2685e-01,
           -5.8252e-01, -7.4786e-01],
          [-3.3110e-01, -2.7106e-01, -2.6700e-01,  ..., -5.3449e-01,
           -6.7546e-01, -5.2823e-01],
          [-3.5195e-01, -3.9782e-01, -3.0660e-01,  ..., -6.1226e-01,
           -6.7841e-01, -5.2704e-01],
          ...,
          [-4.4013e-01, -2.4983e-01, -4.2551e-01,  ..., -6.3233e-01,
           -6.2543e-01, -4.8785e-01],
          [-2.7923e-01, -1.2197e-01, -3.1764e-01,  ..., -5.1685e-01,
           -6.9366e-01, -5.4032e-01],
          [-3.1216e-01, -1.8719e-01, -3.1127e-01,  ..., -5.1029e-01,
           -7.8077e-01, -6.2979e-01]]],
        [[[-5.4127e-01, -1.8591e-01,  4.4844e-02,  ..., -5.6645e-01,
           -2.2365e-01, -4.2232e-01],
          [-1.6064e-01, -7.6368e-02, -3.8532e-02,  ..., -3.4744e-01,
           -1.6568e-01, -4.7379e-01],
          [ 5.3217e-02,  3.9000e-02,  1.9364e-01,  ..., -3.2894e-01,
           -2.3052e-01, -3.1165e-01],
          ...,
          [-4.2502e-01, -5.6056e-01, -5.8151e-01,  ..., -5.1674e-01,
           -4.0486e-01, -7.1999e-01],
          [-1.5738e-01, -3.9009e-01, -6.1979e-01,  ..., -4.8072e-01,
           -5.0184e-01, -4.4266e-01],
          [ 3.9183e-02,  1.3871e-02, -3.6543e-01,  ..., -3.5936e-01,
           -4.3252e-01, -3.4329e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-2.2962e-01, -4.4623e-01, -3.3471e-01,  ...,  4.6849e-01,
            4.7556e-01,  4.9119e-01],
          [-9.9498e-01, -5.2518e-01, -2.4906e-01,  ..., -4.2093e-04,
            1.9783e-01,  3.6082e-01],
          [-9.2072e-01, -2.0259e-01, -3.1467e-01,  ...,  4.4906e-02,
            3.6021e-01,  1.0227e-01],
          ...,
          [-4.2400e-01, -4.7889e-01, -2.4320e-01,  ...,  3.0446e-01,
            3.7270e-01, -2.6451e-01],
          [-1.6701e-01, -9.8506e-02, -4.4391e-01,  ...,  3.2434e-01,
            3.6079e-01, -5.8844e-01],
          [-3.5909e-01,  1.8073e-01,  6.1359e-03,  ...,  3.5290e-01,
            3.5063e-01, -1.6890e-01]]],
        [[[-6.0150e-01, -6.0480e-01, -5.0926e-01,  ...,  1.0594e-01,
           -2.2604e-01, -5.1167e-01],
          [-6.2239e-01, -3.0049e-01, -4.4732e-01,  ...,  2.0956e-01,
           -2.7359e-01, -4.6704e-01],
          [-4.2166e-01, -2.3557e-01, -6.5248e-01,  ...,  3.6293e-01,
            1.9493e-02, -5.3403e-01],
          ...,
          [-3.2376e-01, -2.8476e-01, -7.1443e-02,  ...,  2.8545e-01,
            3.0150e-01,  1.9096e-01],
          [-4.0725e-01, -2.6816e-01, -3.4311e-01,  ...,  2.3930e-01,
            5.2464e-01,  4.2111e-01],
          [-6.6558e-01, -4.5700e-01, -4.5989e-01,  ...,  6.0948e-01,
            5.5365e-01,  5.0911e-01]]],
        [[[-6.5116e-02,  1.0744e-01,  2.2401e-01,  ..., -3.2413e-02,
           -8.0875e-02, -3.8904e-01],
          [-1.8095e-02,  5.9539e-02,  1.2628e-01,  ..., -1.6683e-01,
           -7.7932e-02, -1.8422e-01],
          [-6.9534e-02,  1.7848e-01,  3.9944e-01,  ..., -3.3797e-02,
           -1.6910e-01, -3.9322e-01],
          ...,
          [ 3.3708e-01,  6.2162e-01,  5.1164e-01,  ..., -5.7180e-01,
           -3.1752e-01, -2.0863e-01],
          [ 3.4060e-01,  5.8629e-01,  5.8864e-01,  ..., -3.2963e-01,
           -5.6874e-02, -2.0804e-01],
          [-8.5754e-02,  1.2879e-01,  2.5470e-01,  ..., -3.2614e-01,
           -2.2951e-01, -4.1082e-01]]],
        ...,
        [[[-5.9816e-02, -8.7595e-02,  1.4385e-02,  ..., -2.7838e-01,
           -5.4406e-01, -7.2227e-01],
          [ 1.8978e-02, -8.2270e-02, -1.9874e-01,  ..., -3.6995e-01,
           -5.4757e-01, -8.9170e-01],
          [ 1.5966e-01,  1.0526e-01, -2.3423e-02,  ..., -5.9680e-01,
           -4.0829e-01, -6.0889e-01],
          ...,
          [ 1.7321e-01,  2.9372e-01,  1.6343e-01,  ..., -2.5573e-01,
           -3.7949e-01, -6.7281e-01],
          [-9.9847e-02, -7.7589e-02,  4.1847e-01,  ..., -5.8138e-01,
           -3.3167e-01, -5.1306e-01],
          [ 3.8818e-02,  1.3329e-01,  3.8870e-01,  ..., -2.9572e-01,
           -2.6684e-01, -5.2844e-01]]],
        [[[-5.0735e-01, -1.4092e-01,  2.1465e-03,  ..., -6.0400e-02,
           -3.3895e-01, -1.0000e+00],
          [-6.8687e-01, -2.5197e-01,  1.2980e-01,  ..., -1.5969e-01,
           -4.8478e-01, -8.8362e-01],
          [-7.9808e-01, -3.8023e-01,  6.5244e-03,  ..., -4.4767e-01,
           -6.2923e-01, -6.7549e-01],
          ...,
          [-6.1062e-01, -2.0280e-01, -4.5210e-02,  ..., -2.6357e-01,
           -6.7624e-01, -6.6942e-01],
          [-3.9031e-01, -1.2083e-01, -9.1717e-02,  ..., -4.0978e-01,
           -9.7061e-01, -8.0306e-01],
          [-4.9050e-01,  7.5924e-02,  2.3994e-01,  ..., -5.6685e-01,
           -4.6827e-01, -7.3687e-01]]],
        [[[-1.5141e-01,  1.6897e-01,  2.9127e-01,  ...,  6.3530e-01,
            2.5526e-01,  1.7449e-01],
          [-3.3761e-01,  5.4361e-02,  3.8191e-01,  ...,  5.0288e-01,
            4.2873e-01,  1.1225e-01],
          [-3.0503e-01,  9.6909e-02,  2.8992e-01,  ...,  5.7190e-01,
            5.0685e-01,  1.1925e-01],
          ...,
          [-3.5373e-01,  7.0683e-02,  4.0178e-01,  ...,  2.4743e-01,
            2.7418e-01,  1.3517e-01],
          [-3.3418e-01,  2.7160e-01,  5.1463e-01,  ...,  3.2726e-01,
            1.6042e-01,  1.1249e-01],
          [-1.5287e-01,  2.6534e-01,  3.3465e-01,  ...,  4.8463e-01,
            1.6899e-01,  1.4310e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.4598e-01,  9.7646e-02,  3.9956e-01,  ..., -5.9418e-02,
           -3.7734e-01, -3.2229e-01],
          [-2.2335e-01,  2.5312e-01,  7.8541e-01,  ...,  7.3576e-04,
           -5.8193e-02, -2.1137e-01],
          [-6.6438e-02,  5.1408e-01,  8.8328e-01,  ..., -2.9734e-01,
           -6.9093e-02, -2.7546e-01],
          ...,
          [-2.0100e-01,  2.4436e-01,  3.5856e-01,  ...,  2.1614e-01,
            8.2108e-02, -3.0717e-01],
          [ 1.3665e-02,  4.5231e-01,  4.6814e-01,  ...,  8.0152e-02,
           -2.2263e-02, -4.1274e-01],
          [ 2.9486e-02,  4.7241e-01,  4.5870e-01,  ...,  1.3761e-01,
           -8.6850e-02, -5.5514e-01]]],
        [[[-7.7608e-02, -3.9608e-01, -1.9496e-01,  ..., -3.0890e-01,
           -4.4518e-01, -6.9880e-01],
          [-1.1562e-01, -2.9943e-01, -1.4045e-01,  ..., -3.3110e-01,
           -5.9179e-01, -6.2318e-01],
          [-2.8352e-01, -2.0009e-01, -2.8100e-01,  ..., -3.3510e-01,
           -5.2958e-01, -5.4303e-01],
          ...,
          [-2.9803e-01, -1.3524e-01, -4.4720e-02,  ..., -1.0000e+00,
           -5.9377e-01, -6.4463e-01],
          [-3.2881e-01,  1.4439e-02,  2.9803e-02,  ..., -8.2096e-01,
           -4.8918e-01, -5.8397e-01],
          [-2.3198e-01, -1.7755e-01, -1.0062e-01,  ..., -4.8879e-01,
           -5.2553e-01, -7.1451e-01]]],
        [[[-5.4534e-01, -1.8997e-01,  3.0482e-02,  ...,  1.0814e-01,
            3.5409e-01,  2.1693e-02],
          [-8.3709e-01, -2.8237e-01, -2.5755e-01,  ...,  1.4970e-01,
            2.7656e-01,  3.7873e-02],
          [-5.7148e-01, -1.6463e-01, -2.3608e-01,  ...,  1.3277e-01,
            6.9584e-02, -5.7644e-03],
          ...,
          [-8.1235e-01, -5.3930e-01, -6.0890e-02,  ...,  2.9177e-01,
            2.7554e-01, -2.1582e-02],
          [-8.8177e-01, -3.9697e-01, -2.6124e-01,  ...,  4.2043e-01,
            3.9746e-01, -2.3627e-01],
          [-8.0514e-01, -4.2692e-01, -4.8391e-01,  ...,  3.7957e-01,
            4.1988e-01, -1.7983e-01]]],
        ...,
        [[[-5.1875e-01, -6.2220e-02,  8.4727e-02,  ...,  2.5372e-01,
           -5.5552e-02, -4.0833e-01],
          [-6.4650e-01, -3.3854e-01, -8.1960e-03,  ...,  3.1700e-01,
           -3.8162e-02, -3.3828e-01],
          [-6.2635e-01, -5.9009e-01, -1.2260e-01,  ...,  1.7108e-01,
           -4.2775e-02, -3.3691e-01],
          ...,
          [-4.9715e-01, -7.2590e-02,  1.2486e-01,  ..., -1.3395e-01,
           -1.7192e-01, -4.2003e-01],
          [-5.2915e-01, -2.6709e-01, -3.4212e-02,  ...,  2.5581e-01,
            5.9842e-02, -5.9257e-01],
          [-5.5657e-01, -2.5134e-01,  8.6536e-02,  ...,  2.4967e-01,
            6.8000e-02, -5.0862e-01]]],
        [[[-3.1158e-01, -2.3298e-02,  1.2115e-01,  ...,  2.9074e-01,
            1.3698e-01, -5.8766e-01],
          [-5.4279e-01, -8.6875e-02,  2.7544e-01,  ...,  1.1417e-01,
            1.1694e-01, -3.2441e-01],
          [-3.6314e-01,  1.3750e-01,  2.7404e-01,  ..., -1.2750e-01,
            3.2382e-02, -2.5563e-01],
          ...,
          [-3.5929e-01,  9.4473e-02,  1.7715e-01,  ..., -1.2510e-01,
           -1.7067e-01, -5.7505e-01],
          [-1.9852e-01,  1.2336e-01,  1.9326e-01,  ..., -3.7467e-02,
           -1.5047e-01, -6.0822e-01],
          [-2.4354e-01, -1.6850e-01,  2.0156e-01,  ...,  1.2475e-01,
           -1.1225e-01, -6.4541e-01]]],
        [[[-2.7422e-01, -1.4446e-01, -2.5626e-01,  ..., -4.3574e-01,
           -1.7914e-03,  1.6401e-02],
          [-1.2529e-01, -9.4146e-03, -1.8638e-01,  ..., -2.0957e-01,
            1.5589e-03, -5.4908e-02],
          [-4.3902e-01, -1.0698e-01, -3.1691e-02,  ..., -3.2829e-02,
            3.3414e-02,  1.7107e-01],
          ...,
          [-2.2286e-01, -1.4579e-01, -3.3389e-01,  ..., -2.0287e-01,
           -1.5613e-01, -2.5572e-02],
          [ 3.9882e-01,  5.1580e-01,  5.0976e-01,  ..., -2.3038e-02,
            2.5476e-02,  8.7280e-02],
          [ 6.7565e-01,  8.0101e-01,  8.6156e-01,  ..., -1.7024e-01,
           -1.7306e-03,  9.3360e-02]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2614, -0.2655, -0.1724,  ..., -0.4770, -0.6022, -0.9148],
          [-0.1346, -0.1491,  0.0056,  ..., -0.3296, -0.5538, -0.6820],
          [-0.1614, -0.2457,  0.0048,  ..., -0.5007, -0.7051, -0.7061],
          ...,
          [-0.1132, -0.0489,  0.0250,  ..., -0.4614, -0.5012, -0.6809],
          [-0.1691, -0.1651, -0.0673,  ..., -0.3616, -0.5334, -0.6663],
          [-0.3702, -0.2090, -0.1808,  ..., -0.6050, -0.7499, -0.7118]]],
        [[[-0.0502,  0.0334, -0.0861,  ..., -0.1850, -0.3042, -0.3514],
          [-0.1941,  0.0543,  0.1322,  ..., -0.3977, -0.4518, -0.5492],
          [-0.3220, -0.2441,  0.0649,  ..., -0.1142, -0.2909, -0.4881],
          ...,
          [-0.0943,  0.2526,  0.2705,  ..., -0.7229, -0.6668, -0.7425],
          [-0.0352,  0.1665,  0.2203,  ..., -0.3464, -0.3806, -0.4683],
          [-0.0485,  0.2083,  0.2288,  ..., -0.4104, -0.4415, -0.5232]]],
        [[[-0.0707,  0.0042,  0.0327,  ..., -0.8553, -0.8471, -0.7381],
          [-0.0293,  0.0957,  0.2078,  ..., -0.7529, -0.8522, -0.5468],
          [ 0.1581,  0.2878,  0.3198,  ..., -0.6749, -0.6722, -0.4585],
          ...,
          [-0.0154,  0.1591,  0.2354,  ..., -0.3034, -0.4313, -0.7973],
          [-0.1485,  0.0056,  0.0849,  ..., -0.5688, -0.4880, -0.6824],
          [-0.0239,  0.0600,  0.0524,  ..., -0.5733, -0.5625, -0.8627]]],
        ...,
        [[[-0.6287, -0.0860,  0.0976,  ..., -0.2336, -0.4513, -0.5270],
          [-0.3595, -0.0994,  0.0951,  ..., -0.3002, -0.4015, -0.6205],
          [-0.3657, -0.1291,  0.1057,  ..., -0.3984, -0.3208, -0.5324],
          ...,
          [-0.2532,  0.0764,  0.2377,  ..., -0.2571, -0.5181, -0.6810],
          [-0.2401,  0.1284,  0.2107,  ..., -0.3207, -0.4179, -0.6251],
          [-0.4186, -0.1155,  0.1070,  ..., -0.3055, -0.4944, -0.6998]]],
        [[[-0.4225, -0.4846, -0.5961,  ..., -0.4746, -0.7724, -0.6058],
          [-0.2129, -0.3965, -0.4681,  ..., -0.5528, -0.8074, -0.6339],
          [-0.1774, -0.2579, -0.6899,  ..., -0.6903, -0.8327, -0.7137],
          ...,
          [-0.7809, -0.4198, -0.3006,  ..., -0.1236,  0.0147, -0.0728],
          [-0.4663, -0.3622, -0.2670,  ..., -0.3593, -0.1300, -0.1070],
          [-0.3609, -0.2306, -0.3540,  ..., -0.5366, -0.2624, -0.1766]]],
        [[[-0.2610, -0.1608, -0.1490,  ...,  0.5202,  0.1424, -0.3360],
          [-0.3263, -0.0584, -0.2098,  ...,  0.6068,  0.3656, -0.2385],
          [-0.2710,  0.1039, -0.0263,  ...,  0.8560,  0.3647, -0.2383],
          ...,
          [-0.4368, -0.0584,  0.1419,  ...,  0.7949,  0.6428,  0.1451],
          [-0.2336, -0.1437, -0.1449,  ...,  0.6182,  0.3887,  0.2202],
          [-0.1560, -0.2796, -0.4230,  ...,  0.4927,  0.3686,  0.4237]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[ 0.0084,  0.0767,  0.0980,  ..., -0.2360, -0.1769, -0.0423],
          [-0.3143,  0.0354,  0.1664,  ..., -0.4517, -0.3363, -0.1565],
          [-0.4265, -0.2220,  0.0015,  ..., -0.2804, -0.3395, -0.3974],
          ...,
          [-0.3458, -0.1071, -0.2051,  ..., -0.2587, -0.2552, -0.2343],
          [-0.2109, -0.3241, -0.1917,  ..., -0.2767, -0.2510, -0.6026],
          [-0.0609, -0.1723, -0.4914,  ...,  0.0773,  0.2359,  0.0261]]],
        [[[-0.5214,  0.1463,  0.0960,  ...,  0.5173,  0.8821,  0.8448],
          [-0.3462,  0.2249,  0.1427,  ...,  0.3736,  0.6201,  0.6262],
          [-0.6006,  0.1993,  0.3747,  ...,  0.2455,  0.7840,  0.7223],
          ...,
          [-0.4379, -0.0957, -0.2116,  ...,  0.6504,  0.9235,  0.7842],
          [-0.4022,  0.1768,  0.0864,  ...,  0.4314,  0.5871,  0.3762],
          [-0.4671,  0.2290,  0.0386,  ...,  0.4784,  0.8489,  0.7766]]],
        [[[-0.1835,  0.2806,  0.1278,  ...,  0.0839, -0.1358, -0.2851],
          [-0.1785,  0.3478,  0.2112,  ...,  0.1991, -0.0406, -0.6026],
          [-0.4069,  0.0789,  0.3010,  ...,  0.4189, -0.0109, -0.3979],
          ...,
          [-0.3863, -0.0929,  0.0637,  ...,  0.0412, -0.0285, -0.3216],
          [-0.8028, -0.3452,  0.0514,  ...,  0.1704,  0.0205, -0.1232],
          [-1.0000, -0.2407,  0.2693,  ...,  0.3240,  0.0614, -0.2470]]],
        ...,
        [[[-0.5226, -0.4481, -0.6062,  ..., -0.2512, -0.4789, -0.8543],
          [-0.5167, -1.0000, -0.6736,  ..., -0.2160, -0.2966, -0.7894],
          [-0.4858, -0.5006, -0.5239,  ..., -0.2348, -0.2430, -0.5876],
          ...,
          [-0.2284, -0.2007, -0.2915,  ..., -0.2092, -0.5027, -0.7049],
          [-0.1763, -0.3299, -0.2281,  ..., -0.1815, -0.3572, -0.8308],
          [-0.0879, -0.3347, -0.1999,  ..., -0.0830, -0.3346, -0.7366]]],
        [[[-0.4230, -0.1205,  0.1091,  ..., -0.2878, -0.0833,  0.5010],
          [-0.5477,  0.0560,  0.3031,  ..., -0.3320, -0.1125,  0.4727],
          [-0.4832,  0.2326,  0.4653,  ..., -0.2130, -0.1589,  0.5223],
          ...,
          [-0.4656,  0.1683,  0.2513,  ...,  0.0621, -0.2302,  0.5538],
          [-0.4679, -0.0340,  0.1172,  ..., -0.0323, -0.2537,  0.5334],
          [-1.0000, -0.2494, -0.2397,  ..., -0.2870, -0.0884,  0.5510]]],
        [[[ 0.1088,  0.2739,  0.6359,  ...,  0.1348, -0.2393, -0.4133],
          [ 0.0031,  0.2433,  0.4555,  ..., -0.1177, -0.3195, -0.6765],
          [ 0.2487,  0.1981,  0.2226,  ..., -0.3726, -0.4956, -0.6966],
          ...,
          [-0.0638,  0.1456,  0.0909,  ..., -0.1875, -0.2476, -0.4206],
          [ 0.1185,  0.1026,  0.2079,  ..., -0.3548, -0.4665, -0.3804],
          [ 0.0718,  0.1737,  0.1716,  ..., -0.2593, -0.5893, -0.4276]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.2218, -0.2276, -0.2341,  ..., -0.1474, -0.0765, -0.3498],
          [-0.3380, -0.2717, -0.4213,  ..., -0.1469,  0.0966, -0.0846],
          [-0.0925, -0.1153, -0.1981,  ..., -0.0965,  0.0533, -0.0819],
          ...,
          [-0.6394, -0.3604, -0.3282,  ..., -0.3913, -0.5219, -0.5939],
          [-0.7945, -0.4740, -0.2189,  ..., -0.3679, -0.6449, -0.5188],
          [-0.3448, -0.2392, -0.2831,  ..., -0.3633, -0.5565, -0.5810]]],
        [[[-0.9866, -0.4481, -0.2889,  ...,  0.8171,  0.4196, -0.2014],
          [-0.7086, -0.3538, -0.3989,  ...,  0.7963,  0.3728, -0.2431],
          [-0.5412, -0.5148, -0.4166,  ...,  0.8283,  0.4125, -0.1413],
          ...,
          [-0.5254, -0.5923, -0.5017,  ...,  0.7659,  0.4393, -0.0213],
          [-0.6843, -0.7228, -0.5078,  ...,  0.6665,  0.4274,  0.2378],
          [-0.7857, -0.9154, -0.8744,  ...,  0.6147,  0.4622,  0.2175]]],
        [[[-0.0583,  0.0439,  0.2844,  ..., -0.1021, -0.0981,  0.0116],
          [-0.3302,  0.0180,  0.1180,  ..., -0.2052, -0.1528,  0.2040],
          [ 0.1180,  0.2835,  0.1073,  ..., -0.4845, -0.4007,  0.0112],
          ...,
          [-0.1064, -0.3237,  0.1068,  ..., -0.4450, -0.5010, -0.3284],
          [-0.2446, -0.3576, -0.1152,  ..., -0.1415, -0.3665, -0.2546],
          [-0.5564, -0.2054, -0.0340,  ..., -0.2175, -0.6613, -0.5772]]],
        ...,
        [[[-0.6317, -0.1831, -0.0030,  ..., -0.3664, -0.6674, -0.5474],
          [-0.5865, -0.1204, -0.1277,  ..., -0.4817, -0.6268, -0.5534],
          [-0.5735,  0.0018, -0.1111,  ..., -0.4897, -0.4262, -0.6703],
          ...,
          [-0.6552, -0.1546,  0.0540,  ..., -0.4842, -0.7271, -0.8409],
          [-0.5738,  0.0051,  0.2030,  ..., -0.3907, -0.5042, -0.5192],
          [-0.6047, -0.0330,  0.0066,  ..., -0.2453, -0.3341, -0.5441]]],
        [[[-0.2787,  0.1836,  0.0984,  ..., -0.0766, -0.1248, -0.7959],
          [-0.6611,  0.1275,  0.1957,  ..., -0.0697, -0.4008, -0.9248],
          [-0.4363,  0.0393,  0.1403,  ..., -0.1402, -0.3217, -0.9141],
          ...,
          [-0.3906,  0.2140,  0.3708,  ...,  0.0718, -0.0080, -0.4523],
          [-0.4593,  0.0579,  0.2492,  ..., -0.1270, -0.6128, -0.5371],
          [-0.5483, -0.2110,  0.1898,  ..., -0.1419, -0.2053, -0.4243]]],
        [[[ 0.0838, -0.0803, -0.0688,  ..., -0.1898, -0.2115, -0.2027],
          [ 0.2890,  0.3870,  0.4222,  ..., -0.3601, -0.3199, -0.2425],
          [ 0.0700,  0.2645,  0.3902,  ..., -0.7617, -1.0000, -0.6934],
          ...,
          [ 0.2911,  0.1484,  0.1081,  ..., -0.4062, -0.0493, -0.2872],
          [ 0.3149,  0.2365,  0.2080,  ..., -0.4654, -0.0778, -0.1984],
          [ 0.1725,  0.1001,  0.2434,  ..., -0.2371,  0.0231, -0.0522]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-3.3043e-01, -3.4193e-01, -9.7795e-02,  ..., -6.4477e-01,
           -6.2678e-01, -7.1457e-01],
          [-3.0721e-01, -2.7495e-01, -2.0185e-01,  ..., -9.2999e-01,
           -6.1911e-01, -6.7941e-01],
          [-2.2231e-02,  2.3159e-01,  2.3919e-01,  ..., -8.2570e-01,
           -8.9583e-01, -1.0000e+00],
          ...,
          [-1.1837e-01, -1.0566e-02,  1.0599e-01,  ..., -5.9788e-01,
           -5.9654e-01, -4.4599e-01],
          [-3.9992e-01, -2.8756e-01,  4.9094e-02,  ..., -8.3773e-01,
           -7.9618e-01, -4.4976e-01],
          [-4.3219e-01, -1.4034e-01,  3.8203e-02,  ..., -9.0913e-01,
           -7.1667e-01, -4.0565e-01]]],
        [[[-5.9556e-01, -6.7094e-02,  3.3031e-01,  ...,  1.6349e-01,
           -1.8583e-02,  1.8347e-01],
          [-8.4041e-01, -3.5748e-01,  5.7280e-02,  ..., -5.2436e-01,
            1.0010e-01,  2.3759e-01],
          [-4.9786e-01,  1.0677e-01,  2.6821e-01,  ..., -3.9395e-01,
            5.3304e-02,  2.8806e-01],
          ...,
          [-3.5956e-01,  2.3703e-01,  1.5946e-01,  ...,  1.2290e-01,
            1.8986e-02,  1.0206e-01],
          [-5.2008e-01, -1.3743e-01, -7.9943e-02,  ...,  1.2383e-01,
           -1.7924e-01,  1.1638e-01],
          [-7.2043e-01, -2.2480e-01, -5.7335e-02,  ...,  2.9488e-01,
           -1.0676e-01,  9.8696e-02]]],
        [[[-6.4535e-01, -4.6976e-01, -4.3243e-01,  ..., -6.2673e-01,
           -5.0753e-01, -4.4236e-01],
          [-5.9466e-01, -6.4535e-01, -6.7253e-01,  ..., -5.7165e-01,
           -6.4808e-01, -4.3150e-01],
          [-4.7420e-01, -4.6997e-01, -5.4518e-01,  ..., -3.8420e-01,
           -3.8013e-01, -3.3973e-01],
          ...,
          [-4.0990e-01, -3.2220e-01, -2.5759e-01,  ..., -3.3111e-01,
           -2.7296e-01, -3.9741e-01],
          [-4.7728e-01, -6.2516e-01, -2.9543e-01,  ..., -5.5967e-01,
           -5.8968e-01, -5.7106e-01],
          [-4.9322e-01, -4.9843e-01, -3.3579e-01,  ..., -4.2240e-01,
           -4.4348e-01, -5.6609e-01]]],
        ...,
        [[[-2.8748e-01, -1.9408e-01, -2.1565e-01,  ..., -5.5000e-01,
           -5.7962e-01, -6.3205e-01],
          [-2.0587e-01, -2.0769e-01, -1.4962e-01,  ..., -5.5460e-01,
           -6.4769e-01, -5.6660e-01],
          [-3.3652e-01, -2.7772e-01, -2.2571e-01,  ..., -5.1295e-01,
           -4.9334e-01, -6.7890e-01],
          ...,
          [ 3.4916e-02, -2.1722e-02, -9.2875e-02,  ..., -6.5797e-01,
           -7.1509e-01, -7.8346e-01],
          [-7.0912e-04,  9.6647e-02, -2.3121e-02,  ..., -7.9094e-01,
           -7.1656e-01, -9.1156e-01],
          [-1.8409e-01, -9.2330e-02, -2.8390e-01,  ..., -4.5949e-01,
           -4.7552e-01, -5.8908e-01]]],
        [[[-6.5300e-01, -3.6711e-02,  3.5089e-01,  ..., -3.3657e-02,
            1.2997e-01, -2.1149e-01],
          [-5.9946e-01, -2.6024e-01,  2.4444e-01,  ..., -1.1801e-01,
            4.1767e-02, -2.2398e-01],
          [-6.6524e-01, -3.1224e-01, -1.1618e-01,  ..., -7.4310e-02,
           -2.9946e-01, -4.0162e-01],
          ...,
          [-8.3277e-01, -5.5099e-01, -4.0577e-01,  ...,  2.0105e-01,
            2.4656e-01, -9.2241e-02],
          [-5.2866e-01, -6.5704e-02, -1.4073e-01,  ...,  9.2694e-02,
            3.0645e-01, -1.2682e-01],
          [-5.6066e-01,  9.3615e-02,  1.1677e-01,  ...,  3.1990e-01,
            2.7434e-02, -2.4464e-01]]],
        [[[-1.0000e+00, -3.9428e-01, -1.2464e-01,  ...,  3.2248e-01,
            5.1050e-01,  5.4823e-01],
          [-7.5988e-01, -2.5167e-01,  1.3785e-01,  ...,  3.8439e-01,
            3.0577e-01,  5.2178e-01],
          [-5.1187e-01, -1.1661e-01,  9.6806e-02,  ...,  1.9511e-01,
            2.0130e-01,  4.1082e-01],
          ...,
          [-6.5915e-01, -2.0105e-01,  2.0211e-02,  ...,  2.3117e-01,
            4.0698e-01,  2.9850e-01],
          [-6.7157e-01, -6.8849e-02,  6.3509e-02,  ...,  1.5977e-01,
            4.3170e-01,  4.6423e-01],
          [-6.0550e-01,  2.8973e-02,  2.2499e-01,  ...,  8.2476e-02,
            2.9298e-01,  4.2375e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-2.9439e-01, -1.7110e-02,  5.4313e-02,  ..., -3.1608e-01,
           -3.5126e-01, -2.5706e-01],
          [ 1.0654e-01,  1.9114e-02, -1.0795e-02,  ..., -3.3916e-01,
           -3.1168e-01, -3.0845e-01],
          [ 3.9278e-01,  2.0022e-01, -8.6478e-02,  ..., -3.0148e-01,
           -4.0810e-01, -3.7913e-01],
          ...,
          [-2.3620e-01,  8.4061e-02, -7.3623e-02,  ..., -7.1233e-01,
           -5.3993e-01, -2.8432e-01],
          [ 1.1512e-02,  9.5901e-02,  9.0399e-02,  ..., -4.5646e-01,
           -5.9540e-01, -2.1999e-01],
          [-1.6477e-01,  9.6514e-02,  1.2122e-01,  ..., -4.7856e-01,
           -3.8942e-01, -1.6040e-01]]],
        [[[-2.4596e-01, -4.1230e-01, -4.2092e-01,  ..., -2.1293e-01,
           -5.7602e-01, -5.9240e-01],
          [-4.5525e-01, -5.5463e-01, -6.2991e-01,  ..., -3.7092e-01,
           -3.5094e-01, -3.1802e-01],
          [-2.3304e-03, -4.1194e-02, -2.3730e-01,  ..., -9.3550e-02,
           -2.9957e-01, -2.5616e-01],
          ...,
          [-1.9760e-01, -2.2637e-01, -3.0302e-01,  ...,  1.4336e-01,
            1.4565e-01, -8.3931e-03],
          [-1.9068e-01, -1.1236e-01, -7.1296e-02,  ...,  3.6046e-01,
            1.3846e-01,  2.0126e-01],
          [-1.3516e-01, -1.6906e-01, -4.0740e-01,  ...,  6.1389e-01,
            2.8670e-01, -1.3650e-02]]],
        [[[-4.3053e-01, -4.5243e-01, -4.2629e-01,  ..., -4.7813e-01,
           -6.8859e-01, -8.0091e-01],
          [-3.4709e-01, -3.3490e-01, -4.7366e-01,  ..., -6.2980e-01,
           -7.0400e-01, -9.7472e-01],
          [-4.3762e-01, -4.6424e-01, -2.6117e-01,  ..., -8.2051e-01,
           -7.8174e-01, -9.6491e-01],
          ...,
          [-2.1346e-01, -8.0991e-02, -1.8585e-01,  ..., -5.0242e-01,
           -5.0912e-01, -6.4234e-01],
          [-9.6685e-02, -5.2102e-02, -1.2339e-01,  ..., -5.9758e-01,
           -5.1706e-01, -5.8406e-01],
          [-1.0805e-01, -3.2804e-01, -2.5865e-01,  ..., -8.9109e-01,
           -6.8303e-01, -5.6175e-01]]],
        ...,
        [[[-6.4312e-01, -4.3267e-01, -3.8647e-01,  ...,  1.3020e-01,
           -1.6338e-01, -4.5471e-02],
          [-7.3450e-01, -6.5978e-01, -6.7445e-01,  ...,  3.8522e-02,
           -1.1225e-01, -2.3571e-01],
          [-6.5409e-01, -6.8927e-01, -1.0000e+00,  ..., -3.7041e-02,
           -1.5204e-01, -1.5636e-01],
          ...,
          [-2.6309e-01,  7.1689e-02,  6.6579e-02,  ...,  1.9704e-01,
            5.1023e-01,  4.9146e-01],
          [-5.5586e-01,  1.3642e-03,  1.1329e-01,  ..., -1.1730e-01,
            2.5383e-01,  3.7178e-01],
          [-5.7976e-01, -1.8404e-01, -2.7714e-01,  ..., -3.6868e-01,
           -1.4594e-01, -3.4327e-02]]],
        [[[-3.8367e-01, -3.2481e-01, -2.2231e-01,  ..., -8.4103e-01,
           -4.5332e-01, -2.8855e-01],
          [-4.8882e-01, -1.6676e-01, -2.7382e-01,  ..., -7.7311e-01,
           -6.4840e-01, -5.0294e-01],
          [-5.5080e-01, -4.0779e-01, -2.2901e-01,  ..., -5.0524e-01,
           -4.3415e-01, -3.6569e-01],
          ...,
          [-5.9344e-01, -2.6942e-01, -2.5822e-01,  ..., -4.5608e-01,
           -2.5575e-01, -1.9283e-01],
          [-4.5199e-01, -2.0213e-01, -3.6113e-01,  ..., -7.9096e-01,
           -5.1649e-01, -2.6959e-01],
          [-5.9259e-01, -2.5347e-01, -1.2036e-01,  ..., -5.9724e-01,
           -7.7004e-01, -4.9420e-01]]],
        [[[-6.5676e-01,  2.4982e-01,  6.0728e-01,  ..., -2.1841e-01,
           -2.1560e-01,  4.7917e-01],
          [-5.5561e-01,  5.8831e-02,  4.4660e-01,  ...,  1.0933e-01,
           -1.2449e-01,  4.7964e-01],
          [-2.7191e-01,  1.9617e-01,  4.2615e-01,  ...,  1.7867e-01,
           -2.6271e-01,  4.6600e-01],
          ...,
          [-3.1580e-01, -1.2807e-01, -5.7410e-02,  ..., -9.1778e-02,
           -6.1247e-02,  4.8113e-01],
          [-5.6759e-01, -3.2425e-01,  1.0700e-02,  ...,  5.8629e-02,
           -2.4412e-01,  4.7346e-01],
          [-4.1663e-01, -5.3245e-04,  2.5270e-01,  ...,  7.4300e-02,
           -2.6778e-02,  4.7873e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.4524, -0.0520,  0.1288,  ...,  0.0256,  0.0305, -0.6351],
          [-0.3710,  0.1033,  0.0446,  ...,  0.0577,  0.0157, -0.8012],
          [-0.3967,  0.0788,  0.0338,  ..., -0.1010, -0.0295, -0.6944],
          ...,
          [-0.6562,  0.0612,  0.3821,  ..., -0.1041, -0.1988, -0.7642],
          [-0.4310,  0.0974,  0.2202,  ..., -0.0391, -0.1240, -0.7215],
          [-0.3688,  0.1413,  0.2841,  ..., -0.1941, -0.2468, -0.7812]]],
        [[[-0.5266, -0.3886, -0.3454,  ...,  0.0028,  0.3360, -0.0159],
          [-0.1284, -0.0187, -0.0717,  ...,  0.2420,  0.5245,  0.2169],
          [ 0.6406,  0.7655,  0.7093,  ...,  0.1828,  0.5559,  0.3020],
          ...,
          [-0.4492, -0.2169, -0.2538,  ..., -0.2954, -0.4425, -0.3877],
          [-0.5944, -0.4204, -0.3464,  ..., -0.6697, -0.4153, -0.3834],
          [-0.7062, -0.2665, -0.5213,  ..., -0.6963, -0.6314, -0.5087]]],
        [[[-0.6811, -0.2007, -0.0966,  ..., -0.4133, -0.5277, -0.6967],
          [-0.6511, -0.3971, -0.1977,  ..., -0.3267, -0.7867, -0.6398],
          [-0.5846, -0.2134, -0.0480,  ..., -0.2906, -0.7381, -0.5925],
          ...,
          [-0.8055, -0.1794, -0.0392,  ..., -0.5834, -0.4695, -0.6629],
          [-1.0000, -0.2693, -0.0103,  ..., -0.5274, -0.8451, -0.5614],
          [-0.8551, -0.2819, -0.2056,  ..., -0.4440, -0.7934, -0.6266]]],
        ...,
        [[[-0.5022,  0.0304, -0.0964,  ..., -0.1890, -0.2901, -0.4088],
          [-0.6316,  0.0723, -0.0238,  ..., -0.1115, -0.2533, -0.3120],
          [-0.6838,  0.1060,  0.2316,  ...,  0.0998, -0.1361, -0.4320],
          ...,
          [-0.7675, -0.1035,  0.2199,  ...,  0.1759,  0.1594, -0.3551],
          [-0.8305,  0.0196,  0.3239,  ...,  0.2615,  0.0731, -0.5102],
          [-0.7877,  0.0927,  0.3672,  ..., -0.0567, -0.0461, -0.3937]]],
        [[[-0.4096, -0.1240, -0.0565,  ...,  0.0627, -0.0465, -0.0717],
          [-0.7126, -0.1565,  0.3196,  ...,  0.1777, -0.0940, -0.0567],
          [-0.6303, -0.0573,  0.2920,  ...,  0.2370, -0.0998, -0.0808],
          ...,
          [-0.6331, -0.1562,  0.1869,  ...,  0.2460,  0.0881, -0.0368],
          [-0.6749, -0.2757,  0.0724,  ...,  0.0766,  0.1501, -0.0013],
          [-0.4712,  0.0356,  0.0379,  ..., -0.0491, -0.1058, -0.0689]]],
        [[[-0.7094, -0.1239,  0.2424,  ...,  0.4974,  0.4176, -0.2009],
          [-0.8808, -0.0747,  0.1358,  ...,  0.3419,  0.3867, -0.2911],
          [-0.8773, -0.1638,  0.2531,  ...,  0.3216,  0.2344, -0.4010],
          ...,
          [-0.6570,  0.1487,  0.3771,  ...,  0.1638,  0.2002, -0.0578],
          [-0.7446, -0.0057,  0.3975,  ..., -0.3057, -0.2289, -0.4213],
          [-0.5497, -0.0045,  0.3511,  ...,  0.1587, -0.3052, -0.4983]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-6.1348e-01, -1.8678e-01, -9.7158e-02,  ...,  3.2850e-01,
            5.1481e-02, -1.8905e-01],
          [-8.0326e-01, -3.8033e-02, -1.0483e-01,  ...,  1.9932e-01,
            8.5144e-02, -1.9169e-01],
          [-4.4896e-01,  8.6155e-02, -1.3860e-02,  ...,  3.2134e-01,
           -8.6609e-02, -1.7985e-01],
          ...,
          [-4.5369e-01,  1.0049e-02, -1.0829e-01,  ...,  2.4010e-01,
            2.0919e-01, -7.0063e-02],
          [-4.0472e-01,  8.0541e-02,  1.1319e-01,  ...,  3.7203e-02,
            4.7873e-02, -1.3761e-01],
          [-4.4384e-01,  3.7132e-01,  6.2816e-01,  ..., -7.6684e-02,
            9.3609e-02, -5.6964e-02]]],
        [[[-3.1848e-01, -3.0691e-02,  3.3650e-01,  ...,  3.4174e-01,
            2.4058e-02,  4.5787e-01],
          [-7.9482e-01, -3.4691e-01,  2.8071e-01,  ...,  4.3171e-01,
            5.0651e-02,  5.1538e-01],
          [-6.2413e-01, -3.0175e-01,  1.7306e-02,  ...,  3.4802e-01,
            1.2864e-01,  4.8526e-01],
          ...,
          [-2.5213e-01,  3.2869e-01,  4.4225e-01,  ...,  3.7005e-01,
           -2.0676e-01,  4.8668e-01],
          [-5.1514e-01,  1.8864e-01,  5.9494e-01,  ...,  4.2052e-01,
            2.8435e-02,  5.1352e-01],
          [-3.0256e-01,  3.4395e-01,  3.8104e-01,  ...,  3.2382e-01,
            8.0696e-02,  5.0715e-01]]],
        [[[ 1.4401e-02,  2.6546e-01,  3.6920e-01,  ..., -2.3745e-01,
           -2.8284e-01, -5.1569e-01],
          [-2.6839e-01,  2.9941e-01,  4.8628e-01,  ..., -1.4951e-01,
           -3.1558e-01, -6.0471e-01],
          [-1.7381e-01,  2.9182e-01,  4.3428e-01,  ...,  9.4537e-02,
           -1.7878e-01, -5.4101e-01],
          ...,
          [ 3.0702e-01,  4.3063e-01,  2.0226e-01,  ..., -3.6050e-01,
           -5.8535e-01, -9.1788e-01],
          [ 3.8771e-01,  5.0876e-01,  3.4428e-01,  ..., -2.2961e-01,
           -3.6510e-01, -5.0468e-01],
          [ 4.2004e-01,  3.2852e-01,  2.9141e-01,  ..., -1.0169e-01,
           -1.7240e-01, -5.0093e-01]]],
        ...,
        [[[-7.3747e-01,  1.7353e-02, -2.1769e-02,  ...,  1.4686e-01,
           -1.3671e-02, -5.1980e-01],
          [-8.7690e-01, -3.0445e-01,  5.0104e-02,  ..., -6.1906e-02,
           -4.3406e-01, -7.8245e-01],
          [-8.9173e-01, -2.3553e-01,  1.8565e-01,  ..., -2.6213e-01,
           -3.0193e-01, -6.4563e-01],
          ...,
          [-3.6952e-01, -7.7761e-02, -6.0941e-02,  ...,  5.5886e-02,
           -2.8649e-01, -8.1331e-01],
          [-5.0499e-01, -1.2701e-01,  9.6519e-02,  ...,  4.1374e-02,
           -3.2493e-01, -6.1671e-01],
          [-8.3756e-01, -3.5430e-01,  1.1409e-01,  ..., -5.6630e-02,
           -3.1106e-01, -3.8425e-01]]],
        [[[-4.7236e-01, -4.3649e-01, -4.1953e-01,  ..., -3.0139e-01,
           -5.2488e-01, -2.9706e-01],
          [-6.8986e-01, -6.9406e-01, -4.4655e-01,  ..., -3.6510e-01,
           -5.2957e-01, -3.6507e-01],
          [-1.0000e+00, -6.1529e-01, -3.2708e-01,  ..., -6.3352e-01,
           -5.3464e-01, -5.7182e-01],
          ...,
          [-3.1108e-01, -2.7612e-01, -4.0693e-01,  ..., -4.8833e-01,
           -5.0102e-01, -2.5615e-01],
          [-5.1189e-01, -4.8024e-01, -2.5527e-01,  ..., -4.0725e-01,
           -4.3242e-01, -2.2808e-01],
          [-6.9273e-01, -5.6112e-01, -3.1013e-01,  ..., -5.0252e-01,
           -5.7824e-01, -3.0582e-01]]],
        [[[ 4.6376e-01,  3.4613e-01,  5.6577e-04,  ..., -5.1256e-01,
           -6.2370e-01, -6.4173e-01],
          [ 1.9330e-01,  5.7161e-01,  4.7516e-01,  ..., -4.0833e-01,
           -1.9025e-01, -3.9857e-01],
          [ 4.1015e-01,  5.1080e-01,  3.5910e-01,  ..., -1.9574e-01,
           -1.1503e-02, -4.4161e-01],
          ...,
          [ 4.4721e-01,  1.8903e-02, -3.1358e-01,  ..., -4.7249e-01,
           -4.8066e-02,  1.9827e-01],
          [ 7.8182e-02,  9.1293e-02, -1.4618e-01,  ..., -5.1524e-01,
           -2.4547e-01,  2.4113e-01],
          [ 2.0309e-01,  4.5940e-01,  2.2453e-01,  ..., -9.2433e-01,
           -3.9214e-01,  4.7086e-02]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.3927,  0.1148,  0.3072,  ...,  0.0788, -0.0731, -0.4764],
          [-0.4560,  0.0175,  0.1709,  ...,  0.1494, -0.0821, -0.8572],
          [-0.5962, -0.1152,  0.2576,  ..., -0.1154, -0.2279, -0.5923],
          ...,
          [-0.3219,  0.1943,  0.3882,  ..., -0.2418, -0.4111, -1.0000],
          [-0.4997, -0.0664,  0.2845,  ...,  0.0437, -0.3445, -0.5673],
          [-0.3497, -0.0808, -0.1348,  ...,  0.1776,  0.0293, -0.4141]]],
        [[[-0.3278,  0.2101,  0.2117,  ...,  0.2385, -0.0644, -0.0718],
          [-0.5680,  0.1193, -0.0437,  ...,  0.2761, -0.0741, -0.0685],
          [-0.4740,  0.1231,  0.1696,  ...,  0.1455, -0.1282, -0.0449],
          ...,
          [-0.2308,  0.0755,  0.4128,  ..., -0.0469, -0.2638, -0.0760],
          [-0.2831, -0.0076,  0.4030,  ...,  0.0689, -0.2964, -0.0545],
          [-0.3502, -0.0612,  0.3662,  ...,  0.1401, -0.1715, -0.0670]]],
        [[[-0.6243, -0.1352, -0.1705,  ..., -0.4775, -0.6653, -0.7396],
          [-0.5145, -0.1445, -0.1827,  ..., -0.5169, -0.6592, -0.6410],
          [-0.3924, -0.0958,  0.0438,  ..., -0.3519, -0.5728, -0.6668],
          ...,
          [-0.3434,  0.0089,  0.0540,  ..., -0.2687, -0.4498, -0.7155],
          [-0.4563, -0.0175,  0.1819,  ..., -0.2643, -0.3895, -0.5849],
          [-0.6777, -0.3324,  0.2027,  ..., -0.3281, -0.4580, -0.5831]]],
        ...,
        [[[-0.4461,  0.0328, -0.0069,  ..., -0.0963, -0.0048, -0.1730],
          [-0.3762,  0.0412, -0.0185,  ..., -0.1084, -0.0183, -0.4674],
          [-0.6001, -0.1047,  0.2221,  ..., -0.4195, -0.2674, -0.2640],
          ...,
          [-0.3893,  0.0261,  0.3363,  ..., -0.0795, -0.0223, -0.1155],
          [-0.3831, -0.1040,  0.3070,  ..., -0.1480, -0.2038, -0.2986],
          [-0.3500,  0.2548,  0.5990,  ..., -0.3323, -0.3758, -0.3419]]],
        [[[-0.5170, -0.2167,  0.0235,  ...,  0.2624,  0.0913, -0.0869],
          [-0.7479, -0.2302, -0.0684,  ...,  0.3650,  0.2478, -0.1649],
          [-0.5741, -0.1494, -0.0801,  ...,  0.4421,  0.1847, -0.3776],
          ...,
          [-0.9333, -0.3546,  0.0158,  ...,  0.2227,  0.0860, -0.1764],
          [-0.8583, -0.4717, -0.0744,  ...,  0.0468,  0.0750, -0.1438],
          [-0.9868, -0.2710, -0.1007,  ...,  0.0955,  0.0050, -0.3414]]],
        [[[ 0.1899,  0.2552,  0.2726,  ...,  0.2358,  0.0309, -0.4770],
          [ 0.0843,  0.3774,  0.6371,  ...,  0.2049, -0.0129, -0.4331],
          [-0.1174,  0.3864,  0.6169,  ...,  0.0728, -0.0968, -0.4478],
          ...,
          [-0.2663, -0.5340,  0.1576,  ..., -0.1354,  0.0599, -0.0276],
          [-0.2286, -0.2759,  0.1650,  ..., -0.0213,  0.2164,  0.0397],
          [-0.4147, -0.0672,  0.0613,  ..., -0.0773, -0.0581, -0.2202]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-2.7248e-01,  1.4639e-01,  1.3365e-01,  ..., -4.3985e-01,
           -4.6763e-01, -2.8978e-01],
          [ 7.2387e-02,  2.3998e-01,  2.9337e-01,  ..., -6.2853e-01,
           -5.5883e-01, -7.5210e-02],
          [ 1.0761e-01,  4.2468e-02, -4.4429e-02,  ..., -6.7613e-01,
           -4.3445e-01,  1.6577e-02],
          ...,
          [-7.4636e-02,  1.4950e-02, -2.9896e-02,  ..., -1.8372e-01,
           -1.8535e-01,  2.0042e-01],
          [-1.4955e-01, -1.7352e-02,  2.0385e-01,  ..., -1.3467e-01,
           -1.2708e-01,  4.9676e-02],
          [-3.4573e-01, -1.0809e-01,  1.0218e-01,  ..., -5.0029e-01,
           -7.2323e-02,  1.4049e-01]]],
        [[[-5.0318e-01, -7.8774e-02,  6.9170e-03,  ...,  3.7702e-01,
            6.0718e-01,  4.8152e-01],
          [-5.2326e-01, -5.9378e-02, -6.9062e-03,  ...,  4.0181e-01,
            5.6197e-01,  3.1555e-01],
          [-5.4651e-01, -6.1858e-02,  2.0865e-01,  ...,  4.0036e-02,
            3.9722e-01,  1.5969e-01],
          ...,
          [-6.4481e-01, -2.5625e-01,  1.3318e-01,  ...,  2.9578e-01,
            4.6782e-01,  3.7154e-01],
          [-7.5538e-01, -1.4666e-01,  2.0611e-04,  ...,  9.2672e-02,
            4.0037e-01,  3.3183e-01],
          [-8.7294e-01, -1.1800e-01,  1.3751e-01,  ...,  5.9941e-02,
            4.8250e-01,  3.8526e-01]]],
        [[[-4.7660e-01, -2.0488e-01, -1.0265e-01,  ...,  6.8037e-01,
            2.0338e-01, -6.2599e-01],
          [-1.8222e-01,  8.0055e-02, -5.9251e-03,  ...,  6.4781e-01,
            3.7613e-01, -3.6862e-01],
          [-3.3993e-01, -1.3727e-01, -1.5015e-01,  ...,  6.1935e-01,
            1.8821e-01, -3.1869e-01],
          ...,
          [-6.4049e-01, -5.6417e-01, -6.2715e-01,  ...,  3.1876e-01,
           -1.4485e-01, -8.5000e-01],
          [-4.5187e-01, -4.8289e-01, -4.5559e-01,  ...,  2.3247e-01,
           -1.3317e-01, -7.4150e-01],
          [-2.2234e-01, -4.3598e-01, -4.8396e-01,  ...,  1.6521e-01,
           -1.7782e-01, -5.7255e-01]]],
        ...,
        [[[-5.9166e-01, -3.6068e-02,  1.6273e-01,  ...,  1.3275e-01,
            2.3337e-02, -1.6619e-01],
          [-6.8803e-01, -3.4294e-01, -5.1605e-02,  ...,  2.8665e-01,
            2.0095e-01, -2.0610e-01],
          [-9.1492e-01, -3.2488e-01,  1.7183e-02,  ...,  2.6361e-01,
            2.6714e-01, -2.1597e-01],
          ...,
          [-3.1864e-01,  1.1584e-01,  1.8576e-01,  ..., -2.4321e-02,
           -2.9700e-01, -4.2266e-01],
          [-4.3545e-01,  8.8725e-02,  2.0002e-01,  ..., -4.1294e-02,
           -3.3483e-02, -3.1581e-01],
          [-5.4558e-01, -6.5326e-02, -1.3913e-02,  ...,  1.8463e-03,
            1.4817e-03, -3.9062e-01]]],
        [[[ 3.1106e-01,  2.0023e-01,  2.1022e-02,  ...,  7.3901e-03,
           -7.4723e-03,  1.4769e-01],
          [ 2.8081e-01,  3.0342e-02,  1.0225e-01,  ..., -1.7007e-01,
            3.6304e-02,  1.6871e-01],
          [-4.7176e-02,  1.2015e-01,  1.3816e-01,  ...,  5.1176e-02,
            1.4189e-01, -7.9440e-03],
          ...,
          [-1.5981e-01,  1.5606e-02,  1.6754e-01,  ..., -4.1298e-01,
           -4.6468e-01, -8.8962e-01],
          [-7.5840e-02,  1.2500e-01,  1.5582e-01,  ..., -6.2182e-01,
           -5.7458e-01, -6.3873e-01],
          [-3.3074e-03,  3.3037e-02, -8.0520e-03,  ..., -4.4822e-01,
           -7.3009e-01, -5.9316e-01]]],
        [[[-4.7208e-01, -2.2692e-01, -2.4449e-01,  ...,  3.8052e-01,
            3.0842e-01, -1.7943e-01],
          [-6.1409e-01, -2.7660e-01, -1.7833e-01,  ...,  3.3340e-01,
            1.1020e-01, -4.3913e-01],
          [-9.4394e-01, -2.7664e-01, -4.1140e-02,  ...,  1.3993e-01,
           -6.3255e-02, -3.9611e-01],
          ...,
          [-8.7394e-01, -2.9487e-02,  1.0191e-01,  ...,  1.3034e-01,
            1.9724e-02, -3.3677e-01],
          [-5.8391e-01, -5.0713e-03,  8.2650e-02,  ..., -3.6565e-02,
           -1.0985e-01, -3.9108e-01],
          [-5.7485e-01, -8.4043e-02, -8.2862e-02,  ..., -1.7765e-01,
           -1.0043e-01, -3.2954e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-4.0702e-01, -1.0825e-01, -4.1108e-03,  ...,  5.0070e-01,
            1.1353e-01, -6.6347e-01],
          [-3.9713e-01, -1.9471e-02,  1.7742e-01,  ...,  4.4226e-01,
            2.7209e-01, -3.0793e-01],
          [-5.3938e-01, -2.8001e-01,  7.7345e-02,  ...,  2.0323e-01,
            2.8309e-01, -3.0139e-01],
          ...,
          [-7.1875e-01, -1.0169e-01,  2.1061e-01,  ...,  4.6845e-01,
            6.9219e-02, -3.0965e-01],
          [-5.3264e-01,  1.8756e-02,  2.6760e-01,  ...,  3.5644e-01,
            2.3941e-01, -3.0617e-01],
          [-5.2674e-01, -1.0433e-01,  1.0573e-01,  ...,  4.3675e-01,
            1.3200e-01, -2.9206e-01]]],
        [[[-7.4653e-01, -5.0804e-01, -6.2992e-01,  ..., -8.4652e-01,
           -5.1290e-01, -3.7077e-01],
          [-5.3160e-01, -2.1498e-01, -5.0815e-01,  ..., -4.5425e-01,
           -5.0104e-01, -3.9631e-01],
          [-3.5344e-01, -1.1654e-01, -2.5955e-01,  ..., -5.3352e-01,
           -6.0349e-01, -3.7873e-01],
          ...,
          [-4.4402e-01, -4.4383e-01, -3.4710e-01,  ..., -8.0386e-01,
           -7.0021e-01, -4.8120e-01],
          [-4.8712e-01, -2.7699e-01, -2.3736e-01,  ..., -9.9521e-01,
           -8.5739e-01, -4.2737e-01],
          [-5.2015e-01, -1.8544e-01, -2.7894e-01,  ..., -7.3881e-01,
           -7.9151e-01, -3.6656e-01]]],
        [[[-3.9004e-02,  1.0795e-01,  1.1065e-01,  ..., -1.5303e-01,
            1.1839e-01,  2.4956e-01],
          [-2.1311e-01, -1.6578e-02, -6.2736e-02,  ..., -1.0480e-01,
           -2.3716e-02,  9.1044e-02],
          [-7.0881e-01, -4.6705e-01, -3.3027e-01,  ..., -1.9073e-01,
           -2.8011e-01, -2.0538e-01],
          ...,
          [-3.2886e-01,  7.4839e-02,  2.1113e-01,  ...,  7.6030e-02,
            4.4525e-04,  1.0882e-01],
          [-5.3365e-01, -1.5096e-01, -6.7378e-02,  ..., -9.7394e-02,
            7.6879e-02,  1.6648e-01],
          [-7.6178e-01, -5.5319e-01, -5.6644e-01,  ..., -3.0964e-01,
           -1.4579e-01,  2.3657e-03]]],
        ...,
        [[[-7.1821e-01,  1.5871e-01,  5.3294e-01,  ...,  3.3380e-01,
            1.3249e-01, -1.7518e-01],
          [-7.4998e-01,  2.1997e-01,  4.3528e-01,  ...,  6.0072e-02,
           -5.3918e-02, -1.8893e-01],
          [-6.4106e-01,  2.2452e-02,  1.8084e-01,  ...,  7.5425e-02,
            5.4020e-02, -5.0191e-02],
          ...,
          [-7.9745e-01,  1.0975e-01,  2.0999e-01,  ..., -2.9633e-02,
            1.1548e-01,  1.0088e-01],
          [-7.3522e-01,  8.8143e-02,  2.4149e-01,  ..., -1.2467e-01,
           -7.5288e-02, -2.0659e-04],
          [-8.5275e-01,  5.8155e-02,  2.1026e-01,  ..., -1.2396e-02,
            2.4655e-02, -3.9090e-01]]],
        [[[-6.3176e-01, -2.3301e-01,  3.5187e-01,  ...,  4.9238e-01,
            2.1555e-01, -1.3079e-01],
          [-8.9317e-01, -4.4911e-01,  1.4697e-01,  ...,  5.4115e-01,
            2.3848e-01, -2.2185e-01],
          [-7.8929e-01, -2.9961e-01, -1.3933e-01,  ...,  4.6514e-01,
            4.0577e-01, -7.8647e-02],
          ...,
          [-7.1665e-01, -1.7873e-01,  1.2824e-01,  ...,  3.8215e-02,
           -3.5540e-01, -3.6819e-01],
          [-8.6031e-01, -2.9254e-01, -9.8508e-02,  ...,  1.3204e-01,
           -1.3157e-01, -2.4419e-01],
          [-9.1858e-01, -3.2749e-01, -1.2593e-02,  ...,  1.6112e-01,
           -3.4251e-03, -1.9241e-01]]],
        [[[-7.7482e-01, -2.1893e-01,  1.6478e-01,  ..., -9.9932e-02,
           -3.6777e-01, -7.6178e-01],
          [-7.8743e-01, -3.7351e-01,  1.6029e-01,  ...,  6.5296e-02,
           -5.0789e-01, -9.1965e-01],
          [-6.1833e-01, -1.8486e-01,  2.7404e-01,  ...,  2.6147e-03,
           -4.3676e-01, -8.5893e-01],
          ...,
          [-5.6478e-01,  1.7660e-02,  3.2212e-01,  ..., -3.4864e-02,
           -8.3302e-02, -6.8837e-01],
          [-6.7351e-01, -4.0622e-02,  1.4384e-01,  ...,  2.3559e-01,
            1.0363e-01, -5.3044e-01],
          [-3.8695e-01,  1.0804e-01,  1.7352e-01,  ...,  1.2726e-01,
            1.9729e-02, -6.9609e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([128, 1, 36, 40])
input tensor POST:  torch.Size([128, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([128, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-4.8396e-01, -6.6736e-02,  4.0176e-02,  ...,  1.0406e-01,
            2.5228e-01, -3.2154e-02],
          [-3.7395e-01,  9.1022e-02,  1.6006e-01,  ...,  3.1929e-01,
            2.3838e-01,  5.6553e-02],
          [-5.4682e-01,  5.1834e-02,  2.3257e-01,  ...,  4.2815e-01,
            2.6670e-02, -7.7460e-02],
          ...,
          [-4.9133e-01, -7.7227e-02, -2.8822e-01,  ...,  4.1554e-01,
            1.0015e-01, -3.5838e-02],
          [-3.6386e-01, -5.8405e-02,  3.5456e-03,  ...,  4.9493e-01,
            3.0027e-01, -1.3245e-01],
          [-3.6671e-01, -2.5348e-01,  3.8722e-02,  ...,  4.7305e-01,
            4.0186e-01, -9.5066e-02]]],
        [[[-8.2265e-01, -1.6745e-01,  1.3662e-01,  ...,  9.8905e-02,
           -3.9803e-02, -5.1662e-01],
          [-6.8332e-01, -2.6791e-01, -7.4301e-02,  ..., -1.1140e-02,
           -1.6936e-01, -5.4688e-01],
          [-6.8391e-01, -2.2348e-01, -5.4187e-04,  ..., -1.0458e-01,
           -1.4137e-01, -4.1761e-01],
          ...,
          [-4.6491e-01, -2.9392e-02,  2.0853e-01,  ..., -2.4579e-01,
           -1.7225e-01, -2.8535e-01],
          [-3.6313e-01, -7.2333e-02, -1.1699e-02,  ..., -4.0351e-02,
           -7.1729e-02, -2.4307e-01],
          [-3.8279e-01, -2.1226e-02,  4.0471e-02,  ..., -5.3640e-02,
           -1.6062e-01, -3.0541e-01]]],
        [[[-5.9140e-01, -2.5475e-01, -2.6319e-01,  ...,  1.5963e-01,
            1.7884e-02, -2.4669e-01],
          [-6.0683e-01, -3.1011e-01, -1.8190e-01,  ..., -6.5381e-02,
           -4.0838e-01, -3.8423e-01],
          [-6.1818e-01, -2.7693e-01, -1.7604e-01,  ...,  1.7083e-01,
            9.2799e-02, -3.1052e-01],
          ...,
          [-7.9374e-01, -4.8532e-01,  1.0265e-02,  ...,  3.7349e-01,
           -4.5000e-02, -3.5971e-01],
          [-5.0232e-01, -3.2845e-01, -8.3862e-02,  ...,  3.0128e-01,
           -9.7483e-02, -2.3503e-01],
          [-4.6772e-01, -2.0591e-01, -1.9005e-01,  ...,  4.5043e-01,
            2.5321e-01, -9.4937e-02]]],
        ...,
        [[[-4.5060e-01,  1.9406e-01,  2.3842e-01,  ..., -8.6268e-02,
           -1.4767e-01,  1.5613e-01],
          [-5.4386e-01,  5.4214e-02,  4.0892e-01,  ..., -2.7940e-01,
           -1.5616e-01,  1.5194e-01],
          [-5.3541e-01,  9.6067e-02,  4.7686e-01,  ..., -2.4237e-01,
           -3.0145e-01,  1.2546e-01],
          ...,
          [ 8.6933e-02,  7.2162e-01,  9.4161e-01,  ..., -2.0006e-01,
           -1.3005e-01,  1.7133e-01],
          [-3.0127e-01,  3.5964e-01,  6.8994e-01,  ...,  1.5448e-02,
           -9.7936e-02,  8.7869e-02],
          [-5.6617e-02,  2.7015e-01,  5.6400e-01,  ..., -4.3774e-02,
           -2.1482e-01,  1.6088e-01]]],
        [[[-3.3996e-01,  3.8270e-01,  4.1886e-01,  ..., -3.1179e-01,
           -4.3743e-01, -6.0033e-01],
          [-1.3917e-01,  3.4830e-01,  1.2675e-01,  ..., -1.0668e-01,
           -3.4251e-01, -5.1634e-01],
          [-9.8254e-02,  3.5151e-01,  2.6945e-01,  ..., -8.0909e-02,
           -2.6111e-01, -7.3721e-01],
          ...,
          [-5.0107e-01,  3.6489e-01,  6.0392e-01,  ...,  6.2487e-03,
           -2.5624e-01, -6.5546e-01],
          [-8.0493e-02,  2.8151e-01,  3.4191e-01,  ..., -2.9164e-01,
           -3.6334e-01, -5.8748e-01],
          [-8.5564e-02,  4.0441e-01,  4.0381e-01,  ..., -5.3786e-01,
           -2.0899e-01, -3.9657e-01]]],
        [[[-3.4106e-01, -3.2123e-01, -5.4380e-01,  ..., -7.6405e-01,
           -5.5075e-01, -5.5021e-01],
          [-4.3339e-01, -2.7199e-01, -3.4933e-01,  ..., -6.6080e-01,
           -7.0336e-01, -6.8347e-01],
          [-3.1192e-01, -1.3408e-01, -1.1318e-01,  ..., -6.9681e-01,
           -6.7221e-01, -5.0920e-01],
          ...,
          [-2.0876e-01, -1.6693e-01, -4.5430e-01,  ..., -3.2351e-01,
           -5.0497e-01, -4.1544e-01],
          [-4.0087e-01, -1.5986e-01, -1.9731e-01,  ..., -3.4071e-01,
           -5.2735e-01, -4.3245e-01],
          [-3.5936e-01, -2.6833e-01, -3.7461e-01,  ..., -5.6390e-01,
           -7.0193e-01, -4.7992e-01]]]])
encoded_tensor.size: torch.Size([128, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
input tensor PRE:  torch.Size([83, 1, 36, 40])
input tensor POST:  torch.Size([83, 36, 1, 40])
input tensor AFTER TRANSPOSE:  torch.Size([83, 1, 36, 40])
input tensor AFTER TRANSPOSE:  tensor([[[[-0.5575, -0.2551, -0.3033,  ...,  0.3949, -0.0566,  0.2150],
          [-0.5268,  0.0105,  0.0388,  ...,  0.3264,  0.1829,  0.2901],
          [-0.5225,  0.0303,  0.1144,  ..., -0.0045,  0.1192,  0.2533],
          ...,
          [-0.3615, -0.0639,  0.4168,  ...,  0.7201,  0.4877,  0.4119],
          [-0.1905,  0.3109,  0.5202,  ...,  0.6004,  0.3624,  0.2981],
          [-0.2454,  0.3800,  0.4411,  ...,  0.4472,  0.3315,  0.6048]]],
        [[[-0.1610, -0.1486,  0.0765,  ..., -0.0077, -0.3835, -0.7023],
          [-0.4728, -0.2831, -0.2156,  ..., -0.3880, -0.7533, -0.5852],
          [-0.4891, -0.1624, -0.2801,  ..., -0.8071, -1.0000, -0.6883],
          ...,
          [-0.0991, -0.2694, -0.2012,  ..., -0.4690, -0.2840, -0.2981],
          [-0.2380, -0.6845, -0.3353,  ..., -0.9431, -0.6479, -0.4606],
          [-0.3760, -0.5316, -0.4908,  ..., -0.6647, -0.4836, -0.2759]]],
        [[[-0.2248,  0.2952,  0.5862,  ...,  0.3243, -0.1330, -0.7603],
          [-0.4980, -0.0652,  0.4478,  ...,  0.1602, -0.1356, -0.7884],
          [-0.4024,  0.1087,  0.4381,  ...,  0.1444, -0.0636, -0.4542],
          ...,
          [-0.0870,  0.2367,  0.4889,  ...,  0.0970, -0.0378, -0.7177],
          [-0.0053,  0.1328,  0.4154,  ...,  0.1095, -0.2505, -0.6697],
          [ 0.0011,  0.1888,  0.4008,  ...,  0.0504, -0.2476, -0.9973]]],
        ...,
        [[[-0.6497, -0.5481, -0.8071,  ...,  0.1600,  0.1692, -0.1705],
          [-0.3632, -0.2676, -0.3279,  ..., -0.0642,  0.0768, -0.2667],
          [-0.0387, -0.0142, -0.0118,  ...,  0.0360,  0.1606, -0.0024],
          ...,
          [-0.8139, -0.6688, -0.7468,  ..., -0.3633, -0.6748, -0.7936],
          [-0.9491, -0.9901, -0.8169,  ..., -0.4234, -0.5454, -0.6574],
          [-1.0000, -0.7962, -0.8121,  ..., -0.4617, -0.5246, -0.7628]]],
        [[[-0.3706, -0.5746, -0.3674,  ...,  0.1964,  0.3304,  0.2611],
          [-0.3799, -0.3481, -0.3366,  ...,  0.0432, -0.0028, -0.0328],
          [-0.2225, -0.3878, -0.4144,  ..., -0.1496,  0.0358,  0.0223],
          ...,
          [-0.5237, -0.5315, -0.7275,  ...,  0.4143,  0.2021, -0.1584],
          [-0.2473, -0.4216, -0.6095,  ...,  0.3563, -0.1141, -0.6285],
          [-0.3483, -0.4997, -0.5807,  ...,  0.4654,  0.0961, -0.4536]]],
        [[[-0.4973, -0.5722, -0.6489,  ..., -0.0369, -0.1429, -0.7836],
          [-0.5215, -0.4981, -0.8213,  ...,  0.0179, -0.1298, -0.6744],
          [-0.4812, -0.4806, -0.7854,  ..., -0.0742, -0.2812, -0.8460],
          ...,
          [-0.6258, -0.3364, -0.2483,  ..., -0.0044, -0.1074, -0.3698],
          [-0.3844, -0.1700, -0.1090,  ...,  0.0233, -0.0195, -0.3339],
          [-0.5309, -0.3606, -0.2194,  ...,  0.0405, -0.0700, -0.3094]]]])
encoded_tensor.size: torch.Size([83, 10, 5, 5])
encoded_tensor.size: tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        ...,
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]],
        [[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         ...,
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]],
         [[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
Test loss=nan acc=0.64