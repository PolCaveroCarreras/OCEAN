wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
  0%|          | 0/478 [00:00<?, ?batch/s]
loss:0.6923463344573975
loss:0.689734160900116
loss:0.6802303791046143
loss:0.6879875063896179
loss:0.6685183048248291
loss:0.6656168699264526
loss:0.6840320825576782

  3%|▎         | 12/478 [00:05<01:24,  5.49batch/s]
loss:0.61720871925354
loss:0.6571968197822571
loss:0.6203821897506714
loss:0.6160651445388794
loss:0.6256629228591919
loss:0.6651480197906494
loss:0.6324374079704285
loss:0.6703159809112549
loss:0.6233143210411072
loss:0.624187707901001
loss:0.61353600025177

  5%|▌         | 25/478 [00:07<01:13,  6.15batch/s]
loss:0.6285750865936279
loss:0.6189894676208496
loss:0.6037830710411072
loss:0.6104551553726196
loss:0.6117181181907654
loss:0.6073145270347595
loss:0.5856428146362305
loss:0.5995726585388184
loss:0.5779614448547363
loss:0.5747600793838501
loss:0.5811402797698975
loss:0.5956709980964661

  8%|▊         | 38/478 [00:09<01:08,  6.39batch/s]
loss:0.5464376211166382
loss:0.5897689461708069
loss:0.5672236680984497
loss:0.5555744767189026
loss:0.5908830165863037
loss:0.5590882301330566
loss:0.5836834907531738
loss:0.5399826765060425
loss:0.5950204133987427
loss:0.590876579284668
loss:0.5621567964553833
loss:0.5942295789718628

 11%|█         | 51/478 [00:11<01:05,  6.55batch/s]
loss:0.5813843011856079
loss:0.5564022064208984
loss:0.5883415937423706
loss:0.5298997163772583
loss:0.5275577306747437
loss:0.5327589511871338
loss:0.549181342124939
loss:0.5719913244247437
loss:0.5102828145027161
loss:0.555507242679596
loss:0.5812785029411316
loss:0.5506049394607544

 13%|█▎        | 64/478 [00:13<01:03,  6.48batch/s]
loss:0.5220006704330444
loss:0.5221357345581055
loss:0.538494348526001
loss:0.5419787168502808
loss:0.5698867440223694
loss:0.5502017736434937
loss:0.5334192514419556
loss:0.5437434911727905
loss:0.5477252006530762
loss:0.48637545108795166
loss:0.5522868633270264
loss:0.5688444375991821

 16%|█▌        | 77/478 [00:15<01:01,  6.49batch/s]
loss:0.5183956623077393
loss:0.560473620891571
loss:0.5555947422981262
loss:0.5824893712997437
loss:0.5297399759292603
loss:0.5808009505271912
loss:0.525551974773407
loss:0.5371336936950684
loss:0.5051181316375732
loss:0.5513104796409607
loss:0.5300748348236084
loss:0.5010577440261841

 19%|█▉        | 90/478 [00:17<01:01,  6.34batch/s]
loss:0.5244263410568237
loss:0.5214762091636658
loss:0.5192731022834778
loss:0.5229134559631348
loss:0.5288021564483643
loss:0.5013973116874695
loss:0.5295134782791138
loss:0.5246261358261108
loss:0.5302480459213257
loss:0.5164583921432495
loss:0.5089326500892639
loss:0.47520482540130615

 22%|██▏       | 103/478 [00:19<00:59,  6.28batch/s]
loss:0.5157192945480347
loss:0.47439679503440857
loss:0.47893375158309937
loss:0.4934040606021881
loss:0.5315171480178833
loss:0.5039606690406799
loss:0.5178514122962952
loss:0.568486213684082
loss:0.5088509917259216
loss:0.49302732944488525
loss:0.5053859949111938

 24%|██▍       | 115/478 [00:21<00:56,  6.44batch/s]
loss:0.5303094387054443
loss:0.5225286483764648
loss:0.5282449722290039
loss:0.48798736929893494
loss:0.5179972648620605
loss:0.4869149923324585
loss:0.46689289808273315
loss:0.5484731197357178
loss:0.4727611541748047
loss:0.4932568371295929
loss:0.47681576013565063
loss:0.5233509540557861

 27%|██▋       | 128/478 [00:23<00:57,  6.12batch/s]
loss:0.5116955041885376
loss:0.5384266376495361
loss:0.5223656892776489
loss:0.4965876340866089
loss:0.5034366846084595
loss:0.5373861789703369
loss:0.5340361595153809
loss:0.5392554998397827
loss:0.5325440168380737
loss:0.5439629554748535
loss:0.5083634853363037
loss:0.4870871901512146

 29%|██▉       | 141/478 [00:25<00:52,  6.39batch/s]
loss:0.5123197436332703
loss:0.530390202999115
loss:0.5163165926933289
loss:0.5191924571990967
loss:0.4576777517795563
loss:0.5046049356460571
loss:0.4953838586807251
loss:0.46573543548583984
loss:0.48726505041122437
loss:0.4732118844985962
loss:0.5105768442153931

 32%|███▏      | 153/478 [00:27<00:50,  6.50batch/s]
loss:0.4809725284576416
loss:0.47688090801239014
loss:0.4958378076553345
loss:0.5067033767700195
loss:0.45566949248313904
loss:0.5438496470451355
loss:0.4658008813858032
loss:0.526202917098999
loss:0.48481374979019165
loss:0.536188542842865
loss:0.48693734407424927
loss:0.5015053749084473
loss:0.4844547510147095

 35%|███▍      | 166/478 [00:29<00:49,  6.35batch/s]
loss:0.4617125391960144
loss:0.5175157785415649
loss:0.46838533878326416
loss:0.4701613783836365
loss:0.48473069071769714
loss:0.5345553159713745
loss:0.5566744208335876
loss:0.5321407318115234
loss:0.47134941816329956
loss:0.4897041916847229
loss:0.4999631643295288

 37%|███▋      | 179/478 [00:31<00:45,  6.55batch/s]
loss:0.5233819484710693
loss:0.4671418368816376
loss:0.48809000849723816
loss:0.469512015581131
loss:0.4656027853488922
loss:0.49846091866493225
loss:0.49067917466163635
loss:0.5120853185653687
loss:0.4927668571472168
loss:0.4855123460292816
loss:0.4799196124076843
loss:0.4991264343261719

 40%|████      | 192/478 [00:33<00:45,  6.32batch/s]
loss:0.47315242886543274
loss:0.4917144775390625
loss:0.4661567807197571
loss:0.5045350790023804
loss:0.4809439480304718
loss:0.4600750505924225
loss:0.48600292205810547
loss:0.4734400510787964
loss:0.4875054955482483
loss:0.48654666543006897
loss:0.5013210773468018
loss:0.5000607967376709

 43%|████▎     | 205/478 [00:35<00:42,  6.41batch/s]
loss:0.4354172348976135
loss:0.45990806818008423
loss:0.46279874444007874
loss:0.4901833236217499
loss:0.4963364601135254
loss:0.4894418716430664
loss:0.4885316789150238
loss:0.4933032691478729
loss:0.46649497747421265
loss:0.49741262197494507
loss:0.4760957360267639
loss:0.4825441539287567

 46%|████▌     | 218/478 [00:37<00:40,  6.38batch/s]
loss:0.5013233423233032
loss:0.47252964973449707
loss:0.48203083872795105
loss:0.4721589684486389
loss:0.43952131271362305
loss:0.54156494140625
loss:0.4972485303878784
loss:0.46039560437202454
loss:0.4917270243167877
loss:0.5248831510543823
loss:0.45820510387420654
loss:0.4930710196495056

 48%|████▊     | 231/478 [00:39<00:38,  6.47batch/s]
loss:0.4925900101661682
loss:0.46487265825271606
loss:0.509382963180542
loss:0.47645628452301025
loss:0.4891887307167053
loss:0.4390098750591278
loss:0.46397751569747925
loss:0.4787796437740326
loss:0.5141156315803528
loss:0.4975340962409973
loss:0.5108482837677002
loss:0.4789685606956482

 51%|█████     | 244/478 [00:41<00:36,  6.49batch/s]
loss:0.4852066934108734
loss:0.4962822198867798
loss:0.456773042678833
loss:0.4705643057823181
loss:0.5044049024581909
loss:0.5075896382331848
loss:0.5134455561637878
loss:0.4782683849334717
loss:0.48727092146873474
loss:0.48470041155815125
loss:0.4713921546936035
loss:0.4900055229663849

 54%|█████▎    | 256/478 [00:43<00:34,  6.39batch/s]
loss:0.48581448197364807
loss:0.48247718811035156
loss:0.4556726813316345
loss:0.4919282793998718
loss:0.5169192552566528
loss:0.4937567114830017
loss:0.4716455340385437
loss:0.487026184797287
loss:0.5211953520774841
loss:0.4730401635169983
loss:0.46831846237182617

 56%|█████▋    | 270/478 [00:45<00:32,  6.46batch/s]
loss:0.4779254198074341
loss:0.4790102243423462
loss:0.4493621587753296
loss:0.5087975859642029
loss:0.4838308095932007
loss:0.4922230541706085
loss:0.49371689558029175
loss:0.4322688579559326
loss:0.4557012915611267
loss:0.479373037815094
loss:0.4561113119125366
loss:0.49490368366241455

 59%|█████▉    | 282/478 [00:47<00:30,  6.42batch/s]
loss:0.45943719148635864
loss:0.45753970742225647
loss:0.4410666525363922
loss:0.4815410375595093
loss:0.47237205505371094
loss:0.47846129536628723
loss:0.5034936666488647
loss:0.49867844581604004
loss:0.4662702679634094
loss:0.475994348526001
loss:0.4603728652000427
loss:0.47609996795654297

 62%|██████▏   | 295/478 [00:49<00:28,  6.33batch/s]
loss:0.47166651487350464
loss:0.5269918441772461
loss:0.46771252155303955
loss:0.48654767870903015
loss:0.47082340717315674
loss:0.48041683435440063
loss:0.48740410804748535
loss:0.4528932571411133
loss:0.4366952180862427
loss:0.4978881776332855
loss:0.4788913130760193
loss:0.43476659059524536

 64%|██████▍   | 308/478 [00:51<00:26,  6.45batch/s]
loss:0.454120934009552
loss:0.4749089777469635
loss:0.5025522708892822
loss:0.4667700529098511
loss:0.47396785020828247
loss:0.45595961809158325
loss:0.44410812854766846
loss:0.45008963346481323
loss:0.45500653982162476
loss:0.46437975764274597
loss:0.48296087980270386
loss:0.45850539207458496

 67%|██████▋   | 321/478 [00:53<00:24,  6.41batch/s]
loss:0.5027738809585571
loss:0.4643594026565552
loss:0.4985819160938263
loss:0.4580308198928833
loss:0.4905771315097809
loss:0.507940411567688
loss:0.49183595180511475
loss:0.501501202583313
loss:0.45048069953918457
loss:0.4740195870399475
loss:0.4729282259941101
loss:0.5026267766952515

 70%|██████▉   | 334/478 [00:55<00:21,  6.67batch/s]
loss:0.5045309662818909
loss:0.47442662715911865
loss:0.49897587299346924
loss:0.5116915702819824
loss:0.46737733483314514
loss:0.4573550820350647
loss:0.46175986528396606
loss:0.44302117824554443
loss:0.4680139124393463
loss:0.5049333572387695
loss:0.5112627148628235
loss:0.5141193866729736

 73%|███████▎  | 347/478 [00:57<00:20,  6.37batch/s]
loss:0.44715502858161926
loss:0.494651734828949
loss:0.4808672070503235
loss:0.4538538455963135
loss:0.47643405199050903
loss:0.48807641863822937
loss:0.46671584248542786
loss:0.42550036311149597
loss:0.4792482852935791
loss:0.4663856029510498
loss:0.5125998854637146
loss:0.49004536867141724

 75%|███████▌  | 360/478 [00:59<00:18,  6.51batch/s]
loss:0.4907236695289612
loss:0.49886393547058105
loss:0.45344799757003784
loss:0.476414293050766
loss:0.45584893226623535
loss:0.5026133060455322
loss:0.5003939867019653
loss:0.48202794790267944
loss:0.4995010495185852
loss:0.46229833364486694
loss:0.5057407021522522
loss:0.45460566878318787

 78%|███████▊  | 373/478 [01:02<00:16,  6.47batch/s]
loss:0.5107517242431641
loss:0.5273146033287048
loss:0.49957966804504395
loss:0.4773123562335968
loss:0.5151240825653076
loss:0.4644649624824524
loss:0.5265969634056091
loss:0.4613986015319824
loss:0.5280537009239197
loss:0.468271940946579
loss:0.46196117997169495

 81%|████████  | 386/478 [01:04<00:14,  6.34batch/s]
loss:0.511904776096344
loss:0.45308399200439453
loss:0.4338620603084564
loss:0.5005902647972107
loss:0.48130351305007935
loss:0.46556344628334045
loss:0.45517683029174805
loss:0.48235994577407837
loss:0.46855103969573975
loss:0.49565058946609497
loss:0.45724520087242126
loss:0.4666707515716553

 83%|████████▎ | 398/478 [01:05<00:12,  6.41batch/s]
loss:0.45623818039894104
loss:0.47819092869758606
loss:0.47170335054397583
loss:0.4924408197402954
loss:0.4445750415325165
loss:0.4899076819419861
loss:0.48998600244522095
loss:0.5142834186553955
loss:0.5142015814781189
loss:0.4819043278694153
loss:0.4894096851348877
loss:0.4882667660713196

 86%|████████▌ | 411/478 [01:07<00:10,  6.40batch/s]
loss:0.462163507938385
loss:0.44339215755462646
loss:0.4448082745075226
loss:0.5059313774108887
loss:0.5137422680854797
loss:0.4624091386795044
loss:0.46127092838287354
loss:0.5013619661331177
loss:0.4866211712360382
loss:0.48930084705352783
loss:0.47352486848831177
loss:0.4775557219982147

 89%|████████▊ | 424/478 [01:09<00:08,  6.58batch/s]
loss:0.47687602043151855
loss:0.46222540736198425
loss:0.46776026487350464
loss:0.45800697803497314
loss:0.49343350529670715
loss:0.47141316533088684
loss:0.45681440830230713
loss:0.48748859763145447
loss:0.4445647895336151
loss:0.4431203305721283
loss:0.47934603691101074
loss:0.4786494970321655

 91%|█████████▏| 437/478 [01:11<00:06,  6.48batch/s]
loss:0.46764323115348816
loss:0.45873749256134033
loss:0.455282062292099
loss:0.4906511902809143
loss:0.5081430673599243
loss:0.4464170038700104
loss:0.4692472815513611
loss:0.4862193763256073
loss:0.46090006828308105
loss:0.49918121099472046
loss:0.4403645396232605
loss:0.45162951946258545

 94%|█████████▍| 450/478 [01:13<00:04,  6.41batch/s]
loss:0.4613613784313202
loss:0.4990481436252594
loss:0.4990295171737671
loss:0.4654967784881592
loss:0.4532178044319153
loss:0.5057852268218994
loss:0.4597535729408264
loss:0.44922441244125366
loss:0.4699440598487854
loss:0.4744530916213989
loss:0.45234256982803345
loss:0.4928818345069885

 97%|█████████▋| 463/478 [01:15<00:02,  6.37batch/s]
loss:0.43231478333473206
loss:0.4829707145690918
loss:0.5008713006973267
loss:0.5037654042243958
loss:0.42698127031326294
loss:0.49959245324134827
loss:0.46007633209228516
loss:0.4828941226005554
loss:0.4684149920940399
loss:0.4968146085739136
loss:0.4579746127128601
loss:0.4956113398075104

100%|█████████▉| 476/478 [01:18<00:00,  6.38batch/s]
loss:0.4769939184188843
loss:0.45967116951942444
loss:0.4786757230758667
loss:0.47369125485420227
loss:0.4692402780056
loss:0.43837597966194153
loss:0.4687631130218506

100%|██████████| 478/478 [01:18<00:00,  6.11batch/s]
Eval Epoch 0 loss=0.48 acc=0.88
Traceback (most recent call last):
  File "src/main.py", line 258, in <module>
    my_model = train_model(config)
  File "src/main.py", line 168, in train_model
    predictions = my_model(inputs)  # Make predictions using your model
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/DMHA.py", line 127, in forward
    encoder_output = self.front_end(input_tensor)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/OCEAN/src/front_end.py", line 126, in forward
    encoded_tensor = self.conv_blocks(input_tensor) # descomentar si no va
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/usuaris/veu/pol.cavero/miniconda3/envs/ocean/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
Test loss=0.48 acc=0.87